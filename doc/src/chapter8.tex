\title{High-performance computing Many-body methods and infinite nuclear matter}
\author{Justin G.~Lietz, Samuel Novario, Gustav R.~Jansen, Gaute Hagen, and Morten Hjorth-Jensen,}
\institute{Justin G.~Lietz \at Department of Physics and Astronomy and National Superconducting Cyclotron Laboratory, Michigan State University, East Lansing, Michigan,  USA, \email{lietz@nscl.msu.edu}, \and Samuel Novario \at Department of Physics and Astronomy and National Superconducting Cyclotron Laboratory, Michigan State University, East Lansing, Michigan,  USA, \email{novarios@nscl.msu.edu}, \and Gustav R.~Jansen \at Oak Ridge National Laboratory, Physics Division, Oak Ridge, Tennessee, USA and Department of Physics and Astronomy, University of Tennessee, Knoxville, Tennessee, USA, \email{jansen@ornl.gov}, \and Gaute Hagen \at Oak Ridge National Laboratory, Physics Division, Oak Ridge, Tennessee, USA and Department of Physics and Astronomy, University of Tennessee, Knoxville, Tennessee, USA, \email{hageng@ornl.gov},  \and Morten Hjorth-Jensen  \at Department of Physics and Astronomy and National Superconducting Cyclotron Laboratory, Michigan State University, East Lansing, Michigan,  USA and Department of Physics, University of Oslo, Oslo, Norway, \email{hjensen@msu.edu}}

\maketitle
\abstract{We present a computational approach to infinite nuclear matter employing
Hartree-Fock theory, many-body perturbation theory and coupled cluster
theory. These lectures are closely linked with those in
chapters \ref{chap:chapter9}, \ref{chap:chapter10} and \ref{chap:chapter11} and serve as
input for the correlation functions employed in Monte Carlo
calculations in chapter \ref{chap:chapter9}, the in-medium similarity renormalization group theory of
dense fermionic systems of chapter chapter \ref{chap:chapter10} and the Green's function approach in chapter \ref{chap:chapter11}.  We provide extensive code examples and
benchmark calculations, allowing thereby an eventual reader to start
writing her/his own codes. We start with an object-oriented serial
code and end with in-depth discussions on strategies for porting the
code to present and planned high-performance computing facilities. }


%\maketile

\section{Introduction}

Studies of infinite nuclear matter play an important role in nuclear
physics. The aim of this part of the lectures is to provide the
necessary ingredients for perfoming studies of neutron star matter (or
matter in $\beta$-equilibrium) and symmetric nuclear matter.  We will
mainly focus on pure neutron matter, but the framework and formalism
can easily be extended to other dense and homogeneous fermionic
systems such as the electron gas in two and three dimensions. The
introductory material we present here forms also the basis for the
next three chapters, starting with the definition of the
single-particle basis and our Hamiltonians as well as Hartree-Fock
theory. For infinite matter, due to the translational invariance of
the Hamiltonian, the single-particle basis, in terms of plane waves,
unchanged under Hartree-Fock calculations.

Studies of dense baryonic matter are of central importance to our
basic understanding of the stability of nuclear matter, spanning from
matter at high densities and temperatures to matter as found within
dense astronomical objects like neutron stars.

Neutron star matter at densities of 0.1 fm$^{-3}$ and greater, is
often assumed to be made of mainly neutrons, protons, electrons and
muons in beta equilibrium. However, other baryons like various
hyperons may exist, as well as possible mesonic condensates and
transitions to quark degrees of freedom at higher densities \cite{hh2000}.  
In these notes we limit ourselves to
matter composed of neutrons only.  Furthermore, we will also
consider matter at temperatures much lower than the typical Fermi
energies.  

In the next section we present some of the basic quantities that enter the different many-body methods 
discussed in this and the three subsequent chapters. All these methods start with some single-particle basis states,
normally obtained via the solution of mean-field approaches like  Hartree-Fock theory. Contributions from 
correlations beyond such a mean-field basis to selected observables, are then obtained
via a plethora of many-body methods. These methods represent different mathematical algorithms used to solve either 
Schr\"{o}dinger's or Dirac's equations for many interacting fermions. After the definitions of our basis states, we derive the Hartree-Fock equations
in the subsequent section and move on with many-body perturbation theory, full configuration interaction theory and coupled cluster theory. 
Monte Carlo methods, Green's function theory approaches and Similarity Renormlization group approaches are discussed in the subsequent three chapters. 

The strengths and weaknesses of these methods are discussed throughout these chapters, with applications to either a simple pairing model
and/or pure neutron matter. Our focus will be on pure neutron matter, starting with a simple model for the interaction
between nucleons. This allows us to focus on the pedagogical and algorithmic aspects of the various many-body methods, avoiding thereby the  full complexity of nuclear forces.
If properly written however, the codes can easily be extended to include models of the nuclear interactions based on effective field theory \cite{eft} and other baryon species than just neutrons. In our conclusions we point  back to models for nuclear forces and their links to the underlying theory of the strong interaction discussed in the first chapters of this book, bridging thereby the gap between the theory of nuclear Hamiltonians and many-body methods. 


\section{Single-particle basis, Hamiltonians and models for the nuclear force}

\subsection{Introduction to nuclear matter and Hamiltonians}

Although our focus here and in the coming chapters is on neutron matter only, 
our formalism lends itself easily to studies of nuclear  matter 
with a given proton fraction and electrons. In this section we outline some of the background details, with a focus on the calculational basis
and the representation of a nuclear Hamiltonian. 

Neutron star matter is not composed of only neutrons. Rather, matter is composed of various baryons and leptons in chemical and charge equilibrium.
The equilibrium conditions are governed by the weak
processes (normally referred to as the processes for
$\beta$-equilibrium)
\begin{equation} 
      b_1 \rightarrow b_2 + l +\bar{\nu}_l \hspace{1cm} b_2 +l \rightarrow b_1 
+\nu_l,
      \label{eq:betadecay}
\end{equation}
where $b_1$ and $b_2$ refer to  different types of baryons, for example a neutron and a proton.  
The symbol $l$ is either an electron or a muon and  $\bar{\nu}_l $
and $\nu_l$ their respective anti-neutrinos and neutrinos. Leptons like muons 
appear at
a density close to nuclear matter saturation density, the latter being
\[
     n_0 \approx 0.16 \pm 0.02 \hspace{1cm} \mathrm{fm}^{-3},
\]
with a corresponding energy per baryon ${\cal E}_0$ 
for symmetric nuclear matter at saturation density of
\[
     {\cal E}_0 = B/A=-15.6\pm 0.2 \hspace{1cm} \mathrm{MeV}.
\]
The energy per baryon is the central quantity in the present studies. From the energy per baryon, we can define the pressure 
$P$ which counteracts the gravitional forces and hinders the gravitational collapse of neutron start. The pressure  is defined through the relation
\begin{equation}
    P=n^2\frac{\partial {\cal E}}{\partial n}=
      n\frac{\partial \varepsilon}{\partial n}-\varepsilon.
\end{equation}

Similarly, the chemical potential for particle species $i$
is given by
\begin{equation}
     \mu_i = \left(\frac{\partial \varepsilon}{\partial n_i}\right).
     \label{eq:chemicalpotdef}
\end{equation}
In calculations of properties of neutron star matter in $\beta$-equilibrium,
we need to calculate the energy per baryon ${\cal E}$ for e.g.~several 
proton fractions $x_p$. The proton fraction corresponds to
the ratio of protons as
compared to the total nucleon number ($Z/A$). It is 
 defined as
\begin{equation}
    x_p = \frac{n_p}{n},
\end{equation}
where $n=n_p+n_n$, the total baryonic density if neutrons and
protons are the only baryons present. If this is the case,
the total Fermi momentum $k_F$ and the Fermi momenta $k_{Fp}$,
$k_{Fn}$ for protons and neutrons are related to the total nucleon density
$n$ by
\begin{align}
     n = & \frac{2}{3\pi^2} k_F^3 \nonumber \\
       = & x_p n + (1-x_p) n \nonumber \\
       = & \frac{1}{3\pi^2} k_{Fp}^3 + \frac{1}{3\pi^2} k_{Fn}^3.
    \label{eq:densi}
\end{align}
The energy per baryon will thus be
labelled as ${\cal E}(n,x_p)$. The quantity
${\cal E}(n,0)$ refers then to the energy per baryon for pure neutron
matter (PNM) while ${\cal E}(n,\frac{1}{2})$ is the corresponding value for 
SNM. Furthermore, in this work, subscripts $n,p,e,\mu$
will always refer to neutrons, protons, electrons and muons, respectively.


Since the mean free path of a neutrino in a neutron star is bigger
than the typical radius of such a star ($\sim 10$ km), 
we will throughout assume that neutrinos escape freely from the neutron star,
see for example  the work of Prakash et al.
for a discussion
on trapped neutrinos. Eq. (\ref{eq:betadecay}) yields then the following
conditions for matter in $\beta$ equilibrium with for example  nucleonic degrees 
freedom only
\begin{equation}
    \mu_n=\mu_p+\mu_e,
     \label{eq:npebetaequilibrium}
\end{equation}
and 
\begin{equation}
     n_p = n_e,
     \label{eq:chargeconserv}
\end{equation}
where $\mu_i$ and $n_i$ refer to the chemical potential and number density
in fm$^{-3}$ of particle species $i$. 
If muons are present as well,  we need to modify the equation for 
charge conservation, Eq. (\ref{eq:chargeconserv}), to read 
\[
     n_p = n_e+n_{\mu},
\]
and require that $\mu_e = \mu_{\mu}$.

An important ingredient in the discussion of the EoS and the criteria for
matter in $\beta$-equilibrium is the so-called symmetry energy ${\cal S} (n)$, 
defined as
the difference in energy for symmetric nuclear matter
and pure neutron matter 
\begin{equation}
      {\cal S} (n) = {\cal E} (n,x_p=0) - {\cal E} (n,x_p=1/2 ).
      \label{eq:symenergy}
\end{equation}
If we expand the energy per baryon in the case of nucleonic degrees of freedom 
only
in the proton concentration $x_p$ about the value of the energy 
for SNM ($x_p=\frac{1}{2}$), we obtain,
\begin{equation}
     {\cal E} (n,x_p)={\cal E} (n,x_p=\frac{1}{2})+
     \frac{1}{2}\frac{d^2 {\cal E}}{dx_p^2} (n)\left(x_p-1/2\right)^2+\dots ,
     \label{eq:energyexpansion}
\end{equation}
where the term $d^2 {\cal E}/dx_p^2$ 
is to be associated with the symmetry energy ${\cal S} (n)$ in the empirical
mass formula. If
we assume that higher order derivatives in the above expansion are small, then through the 
conditions
for $\beta$-equilbrium of Eqs. (\ref{eq:npebetaequilibrium}) and 
(\ref{eq:chargeconserv})
and Eq. (\ref{eq:chemicalpotdef}) we can define the proton
fraction by the symmetry energy as
\begin{equation}  
    \hbar c\left(3\pi^2nx_p\right)^{1/3} = 4{\cal S} (n)\left(1-2x_p\right),
    \label{eq:crudeprotonfraction}
\end{equation}
where the electron chemical potential is given
by $\mu_e = \hbar c k_F$, i.e.\  ultrarelativistic electrons are assumed.
Thus, the symmetry energy is of paramount importance for studies 
of neutron star matter in $\beta$-equilibrium.
One can extract information about the value of the symmetry energy at saturation 
density
$n_0$ from systematic studies of the masses of atomic nuclei. However, these 
results
are limited to densities around $n_0$ and for proton fractions close to 
$\frac{1}{2}$, see for example the various contributions in Ref.~\cite{symmetryenergy2013}.
Typical values for ${\cal S} (n)$ at $n_0$ are in the range $27-38$ MeV.
For densities greater than $n_0$ it is more difficult to get a reliable 
information on the symmetry energy, and thereby the related proton fraction.

Before we proceed we need some definitions.
We will assume that the interacting part of the Hamiltonian
can be approximated by a two-body interaction.
This means that our Hamiltonian is written as the sum of some onebody part and a twobody part
\begin{equation}
    \hat{H} = \hat{H}_0 + \hat{H}_I 
    = \sum_{i=1}^A \hat{h}_0(x_i) + \sum_{i < j}^A \hat{v}(r_{ij}),
label{Hnuclei}
\end{equation}
with 
\begin{equation}
  H_0=\sum_{i=1}^A \hat{h}_0(x_i).
label{hinuclei}
\end{equation}
The onebody part $u_{\mathrm{ext}}(x_i)$ is normally approximated by a harmonic oscillator or Woods-Saxon potential or for electronic systems the Coulomb interaction an electron feels from the nucleus. However, other potentials are fully possible, such as 
one derived from the self-consistent solution of the Hartree-Fock equations to be discussed below. Since we will work with plane waves, the onebody operator
is simply given by the kinetic energy operator to be discussed below. 

Our Hamiltonian is invariant under the permutation (interchange) of two particles.
Since we deal with fermions however, the total wave function is antisymmetric.
Let $\hat{P}$ be an operator which interchanges two particles.
Due to the symmetries we have ascribed to our Hamiltonian, this operator commutes with the total Hamiltonian,
\[
[\hat{H},\hat{P}] = 0,
 \]
meaning that $\Psi_{\lambda}(x_1, x_2, \dots , x_A)$ is an eigenfunction of 
$\hat{P}$ as well.

In our case we assume that  we can approximate the exact eigenfunction for say the ground state with a Slater determinant
\begin{equation}
   \Phi(x_1, x_2,\dots ,x_A,\alpha,\beta,\dots, \sigma)=\frac{1}{\sqrt{A!}}
\left| \begin{array}{ccccc} \psi_{\alpha}(x_1)& \psi_{\alpha}(x_2)& \dots & \dots & \psi_{\alpha}(x_A)\\
                            \psi_{\beta}(x_1)&\psi_{\beta}(x_2)& \dots & \dots & \psi_{\beta}(x_A)\\  
                            \dots & \dots & \dots & \dots & \dots \\
                            \dots & \dots & \dots & \dots & \dots \\
                     \psi_{\sigma}(x_1)&\psi_{\sigma}(x_2)& \dots & \dots & \psi_{\sigma}(x_A)\end{array} \right|, label{eq:HartreeFockDet}
\end{equation}
where  $x_i$  stand for the coordinates and spin values of a particle $i$ and $\alpha,\beta,\dots, \gamma$ 
are quantum numbers needed to describe remaining quantum numbers.  

The single-particle function $\psi_{\alpha}(x_i)$  are eigenfunctions of the onebody
Hamiltonian $h_i$, that is
\[
\hat{h}_0(x_i)=\hat{t}(x_i) + \hat{u}_{\mathrm{ext}}(x_i),
\]
with eigenvalues 
\[
\hat{h}_0(x_i) \psi_{\alpha}(x_i)=\left(\hat{t}(x_i) + \hat{u}_{\mathrm{ext}}(x_i)\right)\psi_{\alpha}(x_i)=\varepsilon_{\alpha}\psi_{\alpha}(x_i).
\]
The energies $\varepsilon_{\alpha}$ are the so-called non-interacting single-particle energies, or unperturbed energies. 
The total energy is in this case the sum over all  single-particle energies, if no two-body or more complicated
many-body interactions are present.

Properties of the determinant (interchange of any two rows or 
any two columns yields a change in sign; thus no two rows and no 
two columns can be the same) lead to the following consequence of the Pauli principle:

\begin{itemize}
\item No two particles can be at the same place (two columns the same); and

\item No two particles can be in the same state (two rows the same).
\end{itemize}

\noindent
As a practical matter, however, Slater determinants beyond $N=4$
quickly become unwieldy. Thus we turn to the \textbf{occupation representation} or \textbf{second quantization} to simplify
calculations.
We start with a set of orthonormal single-particle states
$\{ \phi_i(x) \}$.  To each single-particle state $\phi_i(x)$ we associate a creation operator 
$\hat{a}^\dagger_i$ and an annihilation operator $\hat{a}_i$. 
When acting on the vacuum state $| 0 \rangle$, the creation operator $\hat{a}^\dagger_i$ causes 
a particle to occupy the single-particle state $\phi_i(x)$:
\[
\phi_i(x) \rightarrow \hat{a}^\dagger_i |0 \rangle
\]
But with multiple creation operators we can occupy multiple states:
\[
\phi_i(x) \phi_j(x^\prime) \phi_k(x^{\prime \prime}) 
\rightarrow \hat{a}^\dagger_i \hat{a}^\dagger_j \hat{a}^\dagger_k |0 \rangle.
\]

Now we impose antisymmetry, by having the fermion operators satisfy  the anti-commutation relations
\[
\hat{a}^\dagger_i \hat{a}^\dagger_j + \hat{a}^\dagger_j \hat{a}^\dagger_i
= [ \hat{a}^\dagger_i ,\hat{a}^\dagger_j ]_+ 
= \{ \hat{a}^\dagger_i ,\hat{a}^\dagger_j \} = 0,
\]
so that 
\[
\hat{a}^\dagger_i \hat{a}^\dagger_j = - \hat{a}^\dagger_j \hat{a}^\dagger_i.
\]
Because of this property, with obtain $\hat{a}^\dagger_i \hat{a}^\dagger_i = 0$, 
enforcing the Pauli exclusion principle.  Thus when writing a Slater determinant 
using creation operators, 
\[
\hat{a}^\dagger_i \hat{a}^\dagger_j \hat{a}^\dagger_k \ldots |0 \rangle
\]
each index $i,j,k, \ldots$ must be unique.


With the definition of  a Fermi level, we can in turn define our ansatz for the ground state, represented by a Slater determinant
as $\Phi_0$.  We will throughout the rest of this text using creation and annihilation operators to represent quantum mechanical operators and states.
It means that our compact representation of a given Slater determinant in what is called Fock space \cite{deffockspace} is
\[
  \Phi_{0}=|i_1 \dots i_A\rangle= a_{i_1}^{\dagger} \dots a_{i_A}^{\dagger} |0\rangle
\]
where $\vert 0\rangle$ is the true vacuum and we have defined the creation and annihilation operators as
    \[
        a_p^\dagger|0\rangle = |p\rangle, \quad a_p |q\rangle = \delta_{pq}|0\rangle
    \]
with the anti-commutation relations
\[
  \delta_{pq} = \left\{a_p, a_q^\dagger \right\},
\]
and 
\[
\left\{a_p^\dagger, a_q \right\} = \left\{a_p, a_q \right\} = \left\{a_p^\dagger, a_q^\dagger \right\}=0.
\]

We can rewrite the ansatz for the ground state as
\[
\vert\Phi_0\rangle = \prod_{i\le F}a_{i}^{\dagger} |0\rangle,
\]
where we have introduced the shorthand label for states above and below the Fermi level $F$ as
$i,j,\ldots \leq F$. For single-particle states the Fermi level we reserve the labels $a,b,\ldots > F$, while the labels $p,q, \ldots$
represent any single particle state, that is states below and above the Fermi level. 

Since our focus is on infinite systems, the one-body part of the Hamiltonian is given by the kinetic energy operator only.
In second quantization it is defined as
\[
\hat{H}_0=\hat{T} = \sum_{pq} \langle p|\hat{t}|q\rangle a_p^\dagger a_q,
\]
while the two-body interaction  reads
\[
\hat{H}_I=\hat{V} = \frac{1}{4} \sum_{pqrs} \langle pq|\hat{v}|rs\rangle_{AS} a_p^\dagger a_q^\dagger a_s a_r,
\]
where we have defined the antisymmetric matrix elements
\[
\langle pq|\hat{v}|rs\rangle_{AS} = \langle pq|\hat{v}|rs\rangle - \langle pq|\hat{v}|sr\rangle.
\]

We can also define a three-body operator
\[
\hat{V}_3 = \frac{1}{36} \sum_{pqrstu} \langle pqr|\hat{v}_3|stu\rangle_{AS} 
                a_p^\dagger a_q^\dagger a_r^\dagger a_u a_t a_s,
\]
with the antisymmetrized matrix element
\begin{align}
            \langle pqr|\hat{v}_3|stu\rangle_{AS} = \langle pqr|\hat{v}_3|stu\rangle + \langle pqr|\hat{v}_3|tus\rangle + \langle pqr|\hat{v}_3|ust\rangle- \langle pqr|\hat{v}_3|sut\rangle - \langle pqr|\hat{v}_3|tsu\rangle - \langle pqr|\hat{v}_3|uts\rangle.
\end{align}
In this the forthcoming chapters we will limit ourselves to two-body interactions at most. 

Using the ansatz for the ground state $\vert \Phi_0$ as new reference vacuum state, we need to redefine the anticommutation relations to
\[
\left\{a_p^\dagger, a_q \right\}= \delta_{pq}, p, q \leq F, 
\]
and
\[
\left\{a_p, a_q^\dagger \right\} = \delta_{pq}, p, q > F.
\]
It is easy to see then that         
\[
        a_i|\Phi_0\rangle = |\Phi_i\rangle, \hspace{0.5cm} a_a^\dagger|\Phi_0\rangle = |\Phi^a\rangle,
\]
and         
\[
a_i^\dagger|\Phi_0\rangle = 0 \hspace{0.5cm}  a_a|\Phi_0\rangle = 0.
\]
It is easy to show, see problem \ref{prob8.1}, that with the new reference vacuum state the Hamiltonian can be rewritten as 
\[
\hat{H}=E_{\mathrem{Ref}}+\hat{H}_N,
\]
with the reference energy defined as 
\[
E_{\mathrem{Ref}}=\langle \Phi_0 \vert \hat{H} \vert \Phi_0\rangle = \sum_{i\le F} \langle i|\hat{h}_0|i\rangle + \frac{1}{2} \sum_{ij\le F}\langle ij|\hat{v}|ij\rangle,
\]
and the new normal-ordered Hamiltonian defined as 
\[
\hat{H}_N = \sum_{pq} \langle p|\hat{h}_0|q\rangle \left\{a^\dagger_p a_q\right\}+\frac{1}{4} \sum_{pqrs} \langle pq|\hat{v}|rs\rangle \left\{a^\dagger_p a^\dagger_q a_s  a_r\right\}+\sum_{pq,i\le F} \langle pi|\hat{v}|qi\rangle \left\{a^\dagger_p a_q\right\},  
\]
where the curly brackets represent normal-ordering with respect to the new reference vacuum state. 
The latter can be rewritten in terms of a new one-body operator and a two-body operator as
\[
\hat{H}_N=\hat{F}_N+\hat{V}_N,
\]
with
\[
\hat{F}_N=\sum_{pq} \langle p|\hat{f}|q\rangle \left\{a^\dagger_p a_q\right\},
\]
where
\[
\langle p|\hat{f}|q\rangle= \langle p|\hat{h}_0|q\rangle \sum_{i\le F} \langle pi|\hat{v}|qi\rangle.  
\]
The last term on the right hand side  represents a medium modification, due to the two-body interaction, to the single-particle Hamiltonian.
Finally, the two-body interaction is given by
\[	     
\hat{V}_N = \frac{1}{4} \sum_{pqrs} \langle pq|\hat{v}|rs\rangle \left\{a^\dagger_p a^\dagger_q a_s  a_r\right\}.
\]


\subsection{Single-particle basis for infinite matter}

Infinite nuclear or neutron matter is a homogeneous system and the
one-particle wave functions are given by plane wave functions
normalized to a volume $\Omega$ for a box with length $L$ (the limit
$L\rightarrow \infty$ is to be taken after we have computed various
expectation values)
\[
\psi_{\mathbf{k}\sigma}(\mathbf{r})= \frac{1}{\sqrt{\Omega}}\exp{(i\mathbf{kr})}\xi_{\sigma}
\]
where $\mathbf{k}$ is the wave number and  $\xi_{\sigma}$ is a spin function for either spin up or down
\[ 
\xi_{\sigma=+1/2}=\left(\begin{array}{c} 1 \\ 0 \end{array}\right) \hspace{0.5cm}
\xi_{\sigma=-1/2}=\left(\begin{array}{c} 0 \\ 1 \end{array}\right).
\]

We focus first on the kinetic energy operator.
We assume that we have periodic boundary conditions which limit the allowed wave numbers to
\[
k_i=\frac{2\pi n_i}{L}\hspace{0.5cm} i=x,y,z \hspace{0.5cm} n_i=0,\pm 1,\pm 2, \dots
\]
The operator for the kinetic energy can be written as, see problem \ref{prob8.2},
\[
\hat{T}=\sum_{\mathbf{p}\sigma_p}\frac{\hbar^2k_P^2}{2m}a_{\mathbf{p}\sigma}^{\dagger}a_{\mathbf{p}\sigma_p}.
\]
When using periodic boundary conditions, the 
discrete-momentum single-particle basis functions 
\[
\phi_{\mathbf{k}}(\mathbf{r}) =
e^{i\mathbf{k}\cdot \mathbf{r}}/L^{d/2}
\]
are associated with 
the single-particle energy   
\begin{align}
  \varepsilon_{n_{x}, n_{y}} = \frac{\hbar^{2}}{2m} \left( \frac{2\pi }{L}\right)^{2}\left( n_{x}^{2} + n_{y}^{2}\right)
\end{align}
for two-dimensional sytems and 
\begin{align}
  \varepsilon_{n_{x}, n_{y}, n_{z}} = \frac{\hbar^{2}}{2m}
  \left( \frac{2\pi }{L}\right)^{2}
  \left( n_{x}^{2} + n_{y}^{2} + n_{z}^{2}\right)
\end{align} 
for three-dimensional systems.


We choose  the single-particle basis such that both the occupied and 
unoccupied single-particle spaces have a closed-shell 
structure. This means that all single-particle states 
corresponding to energies below a chosen cutoff are
included in the basis. We study only the unpolarized spin
phase, in which all orbitals are occupied with one spin-up 
and one spin-down electron. 


The single-particle kinetic energy defined as
\[
\frac{\hbar^2}{2m}\left(k_{n_x}^2+k_{n_y}^2+k_{n_z}^2\right),
\]
and 
\[
k_{n_i}=\frac{2\pi n_i}{L} \hspace{0.1cm} n_i = 0, \pm 1, \pm 2, \dots, 
\]
we can set up a similar table and obtain (assuming identical particles one and including spin up and spin down solutions)  for energies less than or equal to $n_{x}^{2}+n_{y}^{2}+n_{z}^{2}\le 3$


\begin{center}
\begin{tabular}{ccccc}
\hline
\multicolumn{1}{c}{ $n_{x}^{2}+n_{y}^{2}+n_{z}^{2}$ } & \multicolumn{1}{c}{ $n_{x}$ } & \multicolumn{1}{c}{ $n_{y}$ } & \multicolumn{1}{c}{ $n_{z}$ } & \multicolumn{1}{c}{ $N_{\uparrow \downarrow }$ } \\
\hline
0                               & 0       & 0       & 0       & 2                          \\
\hline
1                               & -1      & 0       & 0       &                            \\
1                               & 1       & 0       & 0       &                            \\
1                               & 0       & -1      & 0       &                            \\
1                               & 0       & 1       & 0       &                            \\
1                               & 0       & 0       & -1      &                            \\
1                               & 0       & 0       & 1       & 14                         \\
\hline
2                               & -1      & -1      & 0       &                            \\
2                               & -1      & 1       & 0       &                            \\
2                               & 1       & -1      & 0       &                            \\
2                               & 1       & 1       & 0       &                            \\
2                               & -1      & 0       & -1      &                            \\
2                               & -1      & 0       & 1       &                            \\
2                               & 1       & 0       & -1      &                            \\
2                               & 1       & 0       & 1       &                            \\
2                               & 0       & -1      & -1      &                            \\
2                               & 0       & -1      & 1       &                            \\
2                               & 0       & 1       & -1      &                            \\
2                               & 0       & 1       & 1       & 38                         \\
\hline
3                               & -1      & -1      & -1      &                            \\
3                               & -1      & -1      & 1       &                            \\
3                               & -1      & 1       & -1      &                            \\
3                               & -1      & 1       & 1       &                            \\
3                               & 1       & -1      & -1      &                            \\
3                               & 1       & -1      & 1       &                            \\
3                               & 1       & 1       & -1      &                            \\
3                               & 1       & 1       & 1       & 54                         \\
\hline
\end{tabular}
\end{center}


Continuing in this way we get for $n_{x}^{2}+n_{y}^{2}+n_{z}^{2}=4$ a
total of 22 additional states, resulting in $76$ as a new magic
number. For the lowest six energy values the degeneracy in energy
gives us $2$, $14$, $38$, $54$, $76$ and $114$ as magic numbers. These
numbers will then define our Fermi level when we compute the energy in
a Cartesian basis. When performing calculations based on many-body
perturbation theory, Coupled cluster theory or other many-body
methods, we need then to add states above the Fermi level in order to
sum over single-particle states which are not occupied.

If we wish to study infinite nuclear matter with both protons and
neutrons, the above magic numbers become $4, 28, 76, 108, 132, 228, \dots$.

Every number of particles for filled shells defines also the number of
particles to be used in a given calculation. The number of
particles can in turn be used to define the density of the system via
\[
\rho = g \frac{k_F^3}{6\pi^2},
\]
where we need to define $k_F$ and the degeneracy $g$, which is two
for one type of spin-$1/2$ particles and four for symmetric nuclear
matter.  With the density defined, having fixed the number of particles $A$ and the Fermi momentum $k_F$,
we can define the length $L$ of the box used with periodic
boundary contributions via the relation
\[
  V= L^3= \frac{A}{\rho}.
\]
We can then  can use $L$ to define the spacing between
various $k$-values, that is
\[
  \Delta k = \frac{2\pi}{L}.
\]
Here, $A$ can be the number of nucleons. If we deal with the electron
gas only, this needs to be replaced by the number of electrons $N$.


\subsection{Two-body interaction}

As mentioned above, we will employ a plane wave basis
for our calculations of infinite matter properties. With a cartesian
basis it means that we can calculate directly the various matrix
elements, as discussed in the previous subsection. However, a
cartesian basis represents an approximation to the thermodynamical limit. In
order to compare the stability of our basis with results from the
thermodynamical limit, it is convenient to rewrite the nucleon-nucleon
interaction in terms of a partial wave expansion. This will allow us
to compute the Hartree-Fock energy of the ground state in the
thermodynamical limit (with the caveat that we need to limit the
number of partial waves). In order to find the expressions for the
Hartree-Fock energy in a partial wave basis, we will find it
convenient to rewrite our two-body force in terms of the relative and
center-of-mass motion momenta.

The direct matrix element, with single-particle three-dimensional
momenta $\mathbf{k}_i$, spin $\sigma_i$ and isospin $\tau_i$, is
defined as
\[
\langle \mathbf{k}_a\sigma_a\tau_a \mathbf{k}_b\sigma_b\tau_b \vert \hat{v}\vert \mathbf{k}_c\sigma_c\tau_c \mathbf{k}_d\sigma_d\tau_d \rangle, 
\]
or in a more compact form as
$\langle \mathbf{a}\mathbf{b}\vert \hat{v} \vert \mathbf{c}\mathbf{d} \rangle$
where the boldfaced letters $\mathbf{a}$ etc represent the relevant
quantum numbers, here momentum, spin and isospin. Introducing the
relative momentum
\[
\mathbf{k} = \frac{1}{2}\left(\mathbf{k}_a-\mathbf{k}_b\right), 
\]
and the center-of-mass momentum
\[
\mathbf{K} = \mathbf{k}_a+\mathbf{k}_b,
\]
we have 
\[
\langle \mathbf{k}_a\sigma_a\tau_a \mathbf{k}_b\sigma_b\tau_b \vert \hat{v}\vert \mathbf{k}_c\sigma_c\tau_c \mathbf{k}_d\sigma_d\tau_d \rangle=\langle \mathbf{k}\mathbf{K}\sigma_a\tau_a \sigma_b\tau_b \vert \hat{v}\vert \mathbf{k}'\mathbf{K}'\sigma_c\tau_c \sigma_d\tau_d \rangle.
\]
The nucleon-nucleon interaction conserves the total momentum and is
charge invariant, implying that the above uncoupled matrix element reads
\[
\langle \mathbf{k}\mathbf{K}\sigma_a\tau_a \sigma_b\tau_b \vert \hat{v}\vert \mathbf{k}'\mathbf{K}'\sigma_c\tau_c \sigma_d\tau_d \rangle=\delta_{T_z,T_z'}\delta(\mathbf{K}-\mathbf{K}')\langle \mathbf{k}T_zS_z=(\sigma_a+\sigma_b) \vert \hat{v}\vert \mathbf{k}'T_zS_z'=(\sigma_c+\sigma_d) \rangle,
\]
where we have defined the isospin projections $T_z=\tau_a+\tau_b$ and
$T_z'=\tau_c+\tau_d$.  Defining
$\hat{v}=\hat{v}(\mathbf{k},\mathbf{k}' )$, we can rewrite the
previous equation in a more compact form as
\[
\delta_{T_z,T_z'}\delta(\mathbf{K}-\mathbf{K}')\langle \mathbf{k}T_zS_z=(\sigma_a+\sigma_b) \vert \hat{v}\vert \mathbf{k}'T_zS_z'=(\sigma_c+\sigma_d) \rangle=\delta_{T_z,T_z'}\delta(\mathbf{K}-\mathbf{K}')\langle T_zS_z\vert\hat{v}(\mathbf{k},\mathbf{k}' ) \vert T_zS_z' \rangle.
\]
These matrix elements can in turn be rewritten in terms of the total
two-body quantum numbers for the spin $S$ of two spin-1/2 fermions as
\[
\langle \mathbf{k}T_zS_z \vert \hat{v}(\mathbf{k},\mathbf{k}' )\vert \mathbf{k}'T_zS_z' \rangle=\sum_{SS'}\langle \frac{1}{2}\sigma_a\frac{1}{2}\sigma_b\vert SS_z\rangle \langle \frac{1}{2}\sigma_c\frac{1}{2}\sigma_d\vert S'S_z'\rangle \langle \mathbf{k}T_zSS_z\vert \hat{v}(\mathbf{k},\mathbf{k}' )\vert \mathbf{k}T_zS'S_z' \rangle
\]
The coefficients $\langle \frac{1}{2}\sigma_a\frac{1}{2}\sigma_b\vert
SS_z\rangle$ are so-called Clebsch-Gordan recoupling coefficients.  We
will assume that our interactions break charge and isospin
symmetry. We will refer to $T_z=0$ as the $pn$ (proton-neutron)
channel, $T_z=-1$ as the $pp$ (proton-proton) channel and $T_z=1$ as
the $nn$ (neutron-neutron) channel.

The nucleon-nucleon force is often derived and analyzed theoretically
in terms of a partial wave expansion. A state with linear momentum
$\mathbf{k}$ can be written as
\[
\vert \mathbf{k} \rangle = \sum_{l=0}^{\infty}\sum_{l_l=-l}^{L}\imath^lY_{l}^{m_l}(\hat{k}\vert klm_l\rangle.
\]

In terms of the relative and center-of-mass momenta $\mathbf{k}$ and
$\mathbf{K}$, the potential in momentum space is related to the nonlocal operator
$V(\mathbf{r},\mathbf{r}')$ by
\begin{equation}
      \langle \mathbf{k'K'}\vert \hat{v} \vert \mathbf{k'K} \rangle=
       \int d\mathbf{r}d \mathbf{r'}
        e^{-\imath \mathbf{k'r'}}V(\mathbf{r'},\mathbf{r}) e^{\imath \mathbf{kr}}
       \delta(\mathbf{K},\mathbf{K'}).
\end{equation}
We will assume that the interaction is spherically symmetric and use
the partial wave expansion of the plane waves in
terms of spherical harmonics.
This means that we can separate the radial part of the wave function from its
angular dependence. The wave function of the relative motion is described
in terms of plane waves as
\begin{equation}
       e^{\imath \mathbf{kr}}  =
       \langle\mathbf{r}\vert \mathbf{k}\rangle =  4\pi \sum_{lm} \imath ^{l}
        j_{l} (kr) Y_{lm}^{*}(\mathbf{\hat{k}}) Y_{lm}(\mathbf{\hat{r}}),
\end{equation}
where $j_l$ is a spherical Bessel function and $Y_{lm}$ the
spherical harmonic.
This partial wave basis is useful for defining the operator for
the nucleon-nucleon interaction, which
is symmetric with respect to rotations, parity and
isospin transformations. These symmetries imply that the interaction is
diagonal with respect to the quantum numbers of total angular
momentum $J$, spin $S$ and isospin $T$. Using the above plane wave expansion,
and coupling to final $J$, $S$ and $T$ we get
\begin{equation}
      \langle \mathbf{k'}\vert V \vert \mathbf{k}\rangle
       = (4\pi)^2 \sum_{JM}\sum_{lm}\sum_{l'm'}
      \imath ^{l+l'} Y_{lm}^{*}(\mathbf{\hat{k}}) Y_{l'm'}(\mathbf{\hat{k}'})
      {\cal C}_{m'M_SM}^{l'SJ}{\cal C}_{mM_SM}^{lSJ}
      \langle k'l'STJM \vert V \vert klSTJM \rangle,
\label{eq:vpartial}
\end{equation}
where we have defined
\begin{equation}
    \langle k'l'STJM\vert V \vert klSTJM\rangle =
    \int   j_{l'}(k'r')\langle l'STJM\vert V(r',r)\vert lSTJM \rangle j_l(kr) {r'}^2 dr' r^2 dr.
\end{equation}
We have omitted the momentum of the center-of-mass motion $\mathbf{K}$ and the 
corresponding orbital momentum $L$, since the interaction is diagonal
in these variables. The potentials we will employ in this work, like
those of the Bonn group, are all non-local potentials defined in 
momentum space, and we will therefore not need the last equation.


The interaction we will use for these calculations is a semirealistic nucleon-nucleon potential known as the Minnesota potential which has the form, $V_{\alpha}\left( r\right)=V_{\alpha}e^{-\alpha r^{2}}$. The spin and isospin dependence of the Minnesota potential is given by,
\begin{equation}
V\left( r\right)=\frac{1}{2}\left( V_{R}+\frac{1}{2}\left( 1+P_{12}^{\sigma}\right) V_{T}+\frac{1}{2}\left( 1-P_{12}^{\sigma}\right) V_{S}\right)\left( 1-P_{12}^{\sigma}P_{12}^{\tau}\right),
\end{equation}
where $P_{12}^{\sigma}=\frac{1}{2}\left( 1+\sigma_{1}\cdot\sigma_{2}\right)$ and $P_{12}^{\tau}=\frac{1}{2}\left( 1+\tau_{1}\cdot\tau_{2}\right)$ are the spin and isospin exchange operators, respectively. When this potential is integrated over space, the result depends only on the magnitude of the momentum transfer, $\vec{q}=\frac{1}{2}\left(\vec{k}_{p}-\vec{k}_{q}-\vec{k}_{r}+\vec{k}_{s}\right)$, as well as the spin and isospin dependencies,
\begin{equation}
\braket{pq| V_{\alpha} |rs}=\frac{V_{\alpha}}{L^{3}}\left(\frac{\pi}{\alpha}\right)^{3/2}e^{\frac{-q^{2}}{4\alpha}}\delta_{\vec{k}_{p}+\vec{k}_{q},\vec{k}_{r}+\vec{k}_{s}}
\end{equation}
\begin{center}
  \begin{tabular}{| l | l | l |}
    \hline
    $\alpha$ & $V_{\alpha}$ & $\kappa_{\alpha}$ \\ \hline
    $R$ & 200 $\mathrm{MeV}$ & 1.487 $\mathrm{fm}^{-2}$ \\ \hline
    $T$ & 178 $\mathrm{MeV}$ & 0.639 $\mathrm{fm}^{-2}$ \\ \hline
    $S$ & 91.85 $\mathrm{MeV}$ & 0.465 $\mathrm{fm}^{-2}$ \\ \hline
  \end{tabular}
\end{center}





\section{Hartree-Fock theory}

Hartree-Fock (HF) theory is an algorithm for finding an approximative
expression for the ground state of a given Hamiltonian. The basic
ingredients are Define a single-particle basis $\{\psi_{\alpha}\}$ so
that
\[ 
\hat{h}^{\mathrm{HF}}\psi_{\alpha} = \varepsilon_{\alpha}\psi_{\alpha}
\]
with the Hartree-Fock Hamiltonian defined as
\[
\hat{h}^{\mathrm{HF}}=\hat{t}+\hat{u}_{\mathrm{ext}}+\hat{u}^{\mathrm{HF}}
\]

The term $\hat{u}^{\mathrm{HF}}$ is a single-particle potential to be
determined by the HF algorithm.

The HF algorithm means to choose $\hat{u}^{\mathrm{HF}}$ in order to
have
\[ \langle \hat{H} \rangle = E^{\mathrm{HF}}= \langle \Phi_0 | \hat{H}|\Phi_0 \rangle
\]
that is to find a local minimum with a Slater determinant $\Phi_0$
being the ansatz for the ground state.  The variational principle
ensures that $E^{\mathrm{HF}} \ge E_0$, with $E_0$ the exact ground
state energy.

We will show that the Hartree-Fock Hamiltonian $\hat{h}^{\mathrm{HF}}$
equals our definition of the operator $\hat{f}$ discussed in
connection with the new definition of the normal-ordered Hamiltonian
(see later lectures), that is we have, for a specific matrix element
\[
\langle p |\hat{h}^{\mathrm{HF}}| q \rangle =\langle p |\hat{f}| q \rangle=\langle p|\hat{t}+\hat{u}_{\mathrm{ext}}|q \rangle +\sum_{i\le F} \langle pi | \hat{V} | qi\rangle_{AS},
\]
meaning that
\[
\langle p|\hat{u}^{\mathrm{HF}}|q\rangle = \sum_{i\le F} \langle pi | \hat{V} | qi\rangle_{AS}.
\]
The so-called Hartree-Fock potential $\hat{u}^{\mathrm{HF}}$ brings an
explicit medium dependence due to the summation over all
single-particle states below the Fermi level $F$. It brings also in an
explicit dependence on the two-body interaction (in nuclear physics we
can also have complicated three- or higher-body forces). The two-body
interaction, with its contribution from the other bystanding fermions,
creates an effective mean field in which a given fermion moves, in
addition to the external potential $\hat{u}_{\mathrm{ext}}$ which
confines the motion of the fermion. For systems like nuclei, there is
no external confining potential. Nuclei are examples of self-bound
systems, where the binding arises due to the intrinsic nature of the
strong force. For nuclear systems thus, there would be no external
one-body potential in the Hartree-Fock Hamiltonian.


Another possibility is to expand the single-particle functions in a
known basis and vary the coefficients, that is, the new
single-particle wave function is written as a linear expansion in
terms of a fixed chosen orthogonal basis (for example the well-known
harmonic oscillator functions or the hydrogen-like functions etc).  We
define our new Hartree-Fock single-particle basis by performing a
unitary transformation on our previous basis (labelled with greek
indices) as
\begin{equation}
\psi_p^{HF}  = \sum_{\lambda} C_{p\lambda}\phi_{\lambda}. \label{eq:newbasis}
\end{equation}
In this case we vary the coefficients $C_{p\lambda}$. If the basis has
infinitely many solutions, we need to truncate the above sum.  We
assume that the basis $\phi_{\lambda}$ is orthogonal. A unitary
transformation keeps the orthogonality, as discussed in exercise 1
below.




It is normal to choose a single-particle basis defined as the
eigenfunctions of parts of the full Hamiltonian. The typical situation
consists of the solutions of the one-body part of the Hamiltonian,
that is we have
\[
\hat{h}_0\phi_{\lambda}=\epsilon_{\lambda}\phi_{\lambda}.
\]
The single-particle wave functions $\phi_{\lambda}({\bf r})$, defined
by the quantum numbers $\lambda$ and ${\bf r}$ are defined as the
overlap
\[
   \phi_{\lambda}({\bf r})  = \langle {\bf r} | \lambda \rangle .
\]




In our discussions hereafter we will use our definitions of
single-particle states above and below the Fermi ($F$) level given by
the labels $ijkl\dots \le F$ for so-called single-hole states and
$abcd\dots > F$ for so-called particle states.  For general
single-particle states we employ the labels $pqrs\dots$.





\[
  E[\Phi] = \sum_{\mu=1}^A \langle \mu | h | \mu \rangle
  + \frac{1}{2}\sum_{{\mu}=1}^A\sum_{{\nu}=1}^A \langle \mu\nu|\hat{v}|\mu\nu\rangle_{AS},
\]
we found the expression for the energy functional in terms of the
basis function $\phi_{\lambda}({\bf r})$. We then varied the above
energy functional with respect to the basis functions $|\mu \rangle$.
Now we are interested in defining a new basis defined in terms of a
chosen basis as defined in Eq.~(ref{eq:newbasis}). We can then rewrite
the energy functional as
\begin{equation}
  E[\Phi^{HF}] 
  = \sum_{i=1}^A \langle i | h | i \rangle +
  \frac{1}{2}\sum_{ij=1}^A\langle ij|\hat{v}|ij\rangle_{AS}, \label{FunctionalEPhi2}
\end{equation}
where $\Phi^{HF}$ is the new Slater determinant defined by the new
basis of Eq.~(ref{eq:newbasis}).





Using Eq.~(\ref{eq:newbasis}) we can rewrite
Eq.~(\ref{FunctionalEPhi2}) as
\begin{equation}
  E[\Psi] 
  = \sum_{i=1}^A \sum_{\alpha\beta} C^*_{i\alpha}C_{i\beta}\langle \alpha | h | \beta \rangle +
  \frac{1}{2}\sum_{ij=1}^A\sum_{{\alpha\beta\gamma\delta}} C^*_{i\alpha}C^*_{j\beta}C_{i\gamma}C_{j\delta}\langle \alpha\beta|\hat{v}|\gamma\delta\rangle_{AS}. \label{FunctionalEPhi3}
\end{equation}


We wish now to minimize the above functional. We introduce again a set
of Lagrange multipliers, noting that since $\langle i | j \rangle
= \delta_{i,j}$ and $\langle \alpha | \beta \rangle
= \delta_{\alpha,\beta}$, the coefficients $C_{i\gamma}$ obey the
relation
\[
 \langle i | j \rangle=\delta_{i,j}=\sum_{\alpha\beta} C^*_{i\alpha}C_{i\beta}\langle \alpha | \beta \rangle=
\sum_{\alpha} C^*_{i\alpha}C_{i\alpha},
\]
which allows us to define a functional to be minimized that reads
\begin{equation}
  F[\Phi^{HF}]=E[\Phi^{HF}] - \sum_{i=1}^A\epsilon_i\sum_{\alpha} C^*_{i\alpha}C_{i\alpha}.
\end{equation}







Minimizing with respect to $C^*_{i\alpha}$, remembering that the
equations for $C^*_{i\alpha}$ and $C_{i\alpha}$ can be written as two
independent equations, we obtain
\[
\frac{d}{dC^*_{i\alpha}}\left[  E[\Phi^{HF}] - \sum_{j}\epsilon_j\sum_{\alpha} C^*_{j\alpha}C_{j\alpha}\right]=0,
\]
which yields for every single-particle state $i$ and index $\alpha$
(recalling that the coefficients $C_{i\alpha}$ are matrix elements of
a unitary (or orthogonal for a real symmetric matrix) matrix) the
following Hartree-Fock equations
\[
\sum_{\beta} C_{i\beta}\langle \alpha | h | \beta \rangle+
\sum_{j=1}^A\sum_{\beta\gamma\delta} C^*_{j\beta}C_{j\delta}C_{i\gamma}\langle \alpha\beta|\hat{v}|\gamma\delta\rangle_{AS}=\epsilon_i^{HF}C_{i\alpha}.
\]


We can rewrite this equation as (changing dummy variables)
\[
\sum_{\beta} \left\{\langle \alpha | h | \beta \rangle+
\sum_{j}^A\sum_{\gamma\delta} C^*_{j\gamma}C_{j\delta}\langle \alpha\gamma|\hat{v}|\beta\delta\rangle_{AS}\right\}C_{i\beta}=\epsilon_i^{HF}C_{i\alpha}.
\]
Note that the sums over greek indices run over the number of basis set
functions (in principle an infinite number).





Defining 
\[
h_{\alpha\beta}^{HF}=\langle \alpha | h | \beta \rangle+
\sum_{j=1}^A\sum_{\gamma\delta} C^*_{j\gamma}C_{j\delta}\langle \alpha\gamma|\hat{v}|\beta\delta\rangle_{AS},
\]
we can rewrite the new equations as 
\begin{equation}
\sum_{\gamma}h_{\alpha\beta}^{HF}C_{i\beta}=\epsilon_i^{HF}C_{i\alpha}. \label{eq:newhf}
\end{equation}
The latter is nothing but a standard eigenvalue problem. Compared with
Eq.~(ref{eq:hartreefockcoordinatespace}), we see that we do not need
to compute any integrals in an iterative procedure for solving the
equations.  It suffices to tabulate the matrix elements
$\langle \alpha | h | \beta \rangle$ and
$\langle \alpha\gamma|\hat{v}|\beta\delta\rangle_{AS}$ once and for
all. Successive iterations require thus only a look-up in tables over
one-body and two-body matrix elements. These details will be discussed
below when we solve the Hartree-Fock equations numerical.


Our Hartree-Fock matrix is thus
\[
\hat{h}_{\alpha\beta}^{HF}=\langle \alpha | \hat{h}_0 | \beta \rangle+
\sum_{j=1}^A\sum_{\gamma\delta} C^*_{j\gamma}C_{j\delta}\langle \alpha\gamma|\hat{v}|\beta\delta\rangle_{AS}.
\]
The Hartree-Fock equations are solved in an iterative waym starting
with a guess for the coefficients $C_{j\gamma}=\delta_{j,\gamma}$ and
solving the equations by diagonalization till the new single-particle
energies $\epsilon_i^{\mathrm{HF}}$ do not change anymore by a
prefixed quantity.




Normally we assume that the single-particle basis $|\beta\rangle$
forms an eigenbasis for the operator $\hat{h}_0$, meaning that the
Hartree-Fock matrix becomes
\[
\hat{h}_{\alpha\beta}^{HF}=\epsilon_{\alpha}\delta_{\alpha,\beta}+
\sum_{j=1}^A\sum_{\gamma\delta} C^*_{j\gamma}C_{j\delta}\langle \alpha\gamma|\hat{v}|\beta\delta\rangle_{AS}.
\]
The Hartree-Fock eigenvalue problem
\[
\sum_{\beta}\hat{h}_{\alpha\beta}^{HF}C_{i\beta}=\epsilon_i^{\mathrm{HF}}C_{i\alpha},
\]
can be written out in a more compact form as
\[
\hat{h}^{HF}\hat{C}=\epsilon^{\mathrm{HF}}\hat{C}. 
\]




The Hartree-Fock equations are, in their simplest form, solved in an
iterative way, starting with a guess for the coefficients
$C_{i\alpha}$. We label the coefficients as $C_{i\alpha}^{(n)}$, where
the subscript $n$ stands for iteration $n$.  To set up the algorithm
we can proceed as follows:

We start with a guess
$C_{i\alpha}^{(0)}=\delta_{i,\alpha}$. Alternatively, we could have
used random starting values as long as the vectors are
normalized. Another possibility is to give states below the Fermi
level a larger weight.  The Hartree-Fock matrix simplifies then to
(assuming that the coefficients $C_{i\alpha} $ are real)
\[
\hat{h}_{\alpha\beta}^{HF}=\epsilon_{\alpha}\delta_{\alpha,\beta}+
\sum_{j = 1}^A\sum_{\gamma\delta} C_{j\gamma}^{(0)}C_{j\delta}^{(0)}\langle \alpha\gamma|\hat{v}|\beta\delta\rangle_{AS}.
\]




Solving the Hartree-Fock eigenvalue problem yields then new
eigenvectors $C_{i\alpha}^{(1)}$ and eigenvalues $\epsilon_i^{HF(1)}$.
With the new eigenvalues we can set up a new Hartree-Fock potential
\[
\sum_{j = 1}^A\sum_{\gamma\delta} C_{j\gamma}^{(1)}C_{j\delta}^{(1)}\langle \alpha\gamma|\hat{v}|\beta\delta\rangle_{AS}.
\]
The diagonalization with the new Hartree-Fock potential yields new
eigenvectors and eigenvalues.  This process is continued till for
example
\[
\frac{\sum_{p} |\epsilon_i^{(n)}-\epsilon_i^{(n-1)}|}{m} \le \lambda,  
\]
where $\lambda$ is a user prefixed quantity ($\lambda \sim 10^{-8}$ or
smaller) and $p$ runs over all calculated single-particle energies and
$m$ is the number of single-particle states.


We can rewrite the ground state energy by adding and subtracting
$\hat{u}^{HF}(x_i)$
\[
  E_0^{HF} =\langle \Phi_0 | \hat{H} | \Phi_0\rangle = 
\sum_{i\le F}^A \langle i | \hat{h}_0 +\hat{u}^{HF}| j\rangle+ \frac{1}{2}\sum_{i\le F}^A\sum_{j \le F}^A\left[\langle ij |\hat{v}|ij \rangle-\langle ij|\hat{v}|ji\rangle\right]-\sum_{i\le F}^A \langle i |\hat{u}^{HF}| i\rangle,
\]
which results in
\[
  E_0^{HF}
  = \sum_{i\le F}^A \varepsilon_i^{HF} + \frac{1}{2}\sum_{i\le F}^A\sum_{j \le F}^A\left[\langle ij |\hat{v}|ij \rangle-\langle ij|\hat{v}|ji\rangle\right]-\sum_{i\le F}^A \langle i |\hat{u}^{HF}| i\rangle.
\]
Our single-particle states $ijk\dots$ are now single-particle states
obtained from the solution of the Hartree-Fock equations.



Using our definition of the Hartree-Fock single-particle energies we
obtain then the following expression for the total ground-state energy
\[
  E_0^{HF}
  = \sum_{i\le F}^A \varepsilon_i - \frac{1}{2}\sum_{i\le F}^A\sum_{j \le F}^A\left[\langle ij |\hat{v}|ij \rangle-\langle ij|\hat{v}|ji\rangle\right].
\]


\section{Full Configuration Interaction Theory}

We have defined the ansatz for the ground state as 
\[
|\Phi_0\rangle = \left(\prod_{i\le F}\hat{a}_{i}^{\dagger}\right)|0\rangle,
\]
where the index $i$ defines different single-particle states up to the Fermi level. We have assumed that we have $N$ fermions. 
A given one-particle-one-hole ($1p1h$) state can be written as
\[
|\Phi_i^a\rangle = \hat{a}_{a}^{\dagger}\hat{a}_i|\Phi_0\rangle,
\]
while a $2p2h$ state can be written as
\[
|\Phi_{ij}^{ab}\rangle = \hat{a}_{a}^{\dagger}\hat{a}_{b}^{\dagger}\hat{a}_j\hat{a}_i|\Phi_0\rangle,
\]
and a general $ApAh$ state as 
\[
|\Phi_{ijk\dots}^{abc\dots}\rangle = \hat{a}_{a}^{\dagger}\hat{a}_{b}^{\dagger}\hat{a}_{c}^{\dagger}\dots\hat{a}_k\hat{a}_j\hat{a}_i|\Phi_0\rangle.
\]

We use letters $ijkl\dots$ for states below the Fermi level and $abcd\dots$ for states above the Fermi level. A general single-particle state is given by letters $pqrs\dots$.

We can then expand our exact state function for the ground state 
as
\[
|\Psi_0\rangle=C_0|\Phi_0\rangle+\sum_{ai}C_i^a|\Phi_i^a\rangle+\sum_{abij}C_{ij}^{ab}|\Phi_{ij}^{ab}\rangle+\dots
=(C_0+\hat{C})|\Phi_0\rangle,
\]
where we have introduced the so-called correlation operator 
\[
\hat{C}=\sum_{ai}C_i^a\hat{a}_{a}^{\dagger}\hat{a}_i  +\sum_{abij}C_{ij}^{ab}\hat{a}_{a}^{\dagger}\hat{a}_{b}^{\dagger}\hat{a}_j\hat{a}_i+\dots
\]
Since the normalization of $\Psi_0$ is at our disposal and since $C_0$ is by hypothesis non-zero, we may arbitrarily set $C_0=1$ with 
corresponding proportional changes in all other coefficients. Using this so-called intermediate normalization we have
\[
\langle \Psi_0 | \Phi_0 \rangle = \langle \Phi_0 | \Phi_0 \rangle = 1, 
\]
resulting in 
\[
|\Psi_0\rangle=(1+\hat{C})|\Phi_0\rangle.
\]


We rewrite 
\[
|\Psi_0\rangle=C_0|\Phi_0\rangle+\sum_{ai}C_i^a|\Phi_i^a\rangle+\sum_{abij}C_{ij}^{ab}|\Phi_{ij}^{ab}\rangle+\dots,
\]
in a more compact form as 
\[
|\Psi_0\rangle=\sum_{PH}C_H^P\Phi_H^P=\left(\sum_{PH}C_H^P\hat{A}_H^P\right)|\Phi_0\rangle,
\]
where $H$ stands for $0,1,\dots,n$ hole states and $P$ for $0,1,\dots,n$ particle states. 
Our requirement of unit normalization gives
\[
\langle \Psi_0 | \Psi_0 \rangle = \sum_{PH}|C_H^P|^2= 1,
\]
and the energy can be written as 
\[
E= \langle \Psi_0 | \hat{H} |\Psi_0 \rangle= \sum_{PP'HH'}C_H^{*P}\langle \Phi_H^P | \hat{H} |\Phi_{H'}^{P'} \rangle C_{H'}^{P'}.
\]


Normally 
\[
E= \langle \Psi_0 | \hat{H} |\Psi_0 \rangle= \sum_{PP'HH'}C_H^{*P}\langle \Phi_H^P | \hat{H} |\Phi_{H'}^{P'} \rangle C_{H'}^{P'},
\]
is solved by diagonalization setting up the Hamiltonian matrix defined by the basis of all possible Slater determinants. A diagonalization
is equivalent to finding the variational minimum   of 
\[
 \langle \Psi_0 | \hat{H} |\Psi_0 \rangle-\lambda \langle \Psi_0 |\Psi_0 \rangle,
\]
where $\lambda$ is a variational multiplier to be identified with the energy of the system.

The minimization process results in 
\[
\delta\left[ \langle \Psi_0 | \hat{H} |\Psi_0 \rangle-\lambda \langle \Psi_0 |\Psi_0 \rangle\right]=
\]
\[
\sum_{P'H'}\left\{\delta[C_H^{*P}]\langle \Phi_H^P | \hat{H} |\Phi_{H'}^{P'} \rangle C_{H'}^{P'}+
C_H^{*P}\langle \Phi_H^P | \hat{H} |\Phi_{H'}^{P'} \rangle \delta[C_{H'}^{P'}]-
\lambda( \delta[C_H^{*P}]C_{H'}^{P'}+C_H^{*P}\delta[C_{H'}^{P'}]\right\} = 0.
\]
Since the coefficients $\delta[C_H^{*P}]$ and $\delta[C_{H'}^{P'}]$ are complex conjugates it is necessary and sufficient to require the quantities that multiply with $\delta[C_H^{*P}]$ to vanish.  

This leads to 
\[
\sum_{P'H'}\langle \Phi_H^P | \hat{H} |\Phi_{H'}^{P'} \rangle C_{H'}^{P'}-\lambda C_H^{P}=0,
\]
for all sets of $P$ and $H$.

If we then multiply by the corresponding $C_H^{*P}$ and sum over $PH$ we obtain
\[ 
\sum_{PP'HH'}C_H^{*P}\langle \Phi_H^P | \hat{H} |\Phi_{H'}^{P'} \rangle C_{H'}^{P'}-\lambda\sum_{PH}|C_H^P|^2=0,
\]
leading to the identification $\lambda = E$. This means that we have for all $PH$ sets
\begin{equation}
\sum_{P'H'}\langle \Phi_H^P | \hat{H} -E|\Phi_{H'}^{P'} \rangle = 0. \label{eq:fullci}
\end{equation}



An alternative way to derive the last equation is to start from 
\[
(\hat{H} -E)|\Psi_0\rangle = (\hat{H} -E)\sum_{P'H'}C_{H'}^{P'}|\Phi_{H'}^{P'} \rangle=0, 
\]
and if this equation is successively projected against all $\Phi_H^P$ in the expansion of $\Psi$, we end up with Eq.~(\ref{eq:fullci}).

One solves this equation normally by diagonalization. If we are able to solve this equation exactly (that is
numerically exactly) in a large Hilbert space (it will be truncated in terms of the number of single-particle states included in the definition
of Slater determinants), it can then serve as a benchmark for other many-body methods which approximate the correlation operator
$\hat{C}$.  


\subsection{Example of a Hamiltonian matrix}

Suppose, as an example, that we have six fermions below the Fermi level.
This means that we can make at most $6p-6h$ excitations. If we have an infinity of single particle states above the Fermi level, we will obviously have an infinity of say $2p-2h$ excitations. Each such way to configure the particles is called a \textbf{configuration}. We will always have to truncate in the basis of single-particle states.
This gives us a finite number of possible Slater determinants. Our Hamiltonian matrix would then look like (where each block can have a large dimensionalities):

\begin{table}
\begin{center}
\begin{tabular}{cccccccc}
\hline
\multicolumn{1}{c}{  } & \multicolumn{1}{c}{ $0p-0h$ } & \multicolumn{1}{c}{ $1p-1h$ } & \multicolumn{1}{c}{ $2p-2h$ } & \multicolumn{1}{c}{ $3p-3h$ } & \multicolumn{1}{c}{ $4p-4h$ } & \multicolumn{1}{c}{ $5p-5h$ } & \multicolumn{1}{c}{ $6p-6h$ } \\
\hline
$0p-0h$ & x       & x       & x       & 0       & 0       & 0       & 0       \\
$1p-1h$ & x       & x       & x       & x       & 0       & 0       & 0       \\
$2p-2h$ & x       & x       & x       & x       & x       & 0       & 0       \\
$3p-3h$ & 0       & x       & x       & x       & x       & x       & 0       \\
$4p-4h$ & 0       & 0       & x       & x       & x       & x       & x       \\
$5p-5h$ & 0       & 0       & 0       & x       & x       & x       & x       \\
$6p-6h$ & 0       & 0       & 0       & 0       & x       & x       & x       \\
\hline
\end{tabular}
\end{center}
\end{table}
with a two-body force. Why are there non-zero blocks of elements? 
If we use a Hartree-Fock basis, this corresponds to a particular unitary transformation where matrix elements of the type $\langle 0p-0h \vert \hat{H} \vert 1p-1h\rangle =\langle \Phi_0 | \hat{H}|\Phi_{i}^{a}\rangle=0$ and our Hamiltonian matrix becomes 

\begin{table}
\begin{center}
\begin{tabular}{cccccccc}
\hline
\multicolumn{1}{c}{  } & \multicolumn{1}{c}{ $0p-0h$ } & \multicolumn{1}{c}{ $1p-1h$ } & \multicolumn{1}{c}{ $2p-2h$ } & \multicolumn{1}{c}{ $3p-3h$ } & \multicolumn{1}{c}{ $4p-4h$ } & \multicolumn{1}{c}{ $5p-5h$ } & \multicolumn{1}{c}{ $6p-6h$ } \\
\hline
$0p-0h$ & $\tilde{x}$ & 0           & $\tilde{x}$ & 0           & 0           & 0           & 0           \\
$1p-1h$ & 0           & $\tilde{x}$ & $\tilde{x}$ & $\tilde{x}$ & 0           & 0           & 0           \\
$2p-2h$ & $\tilde{x}$ & $\tilde{x}$ & $\tilde{x}$ & $\tilde{x}$ & $\tilde{x}$ & 0           & 0           \\
$3p-3h$ & 0           & $\tilde{x}$ & $\tilde{x}$ & $\tilde{x}$ & $\tilde{x}$ & $\tilde{x}$ & 0           \\
$4p-4h$ & 0           & 0           & $\tilde{x}$ & $\tilde{x}$ & $\tilde{x}$ & $\tilde{x}$ & $\tilde{x}$ \\
$5p-5h$ & 0           & 0           & 0           & $\tilde{x}$ & $\tilde{x}$ & $\tilde{x}$ & $\tilde{x}$ \\
$6p-6h$ & 0           & 0           & 0           & 0           & $\tilde{x}$ & $\tilde{x}$ & $\tilde{x}$ \\
\hline
\end{tabular}
\end{center}
\end{table}
If we do not make any truncations in the possible sets of Slater determinants (many-body states) we can make by distributing $A$ nucleons among $n$ single-particle states, we call such a calculation for 
\begin{itemize}
\item Full configuration interaction theory
\end{itemize}

\noindent
If we make truncations, we have different possibilities

\begin{itemize}
\item The standard nuclear shell-model. Here we define an effective Hilbert space with respect to a given core. The calculations are normally then performed for all many-body states that can be constructed from the effective Hilbert spaces. This approach requires a properly defined effective Hamiltonian

\item We can truncate in the number of excitations. For example, we can limit the possible Slater determinants to only $1p-1h$ and $2p-2h$ excitations. This is called a configuration interaction calculation at the level of singles and doubles excitations, or just CISD. 

\item We can limit the number of excitations in terms of the excitation energies. If we do not define a core, this defines normally what is called the no-core shell-model approach. 
\end{itemize}

\noindent
What happens if we have a three-body interaction and a Hartree-Fock basis? 

Full configuration interaction theory calculations provide in principle, if we can diagonalize numerically, all states of interest. The dimensionality of the problem explodes however quickly.

The total number of Slater determinants which can be built with say $N$ neutrons distributed among $n$ single particle states is
\[
\left (\begin{array}{c} n \\ N\end{array} \right) =\frac{n!}{(n-N)!N!}. 
\]

For a model space which comprises the first for major shells only $0s$, $0p$, $1s0d$ and $1p0f$ we have $40$ single particle states for neutrons and protons.  For the eight neutrons of oxygen-16 we would then have
\[
\left (\begin{array}{c} 40 \\ 8\end{array} \right) =\frac{40!}{(32)!8!}\sim 10^{9}, 
\]
and multiplying this with the number of proton Slater determinants we end up with approximately witha dimensionality $d$ of $d\sim 10^{18}$.


This number can be reduced if we look at specific symmetries only. However, the dimensionality explodes quickly!

\begin{itemize}
\item For Hamiltonian matrices of dimensionalities  which are smaller than $d\sim 10^5$, we would use so-called direct methods for diagonalizing the Hamiltonian matrix

\item For larger dimensionalities iterative eigenvalue solvers like Lanczos' method are used. The most efficient codes at present can handle matrices of $d\sim 10^{10}$. 
\end{itemize}

\noindent
\subsection{A non-practical way of solving the eigenvalue problem}

For reasons to come (links with Coupled-Cluster theory and Many-Body perturbation theory), 
we will rewrite Eq.~(\ref{eq:fullci}) as a set of coupled non-linear equations in terms of the unknown coefficients $C_H^P$. 
To obtain the eigenstates and eigenvalues in terms of non-linear equations is not a very practical approach. However, it serves the scope of linking FCI theory with approximative solutions to the many-body problem.

To see this, we look at the contributions arising from 
\[
\langle \Phi_H^P | = \langle \Phi_0|
\]
in  Eq.~(\ref{eq:fullci}), that is we multiply with $\langle \Phi_0 |$
from the left in 
\[
(\hat{H} -E)\sum_{P'H'}C_{H'}^{P'}|\Phi_{H'}^{P'} \rangle=0. 
\]
If we assume that we have a two-body operator at most, Slater's rule gives then an equation for the 
correlation energy in terms of $C_i^a$ and $C_{ij}^{ab}$ only.  We get then
\[
\langle \Phi_0 | \hat{H} -E| \Phi_0\rangle + \sum_{ai}\langle \Phi_0 | \hat{H} -E|\Phi_{i}^{a} \rangle C_{i}^{a}+
\sum_{abij}\langle \Phi_0 | \hat{H} -E|\Phi_{ij}^{ab} \rangle C_{ij}^{ab}=0,
\]
or 
\[
E-E_0 =\Delta E=\sum_{ai}\langle \Phi_0 | \hat{H}|\Phi_{i}^{a} \rangle C_{i}^{a}+
\sum_{abij}\langle \Phi_0 | \hat{H}|\Phi_{ij}^{ab} \rangle C_{ij}^{ab},
\]
where the energy $E_0$ is the reference energy and $\Delta E$ defines the so-called correlation energy.
The single-particle basis functions  could be the results of a Hartree-Fock calculation or just the eigenstates of the non-interacting part of the Hamiltonian. 

In our notes on Hartree-Fock calculations, 
we have already computed the matrix $\langle \Phi_0 | \hat{H}|\Phi_{i}^{a}\rangle $ and $\langle \Phi_0 | \hat{H}|\Phi_{ij}^{ab}\rangle$.  If we are using a Hartree-Fock basis, then the matrix elements
$\langle \Phi_0 | \hat{H}|\Phi_{i}^{a}\rangle=0$ and we are left with a \emph{correlation energy} given by
\[
E-E_0 =\Delta E^{HF}=\sum_{abij}\langle \Phi_0 | \hat{H}|\Phi_{ij}^{ab} \rangle C_{ij}^{ab}. 
\]


Inserting the various matrix elements we can rewrite the previous equation as
\[
\Delta E=\sum_{ai}\langle i| \hat{f}|a \rangle C_{i}^{a}+
\sum_{abij}\langle ij | \hat{v}| ab \rangle C_{ij}^{ab}.
\]
This equation determines the correlation energy but not the coefficients $C$. 
We need more equations. Our next step is to set up
\[
\langle \Phi_i^a | \hat{H} -E| \Phi_0\rangle + \sum_{bj}\langle \Phi_i^a | \hat{H} -E|\Phi_{j}^{b} \rangle C_{j}^{b}+
\sum_{bcjk}\langle \Phi_i^a | \hat{H} -E|\Phi_{jk}^{bc} \rangle C_{jk}^{bc}+
\sum_{bcdjkl}\langle \Phi_i^a | \hat{H} -E|\Phi_{jkl}^{bcd} \rangle C_{jkl}^{bcd}=0,
\]
as this equation will allow us to find an expression for the coefficents $C_i^a$ since we can rewrite this equation as 
\[
\langle i | \hat{f}| a\rangle +\langle \Phi_i^a | \hat{H}|\Phi_{i}^{a} \rangle C_{i}^{a}+ \sum_{bj\ne ai}\langle \Phi_i^a | \hat{H}|\Phi_{j}^{b} \rangle C_{j}^{b}+
\sum_{bcjk}\langle \Phi_i^a | \hat{H}|\Phi_{jk}^{bc} \rangle C_{jk}^{bc}+
\sum_{bcdjkl}\langle \Phi_i^a | \hat{H}|\Phi_{jkl}^{bcd} \rangle C_{jkl}^{bcd}=EC_i^a.
\]

We see that on the right-hand side we have the energy $E$. This leads to a non-linear equation in the unknown coefficients. 
These equations are normally solved iteratively ( that is we can start with a guess for the coefficients $C_i^a$). A common choice is to use perturbation theory for the first guess, setting thereby
\[
 C_{i}^{a}=\frac{\langle i | \hat{f}| a\rangle}{\epsilon_i-\epsilon_a}.
\]

The observant reader will however see that we need an equation for $C_{jk}^{bc}$ and $C_{jkl}^{bcd}$ as well.
To find equations for these coefficients we need then to continue our multiplications from the left with the various
$\Phi_{H}^P$ terms. 


For $C_{jk}^{bc}$ we need then
\[
\langle \Phi_{ij}^{ab} | \hat{H} -E| \Phi_0\rangle + \sum_{kc}\langle \Phi_{ij}^{ab} | \hat{H} -E|\Phi_{k}^{c} \rangle C_{k}^{c}+
\]
\[
\sum_{cdkl}\langle \Phi_{ij}^{ab} | \hat{H} -E|\Phi_{kl}^{cd} \rangle C_{kl}^{cd}+\sum_{cdeklm}\langle \Phi_{ij}^{ab} | \hat{H} -E|\Phi_{klm}^{cde} \rangle C_{klm}^{cde}+\sum_{cdefklmn}\langle \Phi_{ij}^{ab} | \hat{H} -E|\Phi_{klmn}^{cdef} \rangle C_{klmn}^{cdef}=0,
\]
and we can isolate the coefficients $C_{kl}^{cd}$ in a similar way as we did for the coefficients $C_{i}^{a}$. 
A standard choice for the first iteration is to set 
\[
C_{ij}^{ab} =\frac{\langle ij \vert \hat{v} \vert ab \rangle}{\epsilon_i+\epsilon_j-\epsilon_a-\epsilon_b}.
\]
At the end we can rewrite our solution of the Schroedinger equation in terms of $n$ coupled equations for the coefficients $C_H^P$.
This is a very cumbersome way of solving the equation. However, by using this iterative scheme we can illustrate how we can compute the
various terms in the wave operator or correlation operator $\hat{C}$. We will later identify the calculation of the various terms $C_H^P$
as parts of different many-body approximations to full CI. In particular, we can  relate this non-linear scheme with Coupled Cluster theory and
many-body perturbation theory.


\subsection{Summarizing FCI and bringing in approximative methods}


If we can diagonalize large matrices, FCI is the method of choice since:
\begin{itemize}
\item It gives all eigenvalues, ground state and excited states

\item The eigenvectors are obtained directly from the coefficients $C_H^P$ which result from the diagonalization

\item We can compute easily expectation values of other operators, as well as transition probabilities

\item Correlations are easy to understand in terms of contributions to a given operator beyond the Hartree-Fock contribution. This is the standard approach in  many-body theory. 
\end{itemize}

\noindent
The correlation energy is defined as, with a two-body Hamiltonian,  
\[
\Delta E=\sum_{ai}\langle i| \hat{f}|a \rangle C_{i}^{a}+
\sum_{abij}\langle ij | \hat{v}| ab \rangle C_{ij}^{ab}.
\]

The coefficients $C$ result from the solution of the eigenvalue problem. 
The energy of say the ground state is then
\[
E=E_{ref}+\Delta E,
\]
where the so-called reference energy is the energy we obtain from a Hartree-Fock calculation, that is
\[
E_{ref}=\langle \Phi_0 \vert \hat{H} \vert \Phi_0 \rangle.
\]

However, as we have seen, even for a small case like the four first major shells and a nucleus like oxygen-16, the dimensionality becomes quickly intractable. If we wish to include single-particle states that reflect weakly bound systems, we need a much larger single-particle basis. We need thus approximative methods that sum specific correlations to infinite order. 

Popular methods are
\begin{itemize}
\item Many-body perturbation theory (in essence a Taylor expansion)

\item Coupled cluster theory (coupled non-linear equations)

\item Green's function approaches (matrix inversion)

\item Similarity group transformation methods (coupled ordinary differential equations
\end{itemize}

All these methods start normally with a Hartree-Fock basis as the calculational basis. 




\section{Many-body perturbation theory}

We assume here that we are only interested in the ground state of the system and 
expand the exact wave function in term of a series of Slater determinants
\[
\vert \Psi_0\rangle = \vert \Phi_0\rangle + \sum_{m=1}^{\infty}C_m\vert \Phi_m\rangle,
\]
where we have assumed that the true ground state is dominated by the 
solution of the unperturbed problem, that is
\[
\hat{H}_0\vert \Phi_0\rangle= W_0\vert \Phi_0\rangle.
\]
The state $\vert \Psi_0\rangle$ is not normalized, rather we have used an intermediate 
normalization $\langle \Phi_0 \vert \Psi_0\rangle=1$ since we have $\langle \Phi_0\vert \Phi_0\rangle=1$. 



The Schroedinger equation is
\[
\hat{H}\vert \Psi_0\rangle = E\vert \Psi_0\rangle,
\]
and multiplying the latter from the left with $\langle \Phi_0\vert $ gives
\[
\langle \Phi_0\vert \hat{H}\vert \Psi_0\rangle = E\langle \Phi_0\vert \Psi_0\rangle=E,
\]
and subtracting from this equation
\[
\langle \Psi_0\vert \hat{H}_0\vert \Phi_0\rangle= W_0\langle \Psi_0\vert \Phi_0\rangle=W_0,
\]
and using the fact that the both operators $\hat{H}$ and $\hat{H}_0$ are hermitian 
results in
\[
\Delta E=E-W_0=\langle \Phi_0\vert \hat{H}_I\vert \Psi_0\rangle,
\]
which is an exact result. We call this quantity the correlation energy.



This equation forms the starting point for all perturbative derivations. However,
as it stands it represents nothing but a mere formal rewriting of Schroedinger's equation and is not of much practical use. The exact wave function $\vert \Psi_0\rangle$ is unknown. In order to obtain a perturbative expansion, we need to expand the exact wave function in terms of the interaction $\hat{H}_I$. 

Here we have assumed that our model space defined by the operator $\hat{P}$ is one-dimensional, meaning that
\[
\hat{P}= \vert \Phi_0\rangle \langle \Phi_0\vert ,
\]
and
\[
\hat{Q}=\sum_{m=1}^{\infty}\vert \Phi_m\rangle \langle \Phi_m\vert .
\]


We can thus rewrite the exact wave function as
\[
\vert \Psi_0\rangle= (\hat{P}+\hat{Q})\vert \Psi_0\rangle=\vert \Phi_0\rangle+\hat{Q}\vert \Psi_0\rangle.
\]
Going back to the Schr\"odinger equation, we can rewrite it as, adding and a subtracting a term $\omega \vert \Psi_0\rangle$ as
\[
\left(\omega-\hat{H}_0\right)\vert \Psi_0\rangle=\left(\omega-E+\hat{H}_I\right)\vert \Psi_0\rangle,
\]
where $\omega$ is an energy variable to be specified later. 


We assume also that the resolvent of $\left(\omega-\hat{H}_0\right)$ exits, that is
it has an inverse which defined the unperturbed Green's function as
\[
\left(\omega-\hat{H}_0\right)^{-1}=\frac{1}{\left(\omega-\hat{H}_0\right)}.
\]

We can rewrite Schroedinger's equation as
\[
\vert \Psi_0\rangle=\frac{1}{\omega-\hat{H}_0}\left(\omega-E+\hat{H}_I\right)\vert \Psi_0\rangle,
\]
and multiplying from the left with $\hat{Q}$ results in
\[
\hat{Q}\vert \Psi_0\rangle=\frac{\hat{Q}}{\omega-\hat{H}_0}\left(\omega-E+\hat{H}_I\right)\vert \Psi_0\rangle,
\]
which is possible since we have defined the operator $\hat{Q}$ in terms of the eigenfunctions of $\hat{H}$.




These operators commute meaning that
\[
\hat{Q}\frac{1}{\left(\omega-\hat{H}_0\right)}\hat{Q}=\hat{Q}\frac{1}{\left(\omega-\hat{H}_0\right)}=\frac{\hat{Q}}{\left(\omega-\hat{H}_0\right)}.
\]
With these definitions we can in turn define the wave function as 
\[
\vert \Psi_0\rangle=\vert \Phi_0\rangle+\frac{\hat{Q}}{\omega-\hat{H}_0}\left(\omega-E+\hat{H}_I\right)\vert \Psi_0\rangle.
\]
This equation is again nothing but a formal rewrite of Schr\"odinger's equation
and does not represent a practical calculational scheme.  
It is a non-linear equation in two unknown quantities, the energy $E$ and the exact
wave function $\vert \Psi_0\rangle$. We can however start with a guess for $\vert \Psi_0\rangle$ on the right hand side of the last equation.



 The most common choice is to start with the function which is expected to exhibit the largest overlap with the wave function we are searching after, namely $\vert \Phi_0\rangle$. This can again be inserted in the solution for $\vert \Psi_0\rangle$ in an iterative fashion and if we continue along these lines we end up with
\[
\vert \Psi_0\rangle=\sum_{i=0}^{\infty}\left\{\frac{\hat{Q}}{\omega-\hat{H}_0}\left(\omega-E+\hat{H}_I\right)\right\}^i\vert \Phi_0\rangle, 
\]
for the wave function and
\[
\Delta E=\sum_{i=0}^{\infty}\langle \Phi_0\vert \hat{H}_I\left\{\frac{\hat{Q}}{\omega-\hat{H}_0}\left(\omega-E+\hat{H}_I\right)\right\}^i\vert \Phi_0\rangle, 
\]
which is now  a perturbative expansion of the exact energy in terms of the interaction
$\hat{H}_I$ and the unperturbed wave function $\vert \Psi_0\rangle$.



In our equations for $\vert \Psi_0\rangle$ and $\Delta E$ in terms of the unperturbed
solutions $\vert \Phi_i\rangle$  we have still an undetermined parameter $\omega$
and a dependecy on the exact energy $E$. Not much has been gained thus from a practical computational point of view. 

In Brilluoin-Wigner perturbation theory it is customary to set $\omega=E$. This results in the following perturbative expansion for the energy $\Delta E$
\[
\Delta E=\sum_{i=0}^{\infty}\langle \Phi_0\vert \hat{H}_I\left\{\frac{\hat{Q}}{\omega-\hat{H}_0}\left(\omega-E+\hat{H}_I\right)\right\}^i\vert \Phi_0\rangle=
\]
\[
\langle \Phi_0\vert \left(\hat{H}_I+\hat{H}_I\frac{\hat{Q}}{E-\hat{H}_0}\hat{H}_I+
\hat{H}_I\frac{\hat{Q}}{E-\hat{H}_0}\hat{H}_I\frac{\hat{Q}}{E-\hat{H}_0}\hat{H}_I+\dots\right)\vert \Phi_0\rangle. 
\]

\[
\Delta E=\sum_{i=0}^{\infty}\langle \Phi_0\vert \hat{H}_I\left\{\frac{\hat{Q}}{\omega-\hat{H}_0}\left(\omega-E+\hat{H}_I\right)\right\}^i\vert \Phi_0\rangle=\]
\[
\langle \Phi_0\vert \left(\hat{H}_I+\hat{H}_I\frac{\hat{Q}}{E-\hat{H}_0}\hat{H}_I+
\hat{H}_I\frac{\hat{Q}}{E-\hat{H}_0}\hat{H}_I\frac{\hat{Q}}{E-\hat{H}_0}\hat{H}_I+\dots\right)\vert \Phi_0\rangle. 
\]
This expression depends however on the exact energy $E$ and is again not very convenient from a practical point of view. It can obviously be solved iteratively, by starting with a guess for  $E$ and then solve till some kind of self-consistency criterion has been reached. 

Actually, the above expression is nothing but a rewrite again of the full Schr\"odinger equation. 

Defining $e=E-\hat{H}_0$ and recalling that $\hat{H}_0$ commutes with 
$\hat{Q}$ by construction and that $\hat{Q}$ is an idempotent operator
$\hat{Q}^2=\hat{Q}$. 
Using this equation in the above expansion for $\Delta E$ we can write the denominator 
\[
\hat{Q}\frac{1}{\hat{e}-\hat{Q}\hat{H}_I\hat{Q}}=
\]
\[
\hat{Q}\left[\frac{1}{\hat{e}}+\frac{1}{\hat{e}}\hat{Q}\hat{H}_I\hat{Q}
\frac{1}{\hat{e}}+\frac{1}{\hat{e}}\hat{Q}\hat{H}_I\hat{Q}
\frac{1}{\hat{e}}\hat{Q}\hat{H}_I\hat{Q}\frac{1}{\hat{e}}+\dots\right]\hat{Q}.
\]

Inserted in the expression for $\Delta E$ leads to 
\[
\Delta E=
\langle \Phi_0\vert \hat{H}_I+\hat{H}_I\hat{Q}\frac{1}{E-\hat{H}_0-\hat{Q}\hat{H}_I\hat{Q}}\hat{Q}\hat{H}_I\vert \Phi_0\rangle. 
\]
In RS perturbation theory we set $\omega = W_0$ and obtain the following expression for the energy difference
\[
\Delta E=\sum_{i=0}^{\infty}\langle \Phi_0\vert \hat{H}_I\left\{\frac{\hat{Q}}{W_0-\hat{H}_0}\left(\hat{H}_I-\Delta E\right)\right\}^i\vert \Phi_0\rangle=
\]
\[
\langle \Phi_0\vert \left(\hat{H}_I+\hat{H}_I\frac{\hat{Q}}{W_0-\hat{H}_0}(\hat{H}_I-\Delta E)+
\hat{H}_I\frac{\hat{Q}}{W_0-\hat{H}_0}(\hat{H}_I-\Delta E)\frac{\hat{Q}}{W_0-\hat{H}_0}(\hat{H}_I-\Delta E)+\dots\right)\vert \Phi_0\rangle.
\]



Recalling that $\hat{Q}$ commutes with $\hat{H_0}$ and since $\Delta E$ is a constant we obtain that
\[
\hat{Q}\Delta E\vert \Phi_0\rangle = \hat{Q}\Delta E\vert \hat{Q}\Phi_0\rangle = 0.
\]
Inserting this results in the expression for the energy results in
\[
\Delta E=\langle \Phi_0\vert \left(\hat{H}_I+\hat{H}_I\frac{\hat{Q}}{W_0-\hat{H}_0}\hat{H}_I+
\hat{H}_I\frac{\hat{Q}}{W_0-\hat{H}_0}(\hat{H}_I-\Delta E)\frac{\hat{Q}}{W_0-\hat{H}_0}\hat{H}_I+\dots\right)\vert \Phi_0\rangle.
\]



We can now this expression in terms of a perturbative expression in terms
of $\hat{H}_I$ where we iterate the last expression in terms of $\Delta E$
\[
\Delta E=\sum_{i=1}^{\infty}\Delta E^{(i)}.
\]
We get the following expression for $\Delta E^{(i)}$
\[
\Delta E^{(1)}=\langle \Phi_0\vert \hat{H}_I\vert \Phi_0\rangle,
\] 
which is just the contribution to first order in perturbation theory,
\[
\Delta E^{(2)}=\langle\Phi_0\vert \hat{H}_I\frac{\hat{Q}}{W_0-\hat{H}_0}\hat{H}_I\vert \Phi_0\rangle, 
\]
which is the contribution to second order.



\[
\Delta E^{(3)}=\langle \Phi_0\vert \hat{H}_I\frac{\hat{Q}}{W_0-\hat{H}_0}\hat{H}_I\frac{\hat{Q}}{W_0-\hat{H}_0}\hat{H}_I\Phi_0\rangle-
\langle\Phi_0\vert \hat{H}_I\frac{\hat{Q}}{W_0-\hat{H}_0}\langle \Phi_0\vert \hat{H}_I\vert \Phi_0\rangle\frac{\hat{Q}}{W_0-\hat{H}_0}\hat{H}_I\vert \Phi_0\rangle,
\]
being the third-order contribution. 


\subsection{Interpreting the correlation energy and the wave operator}

In the shell-model lectures we showed that we could rewrite the exact state function for say the ground state, as a linear expansion in terms of all possible Slater determinants. That is, we 
define the ansatz for the ground state as 
\[
|\Phi_0\rangle = \left(\prod_{i\le F}\hat{a}_{i}^{\dagger}\right)|0\rangle,
\]
where the index $i$ defines different single-particle states up to the Fermi level. We have assumed that we have $N$ fermions. 
A given one-particle-one-hole ($1p1h$) state can be written as
\[
|\Phi_i^a\rangle = \hat{a}_{a}^{\dagger}\hat{a}_i|\Phi_0\rangle,
\]
while a $2p2h$ state can be written as
\[
|\Phi_{ij}^{ab}\rangle = \hat{a}_{a}^{\dagger}\hat{a}_{b}^{\dagger}\hat{a}_j\hat{a}_i|\Phi_0\rangle,
\]
and a general $ApAh$ state as 
\[
|\Phi_{ijk\dots}^{abc\dots}\rangle = \hat{a}_{a}^{\dagger}\hat{a}_{b}^{\dagger}\hat{a}_{c}^{\dagger}\dots\hat{a}_k\hat{a}_j\hat{a}_i|\Phi_0\rangle.
\]

We use letters $ijkl\dots$ for states below the Fermi level and $abcd\dots$ for states above the Fermi level. A general single-particle state is given by letters $pqrs\dots$.

We can then expand our exact state function for the ground state 
as
\[
|\Psi_0\rangle=C_0|\Phi_0\rangle+\sum_{ai}C_i^a|\Phi_i^a\rangle+\sum_{abij}C_{ij}^{ab}|\Phi_{ij}^{ab}\rangle+\dots
=(C_0+\hat{C})|\Phi_0\rangle,
\]
where we have introduced the so-called correlation operator 
\[
\hat{C}=\sum_{ai}C_i^a\hat{a}_{a}^{\dagger}\hat{a}_i  +\sum_{abij}C_{ij}^{ab}\hat{a}_{a}^{\dagger}\hat{a}_{b}^{\dagger}\hat{a}_j\hat{a}_i+\dots
\]
Since the normalization of $\Psi_0$ is at our disposal and since $C_0$ is by hypothesis non-zero, we may arbitrarily set $C_0=1$ with 
corresponding proportional changes in all other coefficients. Using this so-called intermediate normalization we have
\[
\langle \Psi_0 | \Phi_0 \rangle = \langle \Phi_0 | \Phi_0 \rangle = 1, 
\]
resulting in 
\[
|\Psi_0\rangle=(1+\hat{C})|\Phi_0\rangle.
\]

In a shell-model calculation, the unknown coefficients in $\hat{C}$ are the 
eigenvectors which result from the diagonalization of the Hamiltonian matrix.

How can we use perturbation theory to determine the same coefficients? Let us study the contributions to second order in the interaction, namely
\[
\Delta E^{(2)}=\langle\Phi_0\vert \hat{H}_I\frac{\hat{Q}}{W_0-\hat{H}_0}\hat{H}_I\vert \Phi_0\rangle.
\]

The intermediate states given by $\hat{Q}$ can at most be of a $2p-2h$ nature if we have a two-body Hamiltonian. This means that second order in the perturbation theory can have $1p-1h$ and $2p-2h$ at most as intermediate states. When we diagonalize, these contributions are included to infinite order. This means that higher-orders in perturbation theory bring in more complicated correlations. 

If we limit the attention to a Hartree-Fock basis, then we have that
$\langle\Phi_0\vert \hat{H}_I \vert 2p-2h\rangle$ is the only contribution and the contribution to the energy reduces to
\[
\Delta E^{(2)}=\frac{1}{4}\sum_{abij}\langle ij\vert \hat{v}\vert ab\rangle \frac{\langle ab\vert \hat{v}\vert ij\rangle}{\epsilon_i+\epsilon_j-\epsilon_a-\epsilon_b}.
\]

If we compare this to the correlation energy obtained from full configuration interaction theory with a Hartree-Fock basis, we found that
\[
E-E_0 =\Delta E=
\sum_{abij}\langle ij | \hat{v}| ab \rangle C_{ij}^{ab},
\]
where the energy $E_0$ is the reference energy and $\Delta E$ defines the so-called correlation energy.

We see that if we set
\[
C_{ij}^{ab} =\frac{1}{4}\frac{\langle ab \vert \hat{v} \vert ij \rangle}{\epsilon_i+\epsilon_j-\epsilon_a-\epsilon_b},
\]
we have a perfect agreement between FCI and MBPT. However, FCI includes such $2p-2h$ correlations to infinite order. In order to make a meaningful comparison we would at least need to sum such correlations to infinite order in perturbation theory. 

Summing up, we can see that
\begin{itemize}
\item MBPT introduces order-by-order specific correlations and we make comparisons with exact calculations like FCI

\item At every order, we can calculate all contributions since they are well-known and either tabulated or calculated on the fly.

\item MBPT is a non-variational theory and there is no guarantee that higher orders will improve the convergence. 

\item However, since FCI calculations are limited by the size of the Hamiltonian matrices to diagonalize (today's most efficient codes can attach dimensionalities of ten billion basis states, MBPT can function as an approximative method which gives a straightforward (but tedious) calculation recipe. 

\item MBPT has been widely used to compute effective interactions for the nuclear shell-model.

\item But there are better methods which sum to infinite order important correlations. Coupled cluster theory is one of these methods. 
\end{itemize}




\subsection{The Breuckner $G$-matrix}

The Brueckner $G$-matrix has historically been an important ingredient
in many-body calculations of nuclear systems. In this section, we will
briefly survey the philosophy behind the $G$-matrix.

Historically, the $G$-matrix was developed in microscopic nuclear
matter calculations using realistic nucleon-nucleon (NN) interactions.
It is an ingenuous as well as an interesting method to overcome the
difficulties caused by the strong, short-range repulsive core contained
in all modern models for the NN interaction. The $G$-matrix method was
originally developed by Brueckner, and further
developed by Goldstone and Bethe, Brandow and Petschek. 
In the literature it is generally referred to as the
Brueckner theory or the Brueckner-Bethe-Goldstone theory.

Suppose we want to calculate the nuclear matter ground-state
energy $E_0$ using the non-relativistic Schr\"{o}dinger equation
\begin{equation}
      H\Psi_0(A)=E_0(A)\Psi_0(A),
\end{equation}
with $H=T+V$ where $A$ denotes the number of particles, $T$
is the kinetic energy and $V$ is
the nucleon-nucleon
(NN)  potential. Models for the NN interaction are discussed in the chapter on nuclear forces.
The corresponding unperturbed
problem is
\begin{equation}
      H_0\psi_0(A)=W_0(A)\psi_0(A).
\end{equation}
Here $H_0$ is just kinetic energy $T$ and $\psi_0$ is a Slater
determinant representing the Fermi sea, where all orbits through the
Fermi momentum $k_F$ are filled. We write
\begin{equation}
      E_0=W_0+\Delta E_0,
\end{equation}
where $\Delta E_0$ is the ground-state energy shift or correlation energy as it was defined in many-body perturbation theory.
If we know how to calculate $\Delta E_0$, then we know $E_0$, since
$W_0$ is easily obtained. In the limit $A\rightarrow \infty$,
the quantities $E_0$ and $\Delta E_0$ themselves are not well
defined, but the ratios $E_0/A$ and $\Delta E_0/A$ are. The
nuclear-matter binding energy per nucleon is commonly denoted
by $BE/A$, which is just $-E_0/A$. In passing, we note that
the empirical value for symmetric nuclear matter (proton number
$Z$=neutron number $N$) is $\approx 16$ MeV.
There exists a formal theory for the calculation of $\Delta E_0$.
According to the well-known Goldstone linked-diagram theory, the energy shift $\Delta E_0$ is given exactly by the
diagrammatic expansion shown in Fig.~\ref{fig:goldstone}. This theory,
is a linked-cluster perturbation expansion for the ground state
energy of a many-body system, and applies equally well to both
nuclear matter and closed-shell nuclei such as the doubly magic
nucleus $^{40}$Ca. 
We will not discuss the Goldstone expansion, but rather discuss
briefly how it is used in calculations.


Using the standard diagram rules (see the discussion on
coupled-cluster theory and many-body perturbation theory), the various
diagrams contained in the above figure can be readily calculated (in
an uncoupled scheme)
\begin{equation}
   (i)=\frac{(-)^{n_h+n_l}}{2^{n_{ep}}}\sum_{ij\leq k_F}
       \langle ij\vert\hat{v}\vert ij\rangle_{AS},
\end{equation}
with $n_h=n_l=2$ and $n_{ep}=1$. As discussed in connection with the
diagram rules in the many-body perturbation theory chapter, $n_h$
denotes the number of hole lines, $n_l$ the number of closed fermion
loops and $n_{ep}$ is the number of so-called equivalent pairs.  The
factor $1/2^{n_{ep}}$ is needed since we want to count a pair of
particles only once. We will carry this factor $1/2$ with us in the
equations below.  The subscript $AS$ denotes the antisymmetrized and
normalized matrix element
\begin{equation}
     \langle ij\vert\hat{v}\vert ij\rangle_{AS}=\langle ij \vert\hat{v}\vert ij\rangle-
     \langle ji \vert\hat{v}\vert ij\rangle.
\end{equation}
Similarly, diagrams (ii) and (iii) read
\begin{equation}
   (ii)=\frac{(-)^{2+2}}{2^2}\sum_{ij\leq k_F}\sum_{ab>k_F}
   \frac{\langle ij\vert\hat{v}\vert ab\rangle_{AS}
   \langle ab\vert\hat{v}\vert ij\rangle_{AS}}
   {\varepsilon_i+\varepsilon_j-\varepsilon_a-\varepsilon_b},
\end{equation}
and
\begin{equation}
   (iii)=\frac{(-)^{2+2}}{2^3}\sum_{k_i,k_j\leq k_F}\sum_{abcdk_F}
   \frac{\langle ij\vert\hat{v}\vert ab\rangle_{AS}
   \langle ab\vert\hat{v}\vert cd\rangle_{AS}
   \langle cd\vert\hat{v}\vert ij\rangle_{AS}}
   {(\varepsilon_i+\varepsilon_j-\varepsilon_a-\varepsilon_b)
   (\varepsilon_i+\varepsilon_j-\varepsilon_c-\varepsilon_d)}.
\end{equation}
In the above, $\varepsilon$ denotes the sp energies defined by
$H_0$.
The steps leading to the above expressions for the various
diagrams are rather straightforward. Though, if we wish to compute the
matrix elements for the interaction $v$, a serious problem
arises. Typically, the matrix elements will contain a term
(see the next section for the formal details) $V(|{\mathbf r}|)$, which
represents the interaction potential $V$ between two nucleons, where
${\mathbf r}$ is the internucleon distance.
All modern models
for $V$ have a strong short-range repulsive core. Hence,
matrix elements involving $V(|{\mathbf r}|)$, will result in large
(or infinitely large for a potential with a hard core)
and repulsive contributions to the ground-state energy. Thus, the
diagrammatic expansion for the ground-state energy in terms of the
potential $V(|{\mathbf r}|)$ becomes meaningless.

One possible solution to  this problem is provided by the well-known
Brueckner theory or the Brueckner $G$-matrix, or just the
$G$-matrix. In fact, the $G$-matrix is an almost indispensable
tool in almost every microscopic nuclear structure
calculation. Its main idea may be paraphrased as follows.
Suppose we want to calculate the function $f(x)=x/(1+x)$. If
$x$ is small, we may expand the function $f(x)$ as a power series
$x+x^2+x^3+\dots$ and it may be adequate to just calculate the first
few terms. In other words, $f(x)$ may be calculated using a low-order
perturbation method. But if $x$ is large
(or infinitely large), the above
power series is obviously meaningless.
However, the exact function
$x/(1+x)$ is still well defined in the limit
of $x$ becoming very large.

These arguments suggest that one should sum up the diagrams
(i), (ii), (iii) in fig.~\ref{fig:goldstone} and the similar ones
to all orders, instead of computing them one by one. Denoting this
all-order sum as $1/2\tilde{G}_{ijij}$, where we have
introduced the shorthand notation
$\tilde{G}_{ijij}=\langle k_ik_j\vert \tilde{G}\vert k_ik_j\rangle_{AS}$
(and similarly for $\tilde{v}$),
we have that
\begin{align}
      \frac{1}{2}\tilde{G}_{ijij}=&\frac{1}{2}\hat{v}_{ijij}
      +\sum_{ab>k_F}\frac{1}{2}\hat{v}_{ijab}\frac{1}{\varepsilon_i+\varepsilon_j-\varepsilon_a-\varepsilon_b}
      \nonumber \\
      & \times\left[\frac{1}{2}\hat{v}_{abij}+\sum_{cd>k_F}
      \frac{1}{2}\hat{v}_{abcd}\frac{1}
      {\varepsilon_i+\varepsilon_j-\varepsilon_c-\varepsilon_d}
      \frac{1}{2}V_{cdij}+\dots  \right].
\end{align}
The factor $1/2$ is the same as that discussed above, namely we want 
to count a pair of particles only once.
The quantity inside the brackets is just
$1/2\tilde{G}_{mnij}$ and the above equation can be
rewritten as an integral equation
\begin{equation}
      \tilde{G}_{ijij}=\tilde{V}_{ijij}
      +\sum_{ab>F}\frac{1}{2}\hat{v}_{ijab}\frac{1}{\varepsilon_i+\varepsilon_j-\varepsilon_a-\varepsilon_b}
      \tilde{G}_{abij}.
\end{equation}
Note that $\tilde{G}$ is the antisymmetrized $G$-matrix since
the potential $\tilde{v}$ is also antisymmetrized. This means that
$\tilde{G}$ obeys
\begin{equation}
  \tilde{G}_{ijij}=-\tilde{G}_{jiij}=-\tilde{G}_{ijji}.
\end{equation}
The $\tilde{G}$-matrix  is defined as
\begin{equation}
    \tilde{G}_{ijij}=G_{ijij}-G_{jiij},
\end{equation}
and the equation for $G$ is
\begin{equation}
      G_{ijij}=V_{ijij}
      +\sum_{ab>k_F}V_{ijab}\frac{1}
      {\varepsilon_i+\varepsilon_j-\varepsilon_a-\varepsilon_b}
      G_{abij},
      \label{eq:ggeneral}
\end{equation}
which is the familiar $G$-matrix equation. The above
matrix is specifically designed to treat a class of diagrams
contained in $\Delta E_0$, of which typical contributions
were shown in fig.~\ref{fig:goldstone}. In fact the sum of the diagrams
in fig.~\ref{fig:goldstone} is equal to $1/2(G_{ijij}-G_{jiij})$.

Let us now define a more general $G$-matrix as
\begin{equation}
      G_{ijij}=V_{ijij}
      +\sum_{mn>0}V_{ijmn}\frac{Q(mn)}
      {\omega -\varepsilon_m-\varepsilon_n}
      G_{mnij},
      \label{eq:gwithq}
\end{equation}
which is an extension of Eq. (\ref{eq:ggeneral}). Note that 
Eq. (\ref{eq:ggeneral}) has
$\varepsilon_i+\varepsilon_j$ in the energy denominator, whereas
in the latter equation we have a general energy variable $\omega$
in the denominator. Furthermore, in Eq. (\ref{eq:ggeneral})
we have a restricted
sum over $mn$, while in Eq. (\ref{eq:gwithq})
we sum over all $ab$ and we have
introduced a weighting factor $Q(ab)$. In Eq. (\ref{eq:gwithq}) $Q(ab)$
corresponds to the choice
\begin{equation}
   Q(a , b ) =
    \left\{\begin{array}{cc}1,&min(a ,b ) > k_F\\
    0,&\mathrm{else}.\end{array}\right. ,
\end{equation}
where $Q(ab)$ is usually referred to as the $G$-matrix Pauli
exclusion operator. The role of $Q$ is to enforce a selection
of the intermediate states allowed in the $G$-matrix equation. The above
$Q$ requires that the intermediate particles $a$ and $b$
must be both above the Fermi surface defined by $F$. We may enforce
a different requirement by using a summation over intermediate states
different from that in Eq. (\ref{eq:gwithq}).
An example is the Pauli operator
for the model-space Brueckner-Hartree-Fock method discussed below.


Before ending this section, let us rewrite the $G$-matrix equation
in a more compact form.
The sp energies $\varepsilon$ and wave functions are defined
by the unperturbed hamiltonian $H_0$ as
\begin{equation}
   H_0\vert \psi_a\psi_b=(\varepsilon_a+\varepsilon_b)
   \vert \psi_a\psi_b.
\end{equation}
The $G$-matrix equation can then be rewritten in the following
compact form
\begin{equation}
   G(\omega )=V+V\frac{\hat{Q}}{\omega -H_0}G(\omega ),
\end{equation}
with
$\hat{Q}=\sum_{ab}\vert \psi_a\psi_b\langle\langle \psi_a\psi_b\vert$.
In terms of diagrams, $G$ corresponds to an all-order sum of the
"ladder-type" interactions between two particles with the
intermediate states restricted by $Q$.

The $G$-matrix equation has a very simple form. But its
calculation is rather complicated, particularly for finite
nuclear systems such as the nucleus $^{18}$O. There are a
number of complexities. To mention a few, the Pauli operator
$Q$ may not commute with the unperturbed hamiltonian
$H_0$ and we have to make the replacement
\[
\frac{Q}{\omega -H_0}\rightarrow Q\frac{1}{\omega -QH_0Q}Q.
\]
The determination of the starting energy $\omega$ is also another
problem. 


In a medium such as nuclear 
matter we must account
for the fact that certain states are not available as intermediate
states in the calculation of the $G$-matrix.
Following the discussion above
this is achieved by introducing the medium
dependent Pauli operator $Q$. Further, the
energy $\omega$ of the incoming particles, given by a pure kinetic
term in a scattering problem between two unbound particles (for example two colliding protons), must be modified so as to allow
for medium corrections.
How to evaluate the Pauli operator for
nuclear matter is, however, not straightforward.
Before discussing how to evaluate the Pauli operator for nuclear matter,
we note that the $G$-matrix
is conventionally given in terms of partial waves and
the coordinates of the relative and center-of-mass motion.
If we assume that the $G$-matrix is diagonal in $\alpha$ ($\alpha$ is a shorthand
notation for $J$, $S$, $L$ and $T$), we  write the equation for the $G$-matrix as a 
coupled-channels equation in the relative and center-of-mass system
\begin{equation}
   G_{ll'}^{\alpha}(kk'K\omega )=V_{ll'}^{\alpha}(kk')
   +\sum_{l''}\int \frac{d^3 q}{(2\pi )^3}V_{ll''}^{\alpha}(kq)
   \frac{Q(q,K)}{\omega -H_0}
   G_{l''l'}^{\alpha}(qk'K\omega).
   \label{eq:gnonrel}
\end{equation}
This equation is similar in structure to the scattering
equations discussed in connection with nuclear forces (see the chapter on models for nuclear forces), except that we now have
introduced the Pauli operator $Q$ and a medium dependent two-particle
energy $\omega$. The notations in this equation follow those of the chapter on nuclear forces
where we discuss the solution of the scattering
matrix $T$.
The numerical details on how to solve the above $G$-matrix
equation through matrix inversion techniques are discussed below
Note however that the $G$-matrix may not be diagonal in $\alpha$.
This is due to the fact that the
Pauli operator $Q$ is not diagonal
in the above representation in the relative and center-of-mass
system. The Pauli operator depends on the
angle between the relative momentum and the center of mass momentum.
This angle dependence causes $Q$ to couple states with different
relative angular
momentua ${\cal J}$, rendering  a partial wave decomposition of the $G$-matrix equation 
rather difficult.
The angle dependence of the Pauli operator
can be eliminated by introducing the angle-average
Pauli operator, where one replaces the exact Pauli operator $Q$
by its average $\bar{Q}$ over all angles for fixed relative and center-of-mass
momenta.
The choice of Pauli operator is decisive to the determination of the
sp
spectrum. Basically, to first order in the reaction matrix $G$,
there are three commonly used sp spectra, all
defined by the solution of the following equations
\begin{equation}
   \varepsilon_{m} = \varepsilon (k_{m})= t_{m} + u_{m}=\frac{k_{m}^2}{2M_N}+u_{m},
   \label{eq:spnrel}
\end{equation}
and
\begin{align}
   u_{m} =& {\displaystyle \sum_{h \leq k_F}}\left\langle m h \right| G(\omega = \varepsilon_{m} + \varepsilon_h )
   \left| m h \right\rangle_{AS}  \hspace{3mm}k_m \leq k_M,  \\ \\
   u_m=&0, k_m > k_M.
   \label{eq:selfcon}
\end{align}
For notational economy, we set $|{\bf k}_m|=k_m$.
Here we employ antisymmetrized matrix elements (AS), and $k_M$ is a cutoff
on the momentum. Further, $t_m$ is the sp kinetic
energy and similarly $u_m$
is the
sp potential.
The choice of cutoff $k_M$ is actually what determines the three
commonly used sp spectra.
In the conventional BHF approach one employs $k_M = k_F$,
which leads
to a Pauli operator $Q_{\mathrm{BHF}}$ (in the laboratory system) given by
\begin{equation}
   Q_{\mathrm{BHF}}(k_m , k_n ) =
    \left\{\begin{array}{cc}1,&min(k_m ,k_n ) > k_F\\
    0,&\mathrm{else}.\end{array}\right.
    \label{eq:bhf},
\end{equation}
or, since we will define an
angle-average Pauli operator in the relative and center-of-mass
system, we have
\begin{equation}
     \bar{Q}_{\mathrm{BHF}}(k,K)=\left\{\begin{array}{cc}
         0,&k\leq \sqrt{k_{F}^{2}-K^2/4}\\
         1,&k\geq k_F + K/2\\
	\frac{K^2/4+k^2 -k_{F}^2}{kK}&\mathrm{else},\end{array}\right.
    \label{eq:qbhf}
\end{equation}
with $k_F$ the momentum at the Fermi surface.

The BHF choice sets $u_k = 0$ for $k > k_F$, which leads
to an unphysical, large gap at the Fermi surface, typically
of the order of $50-60$ MeV. 
To overcome the gap
problem, Mahaux and collaborators 
introduced a continuous sp spectrum
for all values of $k$. The divergencies
which then may occur in Eq. (\ref{eq:gnonrel}) are taken care of by
introducing
a principal value integration in Eq. (\ref{eq:gnonrel}),
to retain only the
real part contribution to the $G$-matrix.


To define the energy denominators we will also make use of the
angle-average approximation.
The angle dependence is handled by the
so-called effective mass approximation. The single-particle energies
in nuclear matter are assumed to have the simple quadratic form
\begin{equation}
   \begin{array}{ccc}
   \varepsilon (k_m)=&
   {\displaystyle\frac{\hbar^{2}k_m^2}
   {2M_{N}^{*}}}+\Delta ,&\hspace{3mm}k_m\leq k_F\\
   &&\\
   =&{\displaystyle\frac{\hbar^{2}
   k_m^2}{2M_{N}}},&\hspace{3mm}k_m> k_F ,\\
   \end{array}
   \label{eq:spen}
\end{equation}
where $M_{N}^{*}$ is the effective mass of the nucleon and $M_{N}$ is the
bare nucleon mass. For particle states above the Fermi sea we choose
a pure kinetic energy term, whereas for hole states,
the terms $M_{N}^{*}$ and $\Delta$, the latter being 
an effective single-particle
potential related to the $G$-matrix, are obtained through the
self-consistent Brueckner-Hartree-Fock procedure.
The sp potential is obtained through the same angle-average approximation
\begin{align}
  \label{eq:Uav}
   U(k_m) & =\sum_{l\alpha} (2T+1)(2J+1)
   \left \{ \frac{8}{\pi}\int_{0}^{(k_F-k_m)/2}
   k^2dk G_{ll}^{\alpha}(k,\bar{K}_1) \right.  \\
   &    \left.
    + \frac{1}{\pi k_m}\int_{(k_F-k_m)/2}^{(k_F+k_m)/2}
   kdk (k_F ^2-(k_m-2k)^2)
   G_{ll}^{\alpha}(k,\bar{K}_2)  \right \}  \nonumber,
\end{align}
where we have defined
\begin{equation}
    \bar{K}_1^2=4(k_m^2+k^2),
\end{equation}
and
\begin{equation}
    \bar{K}_2^2=4(k_m^2+k^2)-(2k+k_m-k_F)(2k+k_1+k_F).
\end{equation}
This
self-consistency scheme consists in choosing adequate initial values of the
effective mass and $\Delta$. The obtained $G$-matrix is in turn used to
obtain new values for $M_{N}^{*}$ and $\Delta$. This procedure
continues until these parameters vary little.


\section{Coupled cluster theory}
\subsection{Introduction}
Coester and Kummel first developed the ideas that led to coupled-cluster
theory in the late 1950s. The basic idea is that the correlated wave function
of a many-body system $\mid\Psi\rangle$
can be formulated as an exponential of correlation
operators $T$ acting on a reference state $\mid\Phi\rangle$
\[
\mid\Psi\rangle = \exp\left(-\hat{T}\right)\mid\Phi\rangle\ .
\]
We will discuss how to define the operators later in this work. This simple
ansatz carries enormous power. It leads to a non-perturbative many-body
theory that includes summation of ladder diagrams , ring
diagrams, and an infinite-order
generalization of many-body perturbation theory..

Developments and applications of coupled-cluster theory took different
routes in chemistry and nuclear physics. In quantum chemistry,
coupled-cluster developments and applications have proven to be
extremely useful, see for example the review
by \href{{http://journals.aps.org/rmp/abstract/10.1103/RevModPhys.79.291}}{Barrett
and Musial} as well as the recent textbook
by \href{{http://www.cambridge.org/fr/academic/subjects/chemistry/physical-chemistry/many-body-methods-chemistry-and-physics-mbpt-and-coupled-cluster-theory?format=HB}}{Shavitt
and Barrett}.  Many previous applications to nuclear physics struggled
with the repulsive character of the nuclear forces and limited basis
sets used in the computations. Most of these problems have been
overcome during the last decade and coupled-cluster theory is one of
the computational methods of preference for doing nuclear physics,
with applications ranging from light nuclei to medium-heavy nuclei,
see for example the recent review
by \href{{http://iopscience.iop.org/0034-4885/77/9/096302}}{Hagen,Papenbrock, Hjorth-Jensen and Dean}.


\subsection{A quick tour of Coupled Cluster theory}

The ansatz for the wavefunction (ground state) is given by
\begin{equation*}
   \vert \Psi\rangle = \vert \Psi_{CC}\rangle = e^{\hat{T}} \vert \Phi_0\rangle =  
  \left( \sum_{n=1}^{A} \frac{1}{n!} \hat{T}^n \right) \vert \Phi_0\rangle,
\end{equation*}
where $A$ represents the maximum number of particle-hole excitations and $\hat{T}$ is the cluster operator defined as
\begin{align*}
            \hat{T} &= \hat{T}_1 + \hat{T}_2 + \ldots + \hat{T}_A \\
            \hat{T}_n &= \left(\frac{1}{n!}\right)^2 
                \sum_{\substack{
                        i_1,i_2,\ldots i_n \\
                        a_1,a_2,\ldots a_n}}
                t_{i_1i_2\ldots i_n}^{a_1a_2\ldots a_n} a_{a_1}^\dagger a_{a_2}^\dagger \ldots a_{a_n}^\dagger a_{i_n} \ldots a_{i_2} a_{i_1}.
        \end{align*}
    The energy is given by
    \begin{equation*}
        E_{\mathrm{CC}} = \langle\Phi_0\vert  \overline{H}\vert \Phi_0\rangle,
    \end{equation*}
    where $\overline{H}$ is a similarity transformed Hamiltonian
    \begin{align*}
        \overline{H}&= e^{-\hat{T}} \hat{H}_N e^{\hat{T}} \\
        \hat{H}_N &= \hat{H} - \langle\Phi_0\vert \hat{H} \vert \Phi_0\rangle.
    \end{align*}

    The coupled cluster energy is a function of the unknown cluster amplitudes $t_{i_1i_2\ldots i_n}^{a_1a_2\ldots a_n}$,
given by the solutions to the amplitude equations
    \begin{equation*}
        0 = \langle\Phi_{i_1 \ldots i_n}^{a_1 \ldots a_n}\vert \overline{H}\vert \Phi_0\rangle.
    \end{equation*}
The similarity transformed   Hamiltonian  $\overline{H}$ is expanded using the Baker-Campbell-Hausdorff expression,
    \begin{align*}
        \overline{H}&= \hat{H}_N + \left[ \hat{H}_N, \hat{T} \right] + 
            \frac{1}{2} \left[\left[ \hat{H}_N, \hat{T} \right], \hat{T}\right] + \ldots \\
            & \quad \frac{1}{n!} \left[ \ldots \left[ \hat{H}_N, \hat{T} \right], \ldots \hat{T} \right] +\dots
    \end{align*}
and simplified using the connected cluster theorem
    \begin{equation*}
        \overline{H}= \hat{H}_N + \left( \hat{H}_N \hat{T}\right)_c + \frac{1}{2} \left( \hat{H}_N \hat{T}^2\right)_c
            + \dots + \frac{1}{n!} \left( \hat{H}_N \hat{T}^n\right)_c +\dots
    \end{equation*}

A much used approximation is to  truncate the cluster operator $\hat{T}$ at the $n=2$ level. This defines the so-called singes and doubles approximation to the Coupled Cluster wavefunction, normally shortened to CCSD..

The coupled cluster wavefunction is now given by
\begin{equation*}
            \vert \Psi_{CC}\rangle = e^{\hat{T}_1 + \hat{T}_2} \vert \Phi_0\rangle
\end{equation*}
where 
        \begin{align*}
            \hat{T}_1 &= 
            \sum_{ia}
                t_{i}^{a} a_{a}^\dagger a_i \\
            \hat{T}_2 &= \frac{1}{4} 
            \sum_{ijab}
                t_{ij}^{ab} a_{a}^\dagger a_{b}^\dagger a_{j} a_{i}.
        \end{align*}

The amplutudes $t$ play a role similar to the coefficients $C$ in the shell-model calculations. They are obtained by solving a set of non-linear equations
similar to those discussed above in connection withe FCI discussion.

If we truncate our equations at the CCSD level, it corresponds to performing a transformation of the Hamiltonian matrix of the following type for a six particle problem (with a two-body Hamiltonian):

\begin{table}
\begin{center}
\begin{tabular}{cccccccc}
\hline
\multicolumn{1}{c}{  } & \multicolumn{1}{c}{ $0p-0h$ } & \multicolumn{1}{c}{ $1p-1h$ } & \multicolumn{1}{c}{ $2p-2h$ } & \multicolumn{1}{c}{ $3p-3h$ } & \multicolumn{1}{c}{ $4p-4h$ } & \multicolumn{1}{c}{ $5p-5h$ } & \multicolumn{1}{c}{ $6p-6h$ } \\
\hline
$0p-0h$ & $\tilde{x}$ & $\tilde{x}$ & $\tilde{x}$ & 0           & 0           & 0           & 0           \\
$1p-1h$ & 0           & $\tilde{x}$ & $\tilde{x}$ & $\tilde{x}$ & 0           & 0           & 0           \\
$2p-2h$ & 0           & $\tilde{x}$ & $\tilde{x}$ & $\tilde{x}$ & $\tilde{x}$ & 0           & 0           \\
$3p-3h$ & 0           & $\tilde{x}$ & $\tilde{x}$ & $\tilde{x}$ & $\tilde{x}$ & $\tilde{x}$ & 0           \\
$4p-4h$ & 0           & 0           & $\tilde{x}$ & $\tilde{x}$ & $\tilde{x}$ & $\tilde{x}$ & $\tilde{x}$ \\
$5p-5h$ & 0           & 0           & 0           & $\tilde{x}$ & $\tilde{x}$ & $\tilde{x}$ & $\tilde{x}$ \\
$6p-6h$ & 0           & 0           & 0           & 0           & $\tilde{x}$ & $\tilde{x}$ & $\tilde{x}$ \\
\hline
\end{tabular}
\end{center}
\end{table}

In our FCI discussion the correlation energy is defined as, with a two-body Hamiltonian,  
\[
\Delta E=\sum_{ai}\langle i| \hat{f}|a \rangle C_{i}^{a}+
\sum_{abij}\langle ij | \hat{v}| ab \rangle C_{ij}^{ab}.
\]

In Coupled cluster theory it becomes (irrespective of level of truncation of $T$)
\[
\Delta E=\sum_{ai}\langle i| \hat{f}|a \rangle t_{i}^{a}+
\sum_{abij}\langle ij | \hat{v}| ab \rangle t_{ij}^{ab}.
\]

Coupled cluster theory has several interesting computational features
and is the method of choice in quantum chemistry. The method was
originally proposed by Coester and Kummel, two nuclear physicists (way
back in the fifties). It came back in full strength in nuclear physics
during the last decade.

There are several interesting features:
\begin{itemize}
\item With a truncation like CCSD or CCSDT, we can include to infinite order correlations like $2p-2h$.

\item We can include a large basis of single-particle states, not possible in standard FCI calculations
\end{itemize}
However, Coupled Cluster theory is
\begin{itemize}
\item non-variational

\item if we want to find properties of excited states, additional calculations via for example equation of motion methods are needed

\item if correlations are strong, a single-reference ansatz may not be the best starting point

\item we cannot quantify properly the error we make when truncations are made in the cluster operator
\end{itemize}

\subsection{The CCD approximation}

We will now approximate the cluster operator $\hat{T}$ to include only
$2p-2h$ correlations. This leads to the so-called CCD approximation,
that is
\[
\hat{T}\approx \hat{T}_2=\frac{1}{4}\sum_{abij}t_{ij}^{ab}a^{\dagger}_aa^{\dagger}_ba_ja_i,
\]
meaning that we have
\[
\vert \Psi_0 \rangle \approx \vert \Psi_{CCD} \rangle = \exp{\left(\hat{T}_2\right)}\vert \Phi_0\rangle.
\]

Inserting these equations in the expression for the computation of the
energy we have, with a Hamiltonian defined with respect to a general
vacuum (see the exercises in the second quantization part)
\[
\hat{H}=\hat{H}_N+E_{\mathrm{ref}},
\]
with 
\[
\hat{H}_N=\sum_{pq}\langle p \vert \hat{f} \vert q \rangle  a^{\dagger}_pa_q + \frac{1}{4}\sum_{pqrs}\langle pq \vert \hat{v} \vert rs \rangle a^{\dagger}_pa^{\dagger}_qa_sa_r,
\]
we obtain that the energy can be written as 
\[
\langle \Phi_0 \vert \exp{-\left(\hat{T}_2\right)}\hat{H}_N\exp{\left(\hat{T}_2\right)}\vert \Phi_0\rangle =
\langle \Phi_0 \vert \hat{H}_N(1+\hat{T}_2)\vert \Phi_0\rangle = E_{CCD}.
\]
This quantity becomes 
\[
E_{CCD}=E_{\mathrm{ref}}+\frac{1}{4}\sum_{abij}\langle ij \vert \hat{v} \vert ab \rangle t_{ij}^{ab},
\]
where the latter is the correlation energy from this level of approximation of CC theory. 
Similarly, the expression for the amplitudes reads
\[
\langle \Phi_{ij}^{ab} \vert \exp{-\left(\hat{T}_2\right)}\hat{H}_N\exp{\left(\hat{T}_2\right)}\vert \Phi_0\rangle = 0.
\]
These equations can be reduced to (after several applications of Wick's theorem) to, for all $i > j$ and all $a  > b$,
\begin{align}
0 = \langle ab \vert \hat{v} \vert ij \rangle + \left(\epsilon_a+\epsilon_b-\epsilon_i-\epsilon_j\right)t_{ij}^{ab} & \nonumber \\ 
+\frac{1}{2}\sum_{cd} \langle ab \vert \hat{v} \vert cd \rangle t_{ij}^{cd}+\frac{1}{2}\sum_{kl} \langle kl \vert \hat{v} \vert ij \rangle t_{kl}^{ab}+\hat{P}(ij\vert ab)\sum_{kc} \langle kb \vert \hat{v} \vert cj \rangle t_{ik}^{ac} & \nonumber \\
+\frac{1}{4}\sum_{klcd} \langle kl \vert \hat{v} \vert cd \rangle t_{ij}^{cd}t_{kl}^{ab}+\hat{P}(ij)\sum_{klcd} \langle kl \vert \hat{v} \vert cd \rangle t_{ik}^{ac}t_{jl}^{bd}& \nonumber \\
-\frac{1}{2}\hat{P}(ij)\sum_{klcd} \langle kl \vert \hat{v} \vert cd \rangle t_{ik}^{dc}t_{lj}^{ab}-\frac{1}{2}\hat{P}(ab)\sum_{klcd} \langle kl \vert \hat{v} \vert cd \rangle t_{lk}^{ac}t_{ij}^{db},&
\label{eq:ccd}
\end{align}
where we have defined 
\[
\hat{P}\left(ab\right)= 1-\hat{P}_{ab},
\]
where $\hat{P}_{ab}$ interchanges two particles occupying the quantum numbers $a$ and $b$. 
The operator $\hat{P}(ij\vert ab)$  is defined as
\[
\hat{P}(ij\vert ab) = (1-\hat{P}_{ij})(1-\hat{P}_{ab}).
\]
Recall also that the unknown amplitudes $t_{ij}^{ab}$
represent anti-symmetrized matrix elements, meaning that they obey the same symmetry relations as the two-body interaction, that is
\[
t_{ij}^{ab}=-t_{ji}^{ab}=-t_{ij}^{ba}=t_{ji}^{ba}.
\]
The two-body matrix elements are also anti-symmetrized, meaning that
\[
\langle ab \vert \hat{v} \vert ij \rangle = -\langle ab \vert \hat{v} \vert ji \rangle= -\langle ba \vert \hat{v} \vert ij \rangle=\langle ba \vert \hat{v} \vert ji \rangle.
\]
The non-linear equations for the unknown amplitudes  $t_{ij}^{ab}$ are solved iteratively. We discuss the implementation of these equations below.

\paragraph{Approximations to the full CCD equations.}
It is useful to make approximations to the equations for the amplitudes. The standard method for solving these equations is to set up an iterative scheme where method's like Newton's method or similar root searching methods are used to find the amplitudes. 
Itreative solvers need a guess for the amplitudes. A good starting point is to use the correlated wave operator from perturbation theory to
first order in the interaction.
This means that we define the zeroth approximation to the amplitudes as 
\[
t^{(0)}=\frac{\langle ab \vert \hat{v} \vert ij \rangle}{\left(\epsilon_i+\epsilon_j-\epsilon_a-\epsilon_b\right)},
\]
leading to our first approximation for the correlation energy at the CCD level to be equal to second-order perturbation theory without $1p-1h$ excitations, namely
\[
\Delta E_{\mathrm{CCD}}^{(0)}=\frac{1}{4}\sum_{abij} \frac{\langle ij \vert \hat{v} \vert ab \rangle \langle ab \vert \hat{v} \vert ij \rangle}{\left(\epsilon_i+\epsilon_j-\epsilon_a-\epsilon_b\right)}.
\]

With this starting point, we are now ready to solve Eq. (\ref{eq:ccd}) iteratively. Before we attack the full equations, it is however instructive to study a truncated version of the equations. We will first study the following approximation where we take away all terms except the linear terms that involve the single-particle energies and the the two-particle intermediate excitations, that is
\begin{equation}
0 = \langle ab \vert \hat{v} \vert ij \rangle + \left(\epsilon_a+\epsilon_b-\epsilon_i-\epsilon_j\right)t_{ij}^{ab}+\frac{1}{2}\sum_{cd} \langle ab \vert \hat{v} \vert cd \rangle t_{ij}^{cd}.
\label{eq:ccd1}
\end{equation}

Setting the single-particle energies for the hole states equal to an energy variable $\omega = \epsilon_i+\epsilon_j$, Eq. (\ref{eq:ccd1}) reduces to the
well-known equations for the so-called $G$-matrix, widely used in \href{{http://www.sciencedirect.com/science/journal/03701573/261/3-4}}{infinite matter and finite nuclei studies}. The equation can then be reordered and solved by matrix inversion.  To see this let us define the following quantity
\[
\tau_{ij}^{ab}= \left(\omega-\epsilon_a-\epsilon_b\right)t_{ij}^{ab},
\]
and inserting 
\[
1=\frac{\left(\omega-\epsilon_c-\epsilon_d\right)}{\left(\omega-\epsilon_c-\epsilon_d\right)},
\]
in the intermediate sums over $cd$ in Eq. (\ref{eq:ccd1}), we can rewrite the latter equation as
\[
\tau_{ij}^{ab}(\omega)= \langle ab \vert \hat{v} \vert ij \rangle + \frac{1}{2}\sum_{cd} \langle ab \vert \hat{v} \vert cd \rangle \frac{1}{\omega-\epsilon_c-\epsilon_d}\tau_{ij}^{cd}(\omega),
\]
where we have indicated an explicit energy dependence. This equation, transforming a two-particle configuration into a single index, can be transformed into a matrix inversion problem.  Solving the equations for a fixed energy $\omega$ allows us to compare directly with results from Green's function theory when only two-particle intermediate states are included. 

To solve Eq. (\ref{eq:ccd1}), we would thus start with a guess for the unknown amplitudes, typically using the wave operator defined by first order in perturbation theory, leading to a zeroth approximation to the energy given by second-order perturbation theory for the correlation energy.
A simple approach to the solution of  Eq. (\ref{eq:ccd1}), is to thus to
\begin{enumerate}
\item Start with a guess for the amplitudes and compute the zeroth approximation to the correlation energy

\item Use the ansatz for the amplitudes to solve Eq. (\ref{eq:ccd1}) via for example your root-finding method of choice (Newton's method or modifications thereof can be used) and continue these iterations till the correlation energy does not change more than a prefixed quantity $\lambda$; $\Delta E_{\mathrm{CCD}}^{(i)}-\Delta E_{\mathrm{CCD}}^{(i-1)} \le \lambda$.

\item It is common during the iterations to scale the amplitudes with a parameter $\alpha$, with $\alpha \in (0,1]$ as  $t^{(i)}=\alpha t^{(i)}+(1-\alpha)t^{(i-1)}$.
\end{enumerate}

\noindent
The next approximation is to include the two-hole term in Eq. (\ref{eq:ccd}), a term which allow us to make a link with Green's function theory with two-particle and two-hole correlations. This means that we solve
\begin{equation}
0 = \langle ab \vert \hat{v} \vert ij \rangle + \left(\epsilon_a+\epsilon_b-\epsilon_i-\epsilon_j\right)t_{ij}^{ab}+\frac{1}{2}\sum_{cd} \langle ab \vert \hat{v} \vert cd \rangle t_{ij}^{cd}+\frac{1}{2}\sum_{kl} \langle kl \vert \hat{v} \vert ij \rangle t_{kl}^{ab}.
\label{eq:ccd2}
\end{equation}
This equation is solved the same way as we would do for Eq. (\ref{eq:ccd1}). The final step is then to include all terms in Eq. (\ref{eq:ccd}). 

\section{Developing a numerical project}

This section will focus on writing a working CCD code from scratch. If you are familiar with writing quantum many-body physics codes, feel free to skip ahead as we are going to go into some detail about implementing CCD as a computer code now. As we saw earlier, the CCD equations can be written as 
\begin{align}
\left(\epsilon_i+\epsilon_j-\epsilon_a-\epsilon_b\right)t_{ij}^{ab} = \langle ab \vert \hat{v} \vert ij \rangle  & \nonumber \\ 
+\frac{1}{2}\sum_{cd} \langle ab \vert \hat{v} \vert cd \rangle t_{ij}^{cd}+\frac{1}{2}\sum_{kl} \langle kl \vert \hat{v} \vert ij \rangle t_{kl}^{ab}+\hat{P}(ij\vert ab)\sum_{kc} \langle kb \vert \hat{v} \vert cj \rangle t_{ik}^{ac} & \nonumber \\
+\frac{1}{4}\sum_{klcd} \langle kl \vert \hat{v} \vert cd \rangle t_{ij}^{cd}t_{kl}^{ab}+\hat{P}(ij)\sum_{klcd} \langle kl \vert \hat{v} \vert cd \rangle t_{ik}^{ac}t_{jl}^{bd}& \nonumber \\
-\frac{1}{2}\hat{P}(ij)\sum_{klcd} \langle kl \vert \hat{v} \vert cd \rangle t_{ik}^{dc}t_{lj}^{ab}-\frac{1}{2}\hat{P}(ab)\sum_{klcd} \langle kl \vert \hat{v} \vert cd \rangle t_{lk}^{ac}t_{ij}^{db},&
\label{eq:ccd2}
\end{align}
for all $i < j$ and all $a < b$, using the standard notation that $a,b,...$ are particle states and $i,j,...$ are hole states. With the CCD correlation energy given by
\begin{equation}
\Delta E_{CCD} = \frac{1}{4} \sum_{ijab} \braket{ij|\hat{v}|ab}t^{ab}_{ij}.
\label{eq:ccdcorr}
\end{equation}
One way to solve these equations, is to write equation (\ref{eq:ccd2}) as a series of iterative nonlinear algebraic equations.
\begin{align}
t_{ij}^{ab}{}^{(n+1)} = \frac{1}{\epsilon^{ab}_{ij}} \bigg(\langle ab \vert \hat{v} \vert ij \rangle  & \nonumber \\ 
+\frac{1}{2}\sum_{cd} \langle ab \vert \hat{v} \vert cd \rangle t_{ij}^{cd}{}^{(n)}+\frac{1}{2}\sum_{kl} \langle kl \vert \hat{v} \vert ij \rangle t_{kl}^{ab}{}^{(n)}+\hat{P}(ij\vert ab)\sum_{kc} \langle kb \vert \hat{v} \vert cj \rangle t_{ik}^{ac}{}^{(n)} & \nonumber \\
+\frac{1}{4}\sum_{klcd} \langle kl \vert \hat{v} \vert cd \rangle t_{ij}^{cd}{}^{(n)}t_{kl}^{ab}{}^{(n)}+\hat{P}(ij)\sum_{klcd} \langle kl \vert \hat{v} \vert cd \rangle t_{ik}^{ac}{}^{(n)}t_{jl}^{bd}{}^{(n)}& \nonumber \\
-\frac{1}{2}\hat{P}(ij)\sum_{klcd} \langle kl \vert \hat{v} \vert cd \rangle t_{ik}^{dc}{}^{(n)}t_{lj}^{ab}{}^{(n)}-\frac{1}{2}\hat{P}(ab)\sum_{klcd} \langle kl \vert \hat{v} \vert cd \rangle t_{lk}^{ac}{}^{(n)}t_{ij}^{db}{}^{(n)} \bigg),&
\label{eq:ccd3}
\end{align}
for all $i < j$ and all $a < b$, where $\epsilon^{ab}_{ij} = \left(\epsilon_i+\epsilon_j-\epsilon_a-\epsilon_b\right)$, and $t_{ij}^{ab}{}^{(n)}$ is the $t$ amplitude for the nth iteration of the series. This way, given some starting guess $t_{ij}^{ab}{}^{(0)}$, we can generate subsequent $t$ amplitudes that converges to some value. Discussion of the mathematical details regarding convergence will be tabled for later; for now we will talk about implementing these equations into a computer program and assume convergence. In pseudocode, the function that updates the $t$ amplitudes looks like

\begin{algorithmic} 
\State CCD\_Update()
  \For{$i \in \{0,N_{fermi}-1\}$ }  
  \For{$j \in \{0,N_{fermi}-1\}$ }
  \For{$a \in \{N_{fermi},N_{sp}-1\}$ }
  \For{$b \in \{N_{fermi},N_{sp}-1\}$ }
  \State $\text{sum} \gets \text{TBME}[\text{index}(a,b,i,j)$]
  \For{$c \in \{N_{fermi},N_{sp}-1\}$ }
  \For{$d \in \{N_{fermi},N_{sp}-1\}$ }
  \State $\text{sum} \gets \text{sum} + 0.5*\text{ME}[\text{index}(a,b,c,d)] * t\_\text{amplitudes}\_\text{old}[\text{index}(c,d,i,j)]$
  \EndFor
  \EndFor
  \State ...
  \State sum $\gets$ sum + (all other terms)
  \State ...
  \State energy\_denom = SP\_energy[$i$]+SP\_energy[$j$]-SP\_energy[$a$]-SP\_energy[$b$]
  \State t\_amplitudes[index($a,b,i,j$)] = sum/energy\_denom
  \EndFor
  \EndFor
  \EndFor
  \EndFor
\end{algorithmic}
Where $N_{fermi}$ is the fermi level and $N_{sp}$ is the total number of single particle (s.p.) states, indexed from 0 to $N_{sp}-1$. At the most basic level, the CCD equations are just the addition of many products containing $t_{ij}^{ab}$ amplitudes and two-body matrix elements (TBMEs) $\braket{ij|\hat{v}|ab}$, so a lot of care should be placed into how we store these objects. These are both objects with four indices, so a sensible first implementation of the CCD equations would be to create two 4-D arrays to store the objects. However, it is often more convenient to work with simple 1-D arrays instead. $index()$ is a function that maps the four indices onto one index so that a 1-D array can be used. An example of such a function is:
\begin{algorithmic}
\Function{index}{$p,q,r,s$} 
\State \textbf{return} $p*N_{sp}^3 + q*N_{sp}^2 + r*N_{sp} + s$
\EndFunction
\end{algorithmic}
Because elements with repeated indices vanish, $t_{ii}^{ab}=t_{ij}^{aa}=0$ and $\braket{pp|\hat{v}|rs}=\braket{pq|\hat{v}|rr}=0$, data structures using this index function will contain many elements that are automatically zero, so we will discuss more efficient storage strategies later. Notice also that we are looping over all $i,j,a,b$, rather than the restricted indices. This means that we are doing redundant work, but it is simpler to code up, and we will want to unrestrict these indices later anyways.

 The goal of this code is to calculate the correlation energy, $\Delta E_{CCD}$, so after each iteration of our equation, we use our newest $t$ amplitudes to update this value,
\begin{equation}
\Delta E_{CCD}^{(n)} = \frac{1}{4} \sum_{ijab} \braket{ij|\hat{v}|ab}t^{ab}_{ij}{}^{(n)}.
\end{equation}
We check that our result is converged by checking that to see if the most recent iteration has changed the correlation energy by less than some tolerance threshold $\eta$,
\begin{equation}
\eta > | \Delta E_{CCD}^{(n+1)} - \Delta E_{CCD}^{(n)} |.
\end{equation}
The basic structure of the iterative process will look like:
\begin{algorithmic}
  \While {(abs(energy\_Diff) $>$ tolerance)}
  \State CCD\_Update()
  \State correlation\_Energy $\gets$ CCD\_Corr\_Energy()
  \State energy\_Diff $\gets$ correlation\_Energy - correlation\_Energy\_old
  \State correlation\_Energy\_old $\gets$ correlation\_Energy
  \State t\_amplitudes\_old $\gets$ t\_amplitudes
  \EndWhile
\end{algorithmic}

Prior to this algorithm, the $t$ amplitudes should be initalized, $t_{ij}^{ab}{}^{(0)}$. A particularly convenient choice is to set $t_{ij}^{ab}{}^{(0)} = 0$. Notice that if this starting point is used, then

\begin{align}
t_{ij}^{ab}{}^{(1)} = \frac{\langle ab \vert \hat{v} \vert ij \rangle}{\epsilon^{ab}_{ij}}   & \nonumber \\
\label{eq:ccdGuess}
\end{align}
\begin{equation}
\Delta E_{CCD}^{(1)} = \frac{1}{4} \sum_{ijab}\frac{\langle ab \vert \hat{v} \vert ij \rangle}{\epsilon^{ab}_{ij}},
\end{equation}

which is the result from MBPT2. This is a useful, as one iteration of the CCD equations can be ran, and checked against MBPT2 to give some confidence that everything is working so far. To check that everything is working, it is useful to run the code using a minimal example. A simple pairing model Hamiltonian is a nice place to start.
\begin{equation}
\hat{H}_0 = \xi \sum_{p \sigma} (p-1) a^{\dagger}_{p \sigma} a_{p \sigma} 
\end{equation}
\begin{equation}
\hat{V} = -\frac{1}{2}g \sum_{pq} a^{\dagger}_{p+}a^{\dagger}_{p-} a_{q-}a_{q+}
\end{equation}
which represents a basic pairing model with p levels each with a spin degeneracy of 2. The form of the coupled cluster equations in (Eq) uses single-particle states that are eigenstates of the Hartree-Fock operator, $\left(\hat{u}+\hat{u}_{\text{HF}}\right\vert p\rangle=\epsilon_{p}\vert p\rangle$. In the pairing model, this condition is already fulfilled. All we have to do is define the lowest $N_{fermi}$ states as holes then redefine the single-particle energies,
\begin{equation}
\epsilon_q = h_{qq} + \sum_{i} \braket{qi||qi}.
\end{equation}
To be more specific, let's look at this pairing model with 4 particles and 8 single-particle states. These states (with $\xi = 1.0$) could be labeled as such with
\begin{center}
    \begin{tabular}{| l | l | l | l | l |}
    \hline
    State Label & p & 2s$_z$ & E & type\\ \hline
    0 & 1 & 1 & -g/2 & hole \\ \hline
    1 & 1 & -1 & -g/2 & hole \\ \hline
    2 & 2 & 1 & 1-g/2 & hole \\ \hline
    3 & 2 & -1 & 1-g/2 & hole \\ \hline
    4 & 3 & 1 & 2 & particle \\ \hline
    5 & 3 & -1 & 2 & particle \\ \hline
    6 & 4 & 1 & 3 & particle \\ \hline
    7 & 4 & -1 & 3 & particle \\ \hline 
    \end{tabular}
\end{center}

Here are some more results for specific values of g that can be used for benchmarking.

\begin{center}
    \begin{tabular}{| l | l | l | l |}
    \hline
    g & E$_{ref}$ & $\Delta E_{MBPT2}$ & $\Delta E_{CCD}$ \\ \hline
    -1.0 & 3 & -0.46667 & -0.21895* \\ \hline
    -0.5 & 2.5 & -0.08874 & -0.06306 \\ \hline
    0.0 & 2 & 0 & 0 \\ \hline
    0.5 & 1.5 & -0.06239 & -0.08336 \\ \hline
    1.0 & 1 & -0.21905 & -0.36956 \\ \hline     
    \end{tabular}
\end{center}
The $g=-1.0$ case diverges without implementing iterative mixing. Sometimes iterative solvers run into oscillating solutions, and mixing can help the iterations break this cycle.
\begin{equation}
t^{(i)} = \alpha t^{(i)}_{no\_mixing} + (1 - \alpha) t^{(i-1)}
\end{equation}
In the case of this simple pairing model, it is easy to calculate $\Delta E_{MBPT2}$ by hand, which is useful to check the code's calcuation of this value, as well as the first CCD iteration.
\begin{equation}
\Delta E_{MBPT2} = \frac{1}{4} \sum_{abij} \frac{\braket{ij||ab} \braket{ab||ij}}{ \epsilon_{ij}^{ab}} = \sum_{a<b,i<j} \frac{\braket{ij||ab} \braket{ab||ij}}{ \epsilon_{ij}^{ab}}
\end{equation}
For our pairing example:
\[
\Delta E_{MBPT2} = \frac{\braket{01||45}^2}{\epsilon_{01}^{45}} + \frac{\braket{01||67}^2}{\epsilon_{01}^{67}} + \frac{\braket{23||45}^2}{\epsilon_{23}^{45}} + \frac{\braket{23||67}^2}{\epsilon_{23}^{67}} 
\]
\[
\Delta E_{MBPT2} = -\frac{g^2}{4} \bigg( \frac{1}{  4 + g} + \frac{1}{  6 + g} + \frac{1}{  2 + g} + \frac{1}{  4 + g}  \bigg),
\]
which is a nice expression which can be used to check the results for any value of g.

Once a working pairing model has been implemented, improvements can start to be made, all the while using the pairing model to make sure that the code is still working and giving correct answers. Realistic systems will be much larger than this small pairing example. 

One limitation that will be ran into while trying to do realistic CCD calculations is that of memory. The 4-indexed TBMEs and t-amplitudes have to store a lot of elements, and the size of these arrays can quite become larger than that of the available memory on the machine. If calculation wants to use 500 s.p. basis states, then a structure like $\braket{pq|v|rs}$ will have length 500 for each of its four indices, which means it will have $500^4 = 625*10^8$ elements. To get a handle on how much memory is used, consider the elements as double-precision floating point type. One double takes up 8 bytes of memory. So this array would take up $8*625*10^8$ bytes = $5000 * 10^8$ bytes = $500$ Gbytes of memory. Most personal computers in 2016 have 4-8 Gbytes of RAM, so this calculation would be way out of reach. There are supercomputers that can handle applications using 500 Gbytes of memory, but we can quickly reduce the total memory required by applying some physical arguments. In addition to vanishing elements with repeated indices, mentioned above, elements that do not obey certain symmetries are also zero. Almost all realistic two-body forces preserve some quantities due to symmetries in the interaction. For example, an interaction with rotational symmetry will conserve angular momentum. This means that a two-body ket state $\ket{rs}$, which has some set of quantum numbers, will retain quantum numbers corresponding to the interaction symmetries after being acted on by $\hat{v}$. This state is then projected onto $\ket{pq}$ with its own set of quantum numbers. Thus  $\braket{pq|v|rs}$ is only non-zero if $\ket{pq}$ and $\ket{rs}$ share the same quantum numbers that are preserved by $\hat{v}$. In addition, because the cluster operators represent excitations due to the interaction, $t_{ij}^{ab}$ is only non-zero if $\ket{ij}$ has the same relevant quantum numbers as $\ket{ab}$.

To take advantage of this, these two-body ket states can be organized into ``channels'' of shared quantum numbers. In the case of the pairing model, the interaction preserves the total spin projection of a two-body state, $S_{z}=s_{z1}+s_{z2}$. The single particle states can have spin of +1/2 or -1/2, so there can be three two-body channels with $S_{z}=-1,0,+1$. These channels can then be indexed with a unique label in a similar way to the single particle index scheme. In more complicated systems, there will be many more channels involving multiple symmetries, so it is useful to create a data structure that stores the relevant two-body quantum numbers to keep track of the labeling scheme.

Now it is more efficient to use two-dimensional array data structures, where the first index refers to the channel number and the second refers to the element withing that channel. So to access matrix elements or $t$ amplitudes, you can loop over the channels first, then the indices within that channel. To get an idea of the savings using this block diagonal structure, let's look at a case with a plane wave basis, with three momentum and one spin quantum numbers, with an interaction that conserves linear momentum in all three dimensions, as well as the total spin projection. Using 502 basis states, the TBME's require about 0.23 Gb of memory in block diagonal form, which is an enormous saving from the 500 Gb mentions earlier in the na\"ive storage scheme.

Since the calculation of all of these zeros can now be avoided, improvements in speed as memory will now follow. To get a handle on how example these CCD calculations are we need only to look at the most expensive sum in equation \ref{eq:ccd2}. This corresponds to the sum over $klcd$. Since this sum is repeated for all $i < j$ and $a < b$, that means these equations will scale as $\mathcal{O}(n_{p}^{4} n_{h}^{4})$. However, (as we saw earlier?), they can be rewritten using intermediates as

\begin{align}
0 = \braket{ab|\hat{v}|ij} + \hat{P}(ab) \sum_{c} \braket{b| \chi |c} \braket{ac| t |ij} - \hat{P}(ij) \sum_{k} \braket{k| \chi |j} \braket{ab| t |ik} & \nonumber \\ 
+ \frac{1}{2}\sum_{cd} \braket{ab| \chi |cd} \braket{cd| t |ij} +  \frac{1}{2} \sum_{kl} \braket{ab| t |kl} \braket{kl| \chi |ij} \\ 
+ \hat{P}(ij)\hat{P}(ab) \sum_{kc} \braket{ac| t |ik}\braket{kb| \chi |cj} & \nonumber
\end{align}
for all $i,j,a,b$, the reason why these indices are now unrestricted will be explained later. Where the intermediates $\chi$ are
\begin{equation}
\braket{b| \chi |c} = \braket{b|f|c} - \frac{1}{2} \sum_{kld} \braket{bd|t|kl} \braket{kl|v|cd}
\end{equation}
\begin{equation}
\braket{k| \chi |j} = \braket{k|f|j} + \frac{1}{2} \sum_{cdl} \braket{kl|v|cd} \braket{cd|t|jl} 
\end{equation}
\begin{equation}
\braket{kl| \chi |ij} = \braket{kl|v|ij} + \frac{1}{2} \sum_{cd} \braket{kl|v|cd} \braket{cd|t|ij} 
\label{eq:mtxEx}
\end{equation}
\begin{equation}
\braket{kb| \chi |cj} = \braket{kb|v|cj} + \frac{1}{2} \sum_{dl} \braket{kl|v|cd} \braket{db|t|lj} 
\end{equation}
\begin{equation}
\braket{ab| \chi |cd} = \braket{ab|v|cd} 
\end{equation}

Maybe demonstrate how these equations are equal here? 

Now the CCD equations will scale as $\mathcal{O}(n_{h}^{2} n_{p}^{4})$ which is quite a bit better than before. This is of course at the cost of computing the intermediates at the beginning of each iteration, which the most expensive one, $\braket{kb| \chi |cj}$, will scale as $\mathcal{O}(n_{h}^{3} n_{p}^{3})$. To further speed these computations up, we see that these sums can be written as matrix-matrix multiplication. It is not obvious how to write all of these sums in such a way, but it is useful to first remember that to write out the multiplication of matices $\hat{C} = \hat{A} * \hat{B}$ is
\begin{equation}
C_{ij} = \sum_{k} A_{ik} * B_{kj}.
\end{equation}
Notice that equation (\ref{eq:mtxEx}) can be written as
\[
\braket{K| \chi |I} = \braket{K|v|I} + \frac{1}{2} \sum_{C} \braket{K|v|C} \braket{C|t|I} 
\]
by mapping the two index pairs $kl \to K, ij \to I, cd \to C$. So now the sum looks like a matrix-matrix multiplication. This is useful because there are packages like BLAS (Basic Linear Algebra Subprograms) which have extremely fast implementations of matrix-matrix multiplication.

Now that we have a working CCD program, we can move on to more realistic cases. One such case is infinite nuclear matter using a plane-wave basis. These states are solutions to the free-particle Hamiltonian,
\begin{equation}
\frac{-\hbar^2}{2m}\nabla^2\mathop{\phi(\vec{x})}=\epsilon\mathop{\phi(\vec{x})}.
\end{equation}
For a finite basis, we approximate the problem by constructing a box with sides of length $L$, which quantizes the momentum, and impose periodic boundary conditions in each direction.
\begin{align}
\mathop{\phi(x_{i})}=\mathop{\phi(x_{i}+L)} \\
\mathop{\phi_{\vec{k}}(\vec{x})}=\frac{1}{\sqrt{L^{3}}}e^{i\vec{k}\cdot\vec{x}},\hspace{0.5cm}\vec{k}=\frac{2\pi\vec{n}}{L},\hspace{0.5cm}n_{i}
\end{align}

The first step in calculating infinite matter is to construct a model space by finding every single-particle state relevant to a given problem. In our case, this amounts to looping over the quantum numbers for spin, isospin, and the three momentum directions. To control the model space size, the momentum can be truncated to give a cubic space, where $n_{i}\leq n_{\text{max}}$, or a spherical space, where $n_{x}^{2}+n_{y}^{2}+n_{z}^{2}\leq N_{\text{max}}$. The number of single-particle states in a cubic space increases rapidly with $n_{\text{max}}$ compared to the spherical case with $N_{\text{max}}$. For example, in pure neutron matter a cubic space with $n_{\text{max}}=3$ has $668$ states while the spherical space with $N_{\text{max}}=17$ has $610$ states. Therefore, the spherical case will be used for the rest of the calculations here. The loop increases in energy by counting the number of shells, so states can be 'filled' by labeling the first $P$ proton and $N$ neutron states as holes. The following loop is for pure neutron matter and requires the number of neutrons, $N$ and density, $\rho=N/L^{3}$, as input. Symmetric nuclear matter requires an extra loop over isospin.

\begin{algorithmic}
  \State $n=0$
  \For{$\text{shell}\in\{ 0,...,N_{\text{max}}\}$}
  \For{$-\sqrt{N_{\text{max}}}\leq n_{x}\leq\sqrt{N_{\text{max}}}$}
  \For{$-\sqrt{N_{\text{max}}}\leq n_{y}\leq\sqrt{N_{\text{max}}}$}
  \For{$-\sqrt{N_{\text{max}}}\leq n_{z}\leq\sqrt{N_{\text{max}}}$}
  \For{$s_{z}\in\{-\frac{1}{2},\frac{1}{2}\}$}
  \If{$n_{x}^{2}+n_{y}^{2}+n_{z}^{2}=\text{shell}$}
  \State $\text{Energy}=\frac{4\pi^{2}\hbar^{2}}{2m}\times\text{shell}$
  \If{$n<N$}
  \State $\text{type}=\text{``hole''}$
  \Else
  \State $\text{type}=\text{``particle''}$
  \EndIf
  \State STATES $\gets$ ($n$, $n_{x}$, $n_{y}$, $n_{z}$, $s_{z}$, Energy, type)
  \State $n\gets n+1$
  \EndIf
  \EndFor
  \EndFor
  \EndFor
  \EndFor
  \EndFor
\end{algorithmic}

The next step is to build every two-body state in the model space and separate them by their particle/hole character and combined quantum numbers. While each single-particle state was unique, two-body states can share quantum numbers with members of a particular two-body channel. These channels allow us to remove matrix elements and cluster amplitudes that violate the symmetries of the interaction and greatly reduces the size and speed of the calculation. Our structures will depend on direct two-body channels, $T$, where the quantum numbers are added and cross two-body channels, $X$, where the quantum numbers are subtracted. Before filling the channels, it's helpful to order them with an index function which returns a unique index for a given set of two-body quantum numbers. Without an index function, one has to loop over all the channels for each two-body state which adds a substantial amount of time to this algorithm. An example of an index function for the direct channels in symmetric nuclear matter is, for $N_{x}=n_{x,1}+n_{x,2}$, $N_{y}=n_{y,1}+n_{y,2}$, $N_{z}=n_{z,1}+n_{z,2}$, $S_{z}=s_{z,1}+s_{z,2}$, $T_{z}=t_{z,1}+t_{z,2}$, $m=2\lfloor\sqrt{N_{\text{max}}}\rfloor$, and $M=2m+1$,
\begin{equation}
\text{Ind}\left( N_{x},N_{y},N_{z},S_{z},T_{z}\right)=2\left( N_{x}+m\right)M^{3}+2\left( N_{y}+m\right)M^{2}+2\left( N_{z}+m\right)M+2\left( S_{z}+1\right)+\left(T_{z}+1\right).
\end{equation}
This function, which can also be used for the cross-channel index function, is well suited for a cubic model space but can be applied in either case. An additional restriction for two-body states is that they must be composed of two different states to satisfy the Pauli-exclusion principle. 

\begin{algorithmic}
  \For{$\text{sp1}\in STATES$}
  \For{$\text{sp2}\in STATES$}
  \If{$sp1\neq sp2$}
  \State $N_{i}\gets n_{i,1}+n_{i,2}$
  \State $S_{z}\gets s_{z,1}+s_{z,2}$
  \State $T_{z}\gets t_{z,1}+t_{z,2}$
  \State $\text{i\_dir}\gets\text{Ind}\left(N_{x},N_{y},N_{z},S_{z},T_{z}\right)$
  \State $T\gets$ (sp1, sp2, i\_dir)
  \State $N'_{i}\gets n_{i,1}-n_{i,2}$
  \State $S'_{z}\gets s_{z,1}-s_{z,2}$
  \State $T'_{z}\gets t_{z,1}-t_{z,2}$
  \State $\text{i\_cross}\gets\text{Ind}\left(N'_{x},N'_{y},N'_{z},S'_{z},T'_{z}\right)$
  \State $X\gets$ (sp1, sp2, i\_cross)
  \EndIf
  \EndFor
  \EndFor
\end{algorithmic}

From the cross channels, one can construct the cross channel compliments, $X'$, where $X\left( pq\right)\equiv X'\left( qp\right)$. Also from the direct channels, one can construct one-body, and correspondint three-body, channels for each single-particle state, $K$ by finding every combination of two two-body states within a direct channel that contains that single particle state, $T\left( pq\right)=T\left( rs\right)\Rightarrow K_{p}\gets\left( qrs\right)$.

\begin{algorithmic}
  \For{$\text{Chan}\in T$}
  \For{$\text{tb1}\in\text{Chan}$}
  \For{$\text{tb2}\in\text{Chan}$}
  \State $K\gets\text{tb1}_{1}$
  \State $K_{\text{tb1}_{1}}\gets\mathop{\text{tb1}_{2},\text{tb2}_{1},\text{tb2}_{2}}$
  \EndFor
  \EndFor
  \EndFor
\end{algorithmic}

These different sctructures can be further categorized by a two-body state's particle-hole character, $\braket{pp| t |hh}, \braket{hh| v |hh}, \braket{pp| v |pp}, \braket{hh| v |pp}$, and $\braket{hp| v |hp}$, which greatly simplifies the matrix-matrix multiplications of the CCD iterations by indexing the summed variables in a systematic way. Summations are constructed by placeing two structures next to each other in such a way that the inner, summed indices are of the same channel. The resulting structure is indexed by the outer channels.

\begin{align}
\braket{b| \chi |c} = \braket{b|f|c} - \frac{1}{2} \sum_{kld} \braket{bd|t|kl} \braket{kl|v|cd} &\rightarrow f_{c}^{b}\left( K\left( b\right),K\left( c\right)\right) - \frac{1}{2}t_{kl}^{bd}\left( K\left( b\right),K_{b}\left( kld\right)\right)\cdot v_{cd}^{kl}\left( K_{c}\left( kld\right),K\left( c\right)\right) \\
\braket{k| \chi |j} = \braket{k|f|j} + \frac{1}{2} \sum_{cdl} \braket{kl|v|cd} \braket{cd|t|jl} &\rightarrow f_{j}^{k}\left( K\left( k\right),K\left( j\right)\right) + \frac{1}{2}v_{cd}^{kl}\left( K\left( k\right),K_{k}\left( cdl\right)\right)\cdot t_{jl}^{cd}\left( K_{j}\left( cdl\right),K\left( j\right)\right) \\
\braket{kl| \chi |ij} = \braket{kl|v|ij} + \frac{1}{2} \sum_{cd} \braket{kl|v|cd} \braket{cd|t|ij} &\rightarrow v_{ij}^{kl}\left( T\left( kl\right),T\left( ij\right)\right) + \frac{1}{2}v_{cd}^{kl}\left( T\left( kl\right),T\left( cd\right)\right)\cdot t_{ij}^{cd}\left( T\left( cd\right),T\left( ij\right)\right) \\
\braket{kb| \chi |cj} = \braket{kb|v|cj} + \frac{1}{2} \sum_{dl} \braket{kl|v|cd} \braket{db|t|lj} &\rightarrow v_{cj}^{kb}\left( X\left( kc\right),X\left( jb\right)\right) + \frac{1}{2}v_{cd}^{kl}\left( X\left( kc\right),X\left( dl\right)\right)\cdot t_{lj}^{db}\left( X\left( dl\right),X\left( jb\right)\right) \\
\braket{ab| \chi |cd} = \braket{ab|v|cd} &\rightarrow v_{cd}^{ab}\left( T\left( ab\right),T\left( cd\right)\right) \\
\sum_{c} \braket{b| \chi |c} \braket{ac| t |ij} &\rightarrow \chi_{c}^{b}\left( K\left( b\right),K\left( c\right)\right)\cdot t_{ij}^{ac}\left( K\left( c\right), K_{c}\left( ija\right)\right) \\
\sum_{k} \braket{k| \chi |j} \braket{ab| t |ik} &\rightarrow \chi_{j}^{k}\left( K\left( j\right),K\left( k\right)\right)\cdot t_{ik}^{ab}\left( K\left( c\right), K_{c}\left( ija\right)\right) \\
\sum_{cd} \braket{ab| \chi |cd} \braket{cd| t |ij} &\rightarrow \chi_{cd}^{ab}\left( T\left( ab\right),T\left( cd\right)\right)\cdot t_{ij}^{cd}\left( T\left( cd\right),T\left( ij\right)\right) \\
\sum_{kl} \braket{ab| t |kl} \braket{kl| \chi |ij} &\rightarrow t_{kl}^{ab}\left( T\left( ab\right),T\left( kl\right)\right)\cdot \chi_{ij}^{kl}\left( T\left( kl\right),T\left( ij\right)\right) \\ 
\sum_{kc} \braket{ac| t |ik}\braket{kb| \chi |cj} = \sum_{kc} \braket{ai^{-1}| t |kc^{-1}}\braket{kc^{-1}| \chi |jb^{-1}} &\rightarrow t_{ik}^{ac}\left( X\left( ia\right),X\left( kc\right)\right)\cdot \chi_{cj}^{kb}\left( X\left( kc\right),X\left( jb\right)\right)
\end{align}


\begin{figure}
  \includegraphics[width=\linewidth]{Chapter8-figures/fig1.pdf}
  \caption{Energy per particle of pure neutron matter computed in the CCD approximation with the Minnesota potential for different numbers of particles with $\mathrm{N_{max}=20}$.}
  \label{fig:fig1}
\end{figure}

\begin{figure}
  \includegraphics[width=\linewidth]{Chapter8-figures/fig2.pdf}
  \caption{Energy per particle of pure neutron matter computed in the CCD approximation with the Minnesota potential for different model space sizes with $\mathrm{A=20}$.}
  \label{fig:fig2}
\end{figure}

We approximated our problem with periodic boundary conditions, $\mathop{\phi(x_{i})}=\mathop{\phi(x_{i}+L)}$, but we could have chosen anti-periodic boundary conditions, $\mathop{\phi(x_{i})}=-\mathop{\phi(x_{i}+L)}$. The difference between these two shows how the correlation energy contains finite-size effects. One solution to this problem is by integrating over solutions between periodic and anti-periodic conditions, known as twist-averaging. First, we multiply the single-particle states by a phase for each direction, characterized by a twist-angle, $\theta_{i}$.
\begin{equation}
  \mathop{\phi_{\vec{k}}(\vec{x}+\vec{L})}\rightarrow\mathop{e^{i\vec{\theta}}\phi_{\vec{k}}(\vec{x})}
\end{equation}
$\theta_{i}=0$ for PBC and $\theta_{i}=\pi$ for APBC
\begin{align}
\vec{k}\rightarrow\vec{k}+\frac{\vec{\theta}}{L} \\
\epsilon_{\vec{k}}\rightarrow\epsilon_{\vec{k}}+\frac{\pi}{L}\vec{k}\cdot\vec{\theta}+\frac{\pi^{2}}{L^{2}}
\end{align}
Adding these phases changes the single-particle energies, the correction of which disappear as $L\rightarrow\infty$, depending on $\vec{\theta}$ and thus changes the shell structure so that hole states can jump up to particle states and vis a versa. So it's necessary to fill hole states separately for each $\vec{\theta}$. Integration over some quantitiy is approximated by a weighted sum, such as Gauss-Legendre quadrature, over the quantity for each set of twist angles.

\begin{algorithmic}
  \State Build mesh points and weights for each direction $i$: $\{\theta_{i},w_{i}\}$
  \State $E_{\text{twist}}=0$
  \For{$\mathop{(\theta_{x},w_{x})}\in\mathop{\{\theta_{x},w_{x}\}}$}
  \For{$\mathop{(\theta_{y},w_{y})}\in\mathop{\{\theta_{y},w_{y}\}}$}
  \For{$\mathop{(\theta_{z},w_{z})}\in\mathop{\{\theta_{z},w_{z}\}}$}
  \State Build Basis States with $k_{i}\rightarrow k_{i}+\frac{\theta_{i}}{L}$
  \State Order States by Energy and Fill Holes
  \State Get Result $E$ (T,HF,CCD)
  \State $E_{\text{twist}}=E_{\text{twist}}+\frac{1}{\pi^{3}}w_{x}w_{y}w_{z}E$
  \EndFor
  \EndFor
  \EndFor
\end{algorithmic}

This technique gives results which depend much less on the particle number, but requires a full calculation for each set of twist angles, which can grow very quickly. For example, using 10 twist angles in each direction requires 1000 calculations. To see the effects of twist averaging, it's easy to calculate the kinetic energy per particle and the Hartree-Fock energy per particle, which avoids the full CCD calculation. These calculations can be compared to the exact values for infinite matter, which are calculated by integrating the the relevent values up to the fermi surface.

\begin{align}
  \text{T}_{\text{inf}}=\frac{3\hbar^{2}k_{f}^{2}}{10m} \\
  \text{HF}_{\text{inf}}=\frac{1}{\mathop{(2\pi)^{6}}}\frac{L^{3}}{2\rho}\int_{0}^{k_{f}}d\vec{k}_{1}\int_{0}^{k_{f}}d\vec{k}_{2}\braket{\vec{k}_{1}\vec{k}_{2}|\hat{v}|\vec{k}_{1}\vec{k}_{2}}
\end{align}

\begin{figure}
  \includegraphics[width=\linewidth]{Chapter8-figures/fig3.pdf}
  \caption{Finite-size effects in the kinetic energy of pure neutron matter computed with the Minnesota potential as a function of the number of particles for both periodic boundary conditions and twist-averaged boundary conditions.}
  \label{fig:fig3}
\end{figure}

\begin{figure}
  \includegraphics[width=\linewidth]{Chapter8-figures/fig4.pdf}
  \caption{Finite-size effects in the Hartree-Fock energy of pure neutron matter computed with the Minnesota potential as a function of the number of particles for both periodic boundary conditions and twist-averaged boundary conditions.}
  \label{fig:fig4}
\end{figure}


\section{Conclusions}


\section{Exercises}

\begin{prob}
We present a simplified Hamiltonian consisting of an unperturbed
Hamiltonian and a so-called pairing interaction term. It is a model
which to a large extent mimicks some central features of atomic
nuclei, certain atoms and systems which exhibit superfluiditity or
superconductivity.  To study this system, we will use a mix of
many-body perturbation theory (MBPT), Hartree-Fock (HF) theory and full
configuration interaction (FCI) theory. The latter will also provide us with
the exact answer.  When setting up the Hamiltonian matrix you will
need to solve an eigenvalue problem.

We define first the Hamiltonian, with a definition of the model space
and the single-particle basis. Thereafter, we present the various
exercises (some of them are solved).


The Hamiltonian acting in the complete Hilbert space (usually infinite
dimensional) consists of an unperturbed one-body part, $\hat{H}_0$,
and a perturbation $\hat{V}$.

We limit ourselves to at most two-body interactions and our Hamiltonian
is represented by the following operators
\[
\hat{H} = \sum_{\alpha\beta}\langle \alpha |h_0|\beta\rangle
a_{\alpha}^{\dagger}a_{\beta}+\frac{1}{4}\sum_{\alpha\beta\gamma\delta}\langle \alpha\beta|
V|\gamma\delta\rangle a_{\alpha}^{\dagger}a_{\beta}^{\dagger}a_{\delta}a_{\gamma},
\]
where $a_{\alpha}^{\dagger}$ and $a_{\alpha}$ etc.~are standard
fermion creation and annihilation operators, respectively, and
$\alpha\beta\gamma\delta$ represent all possible single-particle
quantum numbers.  The full single-particle space is defined by the
completeness relation
\[
\hat{{\bf 1}} = \sum_{\alpha=1}^{\infty}|\alpha \rangle \langle \alpha|.
\]
In our calculations
we will let the single-particle states $|\alpha\rangle$ be
eigenfunctions of the one-particle operator $\hat{h}_0$. Note that the two-body part of the Hamiltonian
contains anti-symmetrized matrix elements.


The above Hamiltonian acts in turn on various many-body Slater
determinants constructed from the single-basis defined by the one-body
operator $\hat{h}_0$.  As an example, the two-particle model space
$\mathcal{P}$ is defined by an operator
\[
\hat{P} = \sum_{\alpha\beta =1}^{m}|\alpha\beta \rangle \langle
\alpha\beta|,
\]
where we assume that $m=\dim(\mathcal{P})$ and the full space is
defined by
\[
\hat{P}+\hat{Q}=\hat{{\bf 1}},
\]
with the projection operator
\[
\hat{Q} = \sum_{\alpha\beta =m+1}^{\infty}|\alpha\beta \rangle \langle
\alpha\beta|,
\]
being the complement of $\hat{P}$.


Our specific model consists of $N$ doubly-degenerate and equally
spaced single-particle levels labelled by $p=1,2,\dots$ and spin
$\sigma=\pm 1$.  These states are schematically portrayed in
Fig.~ref{fig:schematic}.  The first two single-particle levels define
a possible model space, indicated by the label $\mathcal{P}$.  The
remaining states span the excluded space $\mathcal{Q}$.

We write the Hamiltonian as
\[ \hat{H} = \hat{H}_0 + \hat{V} , \]
where
\[
\hat{H}_0=\xi\sum_{p\sigma}(p-1)a_{p\sigma}^{\dagger}a_{p\sigma}
\]
and
\[
\hat{V}=-\frac{1}{2}g\sum_{pq}a^{\dagger}_{p+}
a^{\dagger}_{p-}a_{q-}a_{q+}.
\]
Here, $H_0$ is the unperturbed Hamiltonian with a spacing between
successive single-particle states given by $\xi$, which we will set to
a constant value $\xi=1$ without loss of generality. The two-body
operator $\hat{V}$ has one term only. It represents the pairing
contribution and carries a constant strength $g$.

The indices
$\sigma=\pm$ represent the two possible spin values. The interaction
can only couple pairs and excites therefore only two particles at the
time.

Show that the unperturbed Hamiltonian $\hat{H}_0$ and $\hat{V}$
  commute with both the spin projection $\hat{S}_z$ and the total spin
  $\hat{S}^2$, given by
\[
  \hat{S}_z := \frac{1}{2}\sum_{p\sigma} \sigma
  a^{\dagger}_{p\sigma}a_{p\sigma}
\]
and
\[
  \hat{S}^2 := \hat{S}_z^2 + \frac{1}{2}(\hat{S}_+\hat{S}_- +
  \hat{S}_-\hat{S}_+),
\]
where
\[
  \hat{S}_\pm := \sum_{p} a^{\dagger}_{p\pm} a_{p\mp}.
\]
This is an important feature of our system that allows us to
block-diagonalize the full Hamiltonian. We will focus on total spin
$S=0$.  In this case, it is convenient to define the so-called pair
creation and pair annihilation operators
\[
\hat{P}^{+}_p = a^{\dagger}_{p+}a^{\dagger}_{p-},
\]
and
\[
\hat{P}^{-}_p = a_{p-}a_{p+},
\]
respectively.

Show that you can rewrite the Hamiltonian (with $\xi=1$) as
\[
\hat{H}=\sum_{p\sigma}(p-1)a_{p\sigma}^{\dagger}a_{p\sigma}
-\frac{1}{2}g\sum_{pq}\hat{P}^{+}_p\hat{P}^{-}_q.
\]
Show also that Hamiltonian commutes with the product of the pair
creation and annihilation operators.  This model corresponds to a
system with no broken pairs. This means that the Hamiltonian can only
link two-particle states in so-called spin-reversed states.

Construct thereafter the Hamiltonian matrix for a system with no
  broken pairs and total spin $S=0$ for the case of the four lowest
  single-particle levels indicated in the
  Fig.~ref{fig:schematic}. Our system consists of four particles
  only.  Our single-particle space consists of only the four lowest
  levels $p=1,2,3,4$.  You need to set up all possible Slater
  determinants.  Find all eigenvalues by diagonalizing the Hamiltonian
  matrix.  Vary your results for values of $g\in [-1,1]$.  We refer to
  this as the exact calculation. Comment the behavior of the ground
  state as function of $g$.



We give first the final Hamiltonian matrix
!bt
\[
H = \left (
\begin{array}{cccccc}
2\delta -g & -g/2 & -g/2 & -g/2 & -g/2 & 0 \\
 -g/2 & 4\delta -g & -g/2 & -g/2 & -0 & -g/2 \\
-g/2 & -g/2 & 6\delta -g & 0 & -g/2 & -g/2 \\
 -g/2 & -g/2 & 0 & 6\delta-g & -g/2 & -g/2 \\
 -g/2 & 0 & -g/2 & -g/2 & 8\delta-g & -g/2 \\
0 & -g/2 & -g/2 & -g/2 & -g/2 & 10\delta -g
\end{array} \right )
\]

The following python program diagonalizes the above Hamiltonian matrix for a given span of interaction strength values, performing both a full configuration interaction calculation and a truncated one. For the truncated case we leave out the $4p4h$ state. This means that in addition to the ground state we include the four possible $2p2h$ states. Such a calculation is normally called a configuration interaction calculation.
\begin{lstlisting}
from numpy import *
from sympy import *
from matplotlib.pyplot import *

g_array = linspace(-1, 1, 1001)
e1_array = []
e2_array = []

for g in g_array:
	H1 = matrix([[2-g , -g/2.,  -g/2., -g/2., -g/2.,     0],
		        [-g/2.,   4-g,  -g/2., -g/2.,    0., -g/2.],
		        [-g/2., -g/2.,    6-g,     0, -g/2., -g/2.],
				[-g/2., -g/2.,      0,   6-g, -g/2., -g/2.],
				[-g/2.,     0,  -g/2., -g/2.,   8-g, -g/2.],
				[0    , -g/2.,  -g/2., -g/2., -g/2.,  10-g]])

	H2 = matrix([[2-g , -g/2.,  -g/2., -g/2., -g/2.],
		        [-g/2.,   4-g,  -g/2., -g/2.,    0.],
		        [-g/2., -g/2.,    6-g,     0, -g/2.],
				[-g/2., -g/2.,      0,   6-g, -g/2.],
				[-g/2.,     0,  -g/2., -g/2.,   8-g]])



	u1, v1 = linalg.eig(H1)
	u2, v2 = linalg.eig(H2)

	if g == 1./2:
		print argmin(u1)

		for i in range(5):
			print " %.3f " % v2[i,0],



	e1_array.append(min(u1))
	e2_array.append(min(u2))


plot(g_array, e1_array, linewidth=2.0)
#plot(g_array, e2_array, linewidth=2.0)
plot(g_array, (2-g_array), linewidth=2.0)
grid()
xlabel(r"Strength of interaction, $g$", fontsize=16)
ylabel(r'Ground state energy', fontsize=16)
#axis([-1,1,-0.4,0.05])
legend(['FCI -- Exact', 'Reference energy'])
savefig("pairing.pdf")
show()
\end{lstlisting}
The eigenvalues and eigenvectors result from the diagonalization of the above Hamiltonian matrix.
In the discussions below and in connection with the first stage of the numerical project, we will use these results to benchmark various approximative methods.
The lowest eigenvalue corresponds to the ground state
energy and we will refer to it as the *exact energy* when no truncations in the space of possible Slater determinants are made..

From our results, we note some important differences between the full configuration interaction (FCI)
calculation and the truncated configuration interaction calculation (CI).
Full configuration interaction is an exact method, but is only
possible if and only if we have a complete and finite SD basis for our
system. In practice, we usually don't have this. Non-complete
CI however, is always possible, but yiels   approximative
results only. The method is however still variational however, meaning that we
guaranteed that the approximation will be equal or bigger to the true
result.
Perturbation theory however, is non-variational and there is no guarantee that including higher orders in the
perturbation gives an improved result, as we will see below.

In an FCI case, we are including all possible exictations to infinite
order, meaning we have all possible $1p1h$ , $2p2h$ etc configurations, up to $4p4h$
excitations for our selected model. Due to the nature of the pairing interaction and our selection
of specific quantum numbers for the many-body states, we do not have any $1p1h$ or $3p3h$ excitations.
In the above CI case, we truncate those excitations somewhere.
If we
were to draw the diagrams of the interactions that contribute to this
CI case, there would be an infinite number of them, as we can have
arbitrarily long chains of operators that still only have at most 2p2h
intermediate states.


We switch now to approximative methods, in our case Hartree-Fock
  theory and many-body perturbation theory. Hereafter we will define
  our model space to consist of the single-particle levels $p=1,2$.
  The remaining levels $p=3,4$ define our excluded space.  This means
  that our ground state Slater determinant consists of four particles
  which can be placed in the doubly degenerate orbits $p=1$ and $p=2$.
  Our first step is to perform a Hartree-Fock calculation with the
  pairing Hamiltonian.  Write first the normal-ordered Hamiltonian
  with respect to the above reference state given by four spin $1/2$
  fermions in the single-particle levels $p=1,2$. Define what is meant
  by a canonical Hartree-Fock case, a non-canonical case and a general
  case.  For all three cases, write down the normal-ordered
  Hamiltonian and draw the diagrammatic form of the Hamiltonian for all three cases.

We will now set up the Hartree-Fock equations by varying the
coefficients of the single-particle functions. The single-particle
basis functions are defined as
\[
\psi_p = \sum_{\lambda} C_{p\lambda}\psi_{\lambda}.
\]
where in our case $p=1,2,3,4$ and $\lambda=1,2,3,4$, that is the first
four lowest single-particle orbits of Fig.~ref{fig:schematic}.  Set
up the Hartree-Fock equations for this system by varying the
coefficients $C_{p\lambda}$ and solve them for values of $g\in
[-1,1]$.  Comment your results and compare with the exact
solution. Discuss also which diagrams in Fig.~ref{fig:diagrams} that
can be affected by a Hartree-Fock basis. Compute the total binding
energy using a Hartree-Fock basis and comment your results.


We will now study the system using non-degenerate
Rayleigh-Schroedinger perturbation theory to third order in the
interaction.  If we exclude the first order contribution, all possible
diagrams (so-called anti-symmetric Goldstone diagrams) are
shown in Fig.~ref{fig:diagrams}.


Based on the form of the interaction, which diagrams contribute to the
binding energy of the ground state?  Write down the expressions for
the diagrams that contribute and find the contribution to the ground
state energy as function $g\in [-1,1]$. Comment your results.  Compare
these results with those you obtained from the exact diagonalization with and without the $4p-4h$ state.
Discuss your results for a canonical Hartree-Fock basis and a non-canonical Hartree-Fock basis.


Diagram 1 in Fig.~ref{fig:diagrams} represents a second-order contribution to the energy and a so-called $2p-2h$ contribution to the intermediate states. Write down the expression for the wave operator in this case and compare the possible contributions with the configuration interaction calculations without the $4p-4h$ Slater determinant. Comment your results for
various values of $g\in [-1,1]$.

We limit now the discussion to the canonical Hartree-Fock case only. To fourth order in perturbation theory we can produce diagrams with $1p-1h$ intermediate excitations as shown in Fig.~ref{fig:fourthorder1p1h}, $2p-2h$ excitations, see Fig.~ref{fig:fourthorder2p2h}, $3p-3h$ excitations as shown in Fig.~ref{fig:fourthorder3p3h} and finally so-called diagrams with intermediate four-particle-four-hole excitations, see Fig.~ref{fig:fourthorder4p4h}.

Define first linked and unlinked diagrams and explain briefly Goldstone's linked diagram theorem.
Based on the linked diagram theorem and the form of the pairing Hamiltonian, which diagrams will contribute
to fourth order?

Calculate the energy to fourth order with a canonical Hartree-Fock basis for $g\in [-1,1]$ and compare
with the full diagonalization case in exercise b). Discuss the results.

To fourth order in the interaction there are several diagrams to consider.
Fortunately, due to the character of the pairing Hamiltonian, several of these contributions are
zero. We limit our discussions also to include the
canonical HF-case only.
All of the diagrams in the canonical case are
shown in figures 3, 4, 5 and 6 above.
Using also the linked diagram theorem, where a
diagram is called unlinked if and only if it has a disconnected part
that is closed, we can eliminate some further  diagrams. Goldstones
linked-diagram theorem states that all unliked diagrams will cancel
against the renormalization terms in Rayleigh-Schroedinger perturbation theory,
meaning that we can define
the energy to each order as a sum of linked diagrams
only. We can then disregard diagram 33 and 41.

Let us now go through all the diagrams and find those that vanish due
to having broken pairs, i.e., the diagrams that vanish due to our
specific interaction. Take for example diagram 1, which vanishes due
to having a term $\langle ab\vert \hat{v} \vert ci\rangle$. From this
argument, we see that all four diagrams from figure 3 vanish. Similar
arguments shows that most diagrams in figure 4 also dissapear. Going
through all the diagrams, we see that 5, 6, 14 and 15 are the ones
that do not vanish in figure 4. For figure 5 we actually see that all
diagrams vanish again. For figure 6 we already found that 33 and 41
vanished due to being unlinked---the rest contribute to the perturbative expansion of the
energy.
The diagrams of figures 3 and 5 vanish since they involve $1p1h$ and $3p3h$ excitations, respectively.

The expressions for these diagrams can easily be written in terms of a
simple Python program. Note however that for every diagram we do
actually perform loops over every single-particle state. As we will
see later, this is extremely inefficient from a computational point
of view. In our discussions of the projects below, we will rewrite the
computations of most diagrams in terms of efficient matrix-matrix
multiplications or matrix-vector multiplications.  The following
Python program gives us the final results for perturbation theory to fourth
order in the interaction. The resulting figures include also plots of the relative error in the
correlation energy. That is, we compare the computed correlation in
perturbation theory with the result from the exact diagonalization discussed above.

\begin{lstlisting}
from sympy import *
from pylab import *

below_fermi = (0,1,2,3)
above_fermi = (4,5,6,7)

states = [(1,1),(1,-1),(2,1),(2,-1),(3,1),(3,-1),(4,1),(4,-1)]
N = 8
g = Symbol('g')



def h0(p,q):
	if p == q:
		p1, s1 = states[p]
		return (p1 - 1)
	else:
		return 0

def f(p,q):
	if p == q:
		return 0

	s = h0(p,q)
	for i in below_fermi:
		s += assym(p,i,q,i)
	return s


def assym(p,q,r,s):
	p1, s1 = states[p]
	p2, s2 = states[q]
	p3, s3 = states[r]
	p4, s4 = states[s]

	if p1 != p2 or p3 != p4:
		return 0
	if s1 == s2 or s3 == s4:
		return 0
	if s1 == s3 and s2 == s4:
		return -g/2.
	if s1 == s4 and s2 == s3:
		return g/2.

def eps(holes, particles):
	E = 0
	for h in holes:
		p, s = states[h]
		E += (p-1)
	for p in particles:
		p, s = states[p]
		E -= (p-1)
	return E


# Diagram 3
# s = 0
# for a in above_fermi:
# 	for b in above_fermi:
# 		for c in above_fermi:
# 			for i in below_fermi:
# 				for j in below_fermi:
# 					for k in below_fermi:
# 						s += assym(i,j,a,b)*assym(a,c,j,k)*assym(b,k,c,i)/eps((i,j),(a,b))/eps((k,j),(a,c))
# print s


# ga = linspace(-1,1,101)
# corr2 = []
# corr3 = []
# corrx = []


# Diagram 1
s1 = 0
for a in above_fermi:
	for b in above_fermi:
		for i in below_fermi:
			for j in below_fermi:
				s1 += 0.25*assym(a,b,i,j)*assym(i,j,a,b)/eps((i,j),(a,b))

# Diagram 4
s4 = 0
for a in above_fermi:
	for b in above_fermi:
		for c in above_fermi:
			for d in above_fermi:
				for i in below_fermi:
					for j in below_fermi:
						s4 += 0.125*assym(i,j,a,b)*assym(a,b,c,d)*assym(c,d,i,j)/eps((i,j),(a,b))/eps((i,j),(c,d))

# Diagram 5
s5 = 0
for a in above_fermi:
	for b in above_fermi:
		for i in below_fermi:
			for j in below_fermi:
				for k in below_fermi:
					for l in below_fermi:
						s5 += 0.125*assym(i,j,a,b)*assym(k,l,i,j)*assym(a,b,k,l)/eps((i,j),(a,b))/eps((k,l),(a,b))

# Diagram 8 (simplified)
s8 = 0
for a in above_fermi:
	for b in above_fermi:
		for i in below_fermi:
			for j in below_fermi:
				for k in below_fermi:
					s8 -= 0.5*assym(i,j,a,b)*assym(a,b,i,k)*f(k,j)/eps((i,j),(a,b))/eps((i,k),(a,b))

# Diagram 9 (simplified)
s9 = 0
for a in above_fermi:
	for b in above_fermi:
		for c in above_fermi:
			for i in below_fermi:
				for j in below_fermi:
					s9 += 0.5*assym(i,j,a,b)*assym(a,c,i,j)*f(b,c)/eps((i,j),(a,b))/eps((i,j),(a,c))


print s1
print s4
print s5
print s8
print s9

s_5 =  -0.0291521990740741*g**4
s14 =  -0.0308883101851853*g**4
s34 =  0.0163049768518519*g**4
s36 =  -0.0145760995370371*g**4
s38 =  -0.0201099537037037*g**4
s39 =  0.0176938657407407*g**4

ga = linspace(-1,1,10001)
e1 = []
corr2 = []
corr3 = []
corr4 = []
for g_val in ga:
	H1 = matrix([[2-g_val , -g_val/2.,  -g_val/2., -g_val/2., -g_val/2.,     0],
		        [-g_val/2.,   4-g_val,  -g_val/2., -g_val/2.,    0., -g_val/2.],
		        [-g_val/2., -g_val/2.,    6-g_val,     0, -g_val/2., -g_val/2.],
				[-g_val/2., -g_val/2.,      0,   6-g_val, -g_val/2., -g_val/2.],
				[-g_val/2.,     0,  -g_val/2., -g_val/2.,   8-g_val, -g_val/2.],
				[0    , -g_val/2.,  -g_val/2., -g_val/2., -g_val/2.,  10-g_val]])

	u1, v1 = linalg.eig(H1)
	e1.append(min(u1))

	corr2.append((s1).subs(g,g_val))
	corr3.append((s1+s4+s5).subs(g,g_val))
	corr4.append((s1+s4+s5+2*s_5+2*s14+2*s34+2*s36+s38+2*s39).subs(g,g_val))

exact = e1 - (2-ga)

plot(ga, exact, linewidth=2.0)
plot(ga, corr2, linewidth=2.0)
plot(ga, corr3, linewidth=2.0)
plot(ga, corr4, linewidth=2.0)
xlabel(r'Interaction strength, $g$', fontsize=16)
ylabel(r'Correlation energy', fontsize=16)
axis([-1,1,-0.5,0.05])
grid()
legend(["Exact", "2. order MPBT", "3. order MPBT", "4. order MPBT"], 'lower left')
savefig("perturbationtheory.pdf")
show()
error1 = zeros(len(exact))
error2 = zeros(len(exact))
error3 = zeros(len(exact))

for i in range(len(exact)):
	error1[i] = abs(float(exact[i]-corr2[i]))
	error2[i] = abs(float(exact[i]-corr3[i]))
	error3[i] = abs(float(exact[i]-corr4[i]))

error1 = array(error1)
error2 = array(error2)
error3 = array(error3)
print type(error1)

plot(ga, log10(error1))
plot(ga, log10(error2))
plot(ga, log10(error3))
xlabel(r"Strength of interaction, $g$", fontsize=16)
ylabel(r"Error, $\log_{\rm 10}({\rm abs}({\rm error})$", fontsize=16)
legend(["2. order MPBT", "3. order MPBT", "4. order MPBT"], 'lower left')
grid()
savefig("logerror.pdf")
show()
\end{lstlisting}

Running the Python program shows us that
the approximation to both second and third order are very
good when the interaction strength is small and contained in the interval
$g\in[-0.5,0.5]$, but as the
interaction gets stronger the approximation worsens. We also
note that the third-order result is actually worse than the second order result
for larger values of the interaction strength, indicating that there is no guarantee that higher orders
in many-body perturbation theory may reduce the relative error in a systematic way.
This is seen in particular for the results to fourth order. For negative interaction strengths
fourth order gives a better result than second and third order, while for $g>0$ the relative error is
worse.
We note also the non-variational character of many-body perturbation theory, with results at different undershooting the true ground state correlation energy

\end{prob}


\begin{prob}
This project serves as a continuation
of the pairing model with the aim being to solve the same problem but
now by developing a program that implements the coupled cluster method
with double excitations only. In doing so you will find it convenient
to write classes which define the single-particle basis and the
Hamiltonian. Your functions that solve the coupled cluster equations
will then just need to set up variables which point to interaction
elements and single-particle states with their pertinent quantum
numbers. Use for example the setup discussed in the FCI lectures for
the pairing model.


Explain why no single excitations are involved in this model.



Set up the coupled cluster equations for doubles excitations and convince yourself about their
meaning and correctness.

Write a class which holds
single-particle data like specific quantum numbers, single-particle
Hamiltonian etc. Write also a class which sets up and stores two-body
matrix elements defined by the single-particle states.  Write
thereafter functions/classes which implement the coupled cluster
method with doubles only.



Compare your results with
those from the exact diagonalization with and without the $4p4h$
excitation. Compare also your results to perturbation theory at
different orders, in particular to second order. Discuss your results.
If other students are solving the same problem using Green's function
theory, you can also compare your results with those obtained from
Green's function theory. The aim is to finalize this part during the
first week. The codes you will develop can be used as a starting point
for the second part of the project.

\end{prob}

\begin{prob}
Consider a Slater determinant built up of orthogonal single-particle orbitals $\psi_{\lambda}$, 
with $\lambda = 1,2,\dots,A$.

The unitary transformation
\[
\psi_a  = \sum_{\lambda} C_{a\lambda}\phi_{\lambda},
\]
brings us into the new basis.  
The new basis has quantum numbers $a=1,2,\dots,A$.
Show that the new basis is orthogonal.

Show that the new Slater determinant constructed from the new single-particle wave functions can be
written as the determinant based on the previous basis and the determinant of the matrix $C$.

Show that the old and the new Slater determinants are equal up to a complex constant with absolute value unity.
Hint: $C$ is a unitary matrix. 


We will assume that we can build various Slater determinants using an orthogonal  single-particle basis $\psi_{\lambda}$, 
with $\lambda = 1,2,\dots,A$. 


The aim of this exercise is to set up specific matrix elements that will turn useful when we start our discussions of the nuclear shell model. In particular you will notice, depending on the character of the operator, that many matrix elements will actually be zero.

Consider three $A$-particle  Slater determinants  $|\Phi_0$, $|\Phi_i^a\rangle$ and $|\Phi_{ij}^{ab}\rangle$, where the notation means that 
Slater determinant $|\Phi_i^a\rangle$ differs from $|\Phi_0\rangle$ by one single-particle state, that is a single-particle
state $\psi_i$ is replaced by a single-particle state $\psi_a$. 
It will later be interpreted as a so-called one-particle-one-hole excitation.
Similarly, the Slater determinant $|\Phi_{ij}^{ab}\rangle$
differs by two single-particle states from $|\Phi_0\rangle$ and is normally thought of as a two-particle-two-hole excitation.

Define a general onebody operator $\hat{F} = \sum_{i}^A\hat{f}(x_{i})$ and a general  twobody operator $\hat{G}=\sum_{i>j}^A\hat{g}(x_{i},x_{j})$ with $g$ being invariant under the interchange of the coordinates of particles $i$ and $j$. You can use here the results from the second exercise set, exercise 3.
Calculate
\[
\langle \Phi_0 \vert\hat{F}\vert\Phi_0\rangle,
\]
and
\[
\langle \Phi_0\vert\hat{G}|\Phi_0\rangle.
\]

Find thereafter 
\[
\langle \Phi_0 |\hat{F}|\Phi_i^a\rangle,
\]
and
\[
\langle \Phi_0|\hat{G}|\Phi_i^a\rangle,
\]

Finally, find
\[
\langle \Phi_0 |\hat{F}|\Phi_{ij}^{ab}\rangle,
\]
and
\[
\langle \Phi_0|\hat{G}|\Phi_{ij}^{ab}\rangle.
\]

What happens with the two-body operator if we have a transition probability  of the type
\[
\langle \Phi_0|\hat{G}|\Phi_{ijk}^{abc}\rangle,
\]
where the Slater determinant to the right of the operator differs by more than two single-particle states?

With an orthogonal basis of Slater determinants $\Phi_{\lambda}$, we can now construct an exact many-body state as a linear expansion of Slater determinants, that is, a given exact state
\[
\Psi_i = \sum_{\lambda =0}^{\infty}C_{i\lambda}\Phi_{\lambda}.
\]
In all practical calculations the infinity is replaced by a given truncation in the sum. 

If you are to compute the expectation value of (at most) a two-body Hamiltonian for the above
exact state
\[
\langle \Psi_i \vert \hat{H} \vert \Psi_i\rangle,
\]
based on the calculations above, which are the only elements which will contribute?  (there is no need to perform any calculation here, use your results from exercises a), b), and c)).

These results simplify to a large extent shell-model calculations. 
\end{prob}


\begin{acknowledgement}
We are much indebted to Thomas Papenbrock for many discussions on many-body physics.
Computational resources were provided by Michigan State University and the Research Council of Norway via the Notur project (Supercomputing grant NN2977K).
This work was supported by NSF Grant No. PHY-1404159 and  the Research Council of Norway under contract ISP-Fysikk/216699.
\end{acknowledgement}







