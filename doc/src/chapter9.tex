\title{Many-body methods and infinite nuclear matter}
\author{Morten Hjorth-Jensen, Gaute Hagen, Justin G.~Lietz and Samuel Novario}
\institute{Morten Hjorth-Jensen  \at Department of Physics and Astronomy and National Superconducting Cyclotron Laboratory, Michigan State University, East Lansing, Michigan,  USA and Department of Physics, University of Oslo, Oslo, Norway, \email{hjensen@msu.edu}, \and Gaute Hagen \at Oak Ridge National Laboratory, Physics Division, Oak Ridge, Tennessee, USA and Department of Physics and Astronomy, University of Tennessee, Knoxville, Tennessee, USA, \email{hageng@ornl.gov}, \and Justin G.~Lietz \at Department of Physics and Astronomy and National Superconducting Cyclotron Laboratory, Michigan State University, East Lansing, Michigan,  USA, \email{lietz@nscl.msu.edu}, \and Samuel Novario \at Department of Physics and Astronomy and National Superconducting Cyclotron Laboratory, Michigan State University, East Lansing, Michigan,  USA, \email{novarios@nscl.msu.edu}}

\maketitle
\abstract{Here we present and discuss various many-body methods } 


%\maketile

\section{Introduction}

Studies of infinite nuclear matter play an important role in nuclear
physics. The aim of this part of the lectures is to provide the
necessary ingredients for perfoming studies of neutron star matter (or
matter in $\beta$-equilibrium) and symmetric nuclear matter. We start
however with the electron gas in two and three dimensions for both
historical and pedagogical reasons. Since there are several benchmark
calculations for the electron gas, this small detour will allow us to
establish the necessary formalism. Thereafter we will study infinite
nuclear matter
\begin{itemize}
\item at the Hartree-Fock with realistic nuclear forces and

\item using many-body methods like coupled-cluster theory or in-medium SRG as discussed in our previous sections.
\end{itemize}

Studies of dense baryonic matter are of central importance to our basic understanding 
of the stability of nuclear matter, spanning from matter at high densities and temperatures
to matter as found within dense astronomical objects  like neutron stars. 

Neutron star matter
at densities of  0.1 fm$^{-3}$ and greater, is often assumed to 
be made of mainly neutrons, protons, electrons and 
muons in beta equilibrium. However, other baryons like various hyperons may exist, as well as possible mesonic condensates and transitions to quark degrees of freedom at higher densities. 
Here we focus on specific definitions of various phases and focus 
on distinct phases of matter such as pure baryonic
matter and/or quark matter.
The composition of matter is then 
determined by the requirements of chemical and electrical equilibrium.
Furthermore, we will also consider matter at temperatures much lower
than the typical Fermi energies.
The equilibrium conditions are governed by the weak processes 
(normally referred to as the processes
for $\beta$-equilibrium)
\begin{equation} 
      b_1 \rightarrow b_2 + l +\bar{\nu}_l \hspace{1cm} b_2 +l \rightarrow b_1 
+\nu_l,
      \label{eq:betadecay}
\end{equation}
where $b_1$ and $b_2$ refer to e.g.\  the baryons being a neutron and a proton, 
respectively, 
$l$ is either an electron or a muon and  $\bar{\nu}_l $
and $\nu_l$ their respective anti-neutrinos and neutrinos. Muons typically 
appear at
a density close to nuclear matter saturation density, the latter being
\[
     n_0 \approx 0.16 \pm 0.02 \hspace{1cm} \mathrm{fm}^{-3},
\]
with a corresponding binding energy ${\cal E}_0$ 
for symmetric nuclear matter (SNM) at saturation density of
\[
     {\cal E}_0 = B/A=-15.6\pm 0.2 \hspace{1cm} \mathrm{MeV}.
\]
In this work the energy per baryon ${\cal E}$ will always be in units of MeV, 
while
the energy density $\varepsilon$ will 
be in units of MeVfm$^{-3}$ and the number density\footnote{We will often 
loosely just use density in our discussions.}
$n$ in units of fm$^{-3}$. The pressure $P$ is 
defined through the relation
\begin{equation}
    P=n^2\frac{\partial {\cal E}}{\partial n}=
      n\frac{\partial \varepsilon}{\partial n}-\varepsilon,
\end{equation}
with 
dimension MeVfm$^{-3}$. 
Similarly, the chemical potential for particle species $i$
is given by
\begin{equation}
     \mu_i = \left(\frac{\partial \varepsilon}{\partial n_i}\right),
     \label{eq:chemicalpotdef}
\end{equation}
with dimension MeV.
In calculations of properties of neutron star matter in $\beta$-equilibrium,
we will need to calculate the energy per baryon ${\cal E}$ for e.g.~several 
proton fractions $x_p$, which corresponds to
the ratio of protons as
compared to the total nucleon number ($Z/A$), 
 defined as
\begin{equation}
    x_p = \frac{n_p}{n},
\end{equation}
where $n=n_p+n_n$, the total baryonic density if neutrons and
protons are the only baryons present. In that case,
the total Fermi momentum $k_F$ and the Fermi momenta $k_{Fp}$,
$k_{Fn}$ for protons and neutrons are related to the total nucleon density
$n$ by
\begin{align}
     n = & \frac{2}{3\pi^2} k_F^3 \nonumber \\
       = & x_p n + (1-x_p) n \nonumber \\
       = & \frac{1}{3\pi^2} k_{Fp}^3 + \frac{1}{3\pi^2} k_{Fn}^3.
    \label{eq:densi}
\end{align}
The energy per baryon will thus be
labelled as ${\cal E}(n,x_p)$.
${\cal E}(n,0)$ will then refer to the energy per baryon for pure neutron
matter (PNM) while ${\cal E}(n,\frac{1}{2})$ is the corresponding value for 
SNM. Furthermore, in this work, subscripts $n,p,e,\mu$
will always refer to neutrons, protons, electrons and muons, respectively.


Since the mean free path of a neutrino in a neutron star is bigger
than the typical radius of such a star ($\sim 10$ km), 
we will throughout assume that neutrinos escape freely from the neutron star,
see for example  the work of Prakash et al.
for a discussion
on trapped neutrinos. Eq. (\ref{eq:betadecay}) yields then the following
conditions for matter in $\beta$ equilibrium with for example  nucleonic degrees 
freedom only
\begin{equation}
    \mu_n=\mu_p+\mu_e,
     \label{eq:npebetaequilibrium}
\end{equation}
and 
\begin{equation}
     n_p = n_e,
     \label{eq:chargeconserv}
\end{equation}
where $\mu_i$ and $n_i$ refer to the chemical potential and number density
in fm$^{-3}$ of particle species $i$. 
If muons are present as well,  we need to modify the equation for 
charge conservation, Eq. (\ref{eq:chargeconserv}), to read 
\[
     n_p = n_e+n_{\mu},
\]
and require that $\mu_e = \mu_{\mu}$.
With more particles present, the equations read
\begin{equation}
    \sum_i\left(n_{b_i}^+ +n_{l_i}^+\right) =   
    \sum_i\left(n_{b_i}^- +n_{l_i}^-\right),
    \label{eq:generalcharge}
\end{equation}
and 
\begin{equation} 
     \mu_n=b_i\mu_i+q_i\mu_l,
     \label{eq:generalbeta}
\end{equation}
where $b_i$ is the baryon number, $q_i$ the lepton charge and the superscripts 
$(\pm)$ on 
number densities $n$ represent particles with positive or negative charge.
To give an example, it is possible to have baryonic matter with hyperons like
$\Lambda$ 
and $\Sigma^{-,0,+}$ and isobars $\Delta^{-,0,+,++}$ as well in addition
to the nucleonic degrees of freedom.
In this case the chemical equilibrium condition of Eq. (\ref{eq:generalbeta}  ) 
becomes,
excluding muons,
\begin{align}
    \mu_{\Sigma^-} = \mu_{\Delta^-} = \mu_n + \mu_e , \nonumber \\ 
    \mu_{\Lambda} = \mu_{\Sigma^0} = \mu_{\Delta^0} = \mu_n , \nonumber \\
    \mu_{\Sigma^+} = \mu_{\Delta^+} = \mu_p = \mu_n - \mu_e ,\nonumber \\
    \mu_{\Delta^{++}} = \mu_n - 2 \mu_e .
    \label{eq:beta_baryonicmatter}
\end{align}
A transition from hadronic to quark matter is expected at high densities. 
The high-density quark matter phase
in the interior of neutron stars is also described by
requiring the system to be locally neutral
\begin{equation} 
    \label{eq:quarkneut}
    (2/3)n_u -(1/3)n_d - (1/3)n_s - n_e = 0,
\end{equation}
where $n_{u,d,s,e}$ 
are the densities of the $u$, $d$ and $s$ quarks and of the
electrons (eventually muons as well), respectively. 
Morover, the system must be in $\beta$-equilibrium, i.e.\ 
the chemical potentials have to satisfy the following equations:
\begin{equation}
      \label{eq:ud}
      \mu_d=\mu_u+\mu_e,
\end{equation}
and
\begin{equation}
      \label{eq:us}
      \mu_s=\mu_u+\mu_e .
\end{equation}
Equations (\ref{eq:quarkneut})-(\ref{eq:us}) have to be solved 
self-consistently together with the field equations for quarks 
at a fixed density $n=n_u+n_d+n_s$.

An important ingredient in the discussion of the EoS and the criteria for
matter in $\beta$-equilibrium is the so-called symmetry energy ${\cal S} (n)$, 
defined as
the difference in energy for symmetric nuclear matter
and pure neutron matter 
\begin{equation}
      {\cal S} (n) = {\cal E} (n,x_p=0) - {\cal E} (n,x_p=1/2 ).
      \label{eq:symenergy}
\end{equation}
If we expand the energy per baryon in the case of nucleonic degrees of freedom 
only
in the proton concentration $x_p$ about the value of the energy 
for SNM ($x_p=\frac{1}{2}$), we obtain,
\begin{equation}
     {\cal E} (n,x_p)={\cal E} (n,x_p=\frac{1}{2})+
     \frac{1}{2}\frac{d^2 {\cal E}}{dx_p^2} (n)\left(x_p-1/2\right)^2+\dots ,
     \label{eq:energyexpansion}
\end{equation}
where the term $d^2 {\cal E}/dx_p^2$ 
is to be associated with the symmetry energy ${\cal S} (n)$ in the empirical
mass formula. If
we assume that higher order derivatives in the above expansion are small
(we will see examples of this in the next subsection), then through the 
conditions
for $\beta$-equilbrium of Eqs. (\ref{eq:npebetaequilibrium}) and 
(\ref{eq:chargeconserv})
and Eq. (\ref{eq:chemicalpotdef}) we can define the proton
fraction by the symmetry energy as
\begin{equation}  
    \hbar c\left(3\pi^2nx_p\right)^{1/3} = 4{\cal S} (n)\left(1-2x_p\right),
    \label{eq:crudeprotonfraction}
\end{equation}
where the electron chemical potential is given
by $\mu_e = \hbar c k_F$, i.e.\  ultrarelativistic electrons are assumed.
Thus, the symmetry energy is of paramount importance for studies 
of neutron star matter in $\beta$-equilibrium.
One can extract information about the value of the symmetry energy at saturation 
density
$n_0$ from systematic studies of the masses of atomic nuclei. However, these 
results
are limited to densities around $n_0$ and for proton fractions close to 
$\frac{1}{2}$.
Typical values for ${\cal S} (n)$ at $n_0$ are in the range $27-38$ MeV.
For densities greater than $n_0$ it is more difficult to get a reliable 
information on the symmetry energy, and thereby the related proton fraction.
We will shed more light on this topic in the next subsection.


Finally, another property of interest in the discussion of the various 
equations of state  
is the incompressibility modulus $K$ at non-zero pressure
\begin{equation}
    K=9\frac{\partial P}{\partial n}.
    \label{eq:incompressibility}
\end{equation}
The sound speed $v_s$ depends as well on the density
of the nuclear medium through the relation
\begin{equation}
    \left(\frac{v_s}{c}\right)^2=\frac{dP}{d\varepsilon}=
    \frac{dP}{dn}\frac{dn}{d\varepsilon}=
    \left(\frac{K}{9(m_nc^2+{\cal E}+P/n)}\right).
    \label{eq:speedofsound}
\end{equation}
It is important to keep track of the dependence on density of $v_s$
since a superluminal behavior can occur at higher densities for most
non-relativistic EoS.
Superluminal behavior would
not occur with a fully relativistic theory, and it is necessary to
gauge the magnitude of the effect it introduces at the higher densities.
This will be discussed at the end of this section.
The adiabatic constant $\Gamma$ can also be extracted from the EoS
by 
\begin{equation}
    \Gamma = \frac{n}{P}\frac{\partial P}{\partial n}.
    \label{eq:adiabaticconstant}
\end{equation}


\section{Brief reminder on second quantization}

\[
  \Phi_{AS}(\alpha_1, \dots, \alpha_A; x_1, \dots x_A)=
            \frac{1}{\sqrt{A}} \sum_{\hat{P}} (-1)^P \hat{P} \prod_{i=1}^A \psi_{\alpha_i}(x_i),
\]
which is equivalent with $|\alpha_1 \dots \alpha_A\rangle= a_{\alpha_1}^{\dagger} \dots a_{\alpha_A}^{\dagger} |0\rangle$. We have also
    \[
        a_p^\dagger|0\rangle = |p\rangle, \quad a_p |q\rangle = \delta_{pq}|0\rangle
    \]
\[
  \delta_{pq} = \left\{a_p, a_q^\dagger \right\},
\]
and 
\[
0 = \left\{a_p^\dagger, a_q \right\} = \left\{a_p, a_q \right\} = \left\{a_p^\dagger, a_q^\dagger \right\}
\]
\[
|\Phi_0\rangle = |\alpha_1 \dots \alpha_A\rangle, \quad \alpha_1, \dots, \alpha_A \leq \alpha_F
\]
\[
\left\{a_p^\dagger, a_q \right\}= \delta_{pq}, p, q \leq \alpha_F 
\]
\[
\left\{a_p, a_q^\dagger \right\} = \delta_{pq}, p, q > \alpha_F
\]
with         $i,j,\ldots \leq \alpha_F, \quad a,b,\ldots > \alpha_F, \quad p,q, \ldots - \textrm{any}$
\[
        a_i|\Phi_0\rangle = |\Phi_i\rangle, \hspace{0.5cm} a_a^\dagger|\Phi_0\rangle = |\Phi^a\rangle
\]
and         
\[
a_i^\dagger|\Phi_0\rangle = 0 \hspace{0.5cm}  a_a|\Phi_0\rangle = 0
\]




The one-body operator is defined as
\[
 \hat{F} = \sum_{pq} \langle p|\hat{f}|q\rangle a_p^\dagger a_q
\]
while the two-body opreator is defined as
\[
\hat{V} = \frac{1}{4} \sum_{pqrs} \langle pq|\hat{v}|rs\rangle_{AS} a_p^\dagger a_q^\dagger a_s a_r
\]
where we have defined the antisymmetric matrix elements
\[
\langle pq|\hat{v}|rs\rangle_{AS} = \langle pq|\hat{v}|rs\rangle - \langle pq|\hat{v}|sr\rangle.
\]

We can also define a three-body operator
\[
\hat{V}_3 = \frac{1}{36} \sum_{pqrstu} \langle pqr|\hat{v}_3|stu\rangle_{AS} 
                a_p^\dagger a_q^\dagger a_r^\dagger a_u a_t a_s
\]
with the antisymmetrized matrix element
\begin{align}
            \langle pqr|\hat{v}_3|stu\rangle_{AS} = \langle pqr|\hat{v}_3|stu\rangle + \langle pqr|\hat{v}_3|tus\rangle + \langle pqr|\hat{v}_3|ust\rangle- \langle pqr|\hat{v}_3|sut\rangle - \langle pqr|\hat{v}_3|tsu\rangle - \langle pqr|\hat{v}_3|uts\rangle.
\end{align}

\[	     
\hat{H}_0 = \sum_{pq} \langle p|\hat{h}_0|q\rangle a^{\dagger}_p a_q,
\]
\[
\hat{H}_0 = \sum_{pq} \langle p|\hat{h}_0|q\rangle \left\{a^\dagger_p a_q\right\} +
             \sum_i \langle i|\hat{h}_0|i\rangle.
\]
\[
  \hat{H}_I = \frac{1}{4} \sum_{pqrs} \langle pq|\hat{v}|rs\rangle a^\dagger_p a^\dagger_q a_s  a_r,
\]
\[
\hat{H}_I =\frac{1}{4} \sum_{pqrs} \langle pq|\hat{v}|rs\rangle \left\{a^\dagger_p a^\dagger_q a_s  a_r\right\}
            + \sum_{pqi} \langle pi|\hat{v}|qi\rangle \left\{a^\dagger_p a_q\right\} 
            + \frac{1}{2} \sum_{ij}\langle ij|\hat{v}|ij\rangle.
\]
Explain again the meaning of the various symbols.

\[
\hat{H}_3 = \frac{1}{36} \sum_{\substack{pqr \\ stu}}
                 \langle pqr|\hat{v}_3|stu\rangle a^\dagger_p a^\dagger_q a^\dagger_r a_u a_t a_s,
\]

and specify the contributions to the twobody, onebody and the scalar part.



\section{Single-particle basis, Hamiltonians and models for the nuclear force}

This is a homogeneous system and the one-particle wave functions are given by plane wave functions normalized to a volume $\Omega$ 
for a box with length $L$ (the limit $L\rightarrow \infty$ is to be taken after we have computed various expectation values)
\[
\psi_{\mathbf{k}\sigma}(\mathbf{r})= \frac{1}{\sqrt{\Omega}}\exp{(i\mathbf{kr})}\xi_{\sigma}
\]
where $\mathbf{k}$ is the wave number and  $\xi_{\sigma}$ is a spin function for either spin up or down
\[ 
\xi_{\sigma=+1/2}=\left(\begin{array}{c} 1 \\ 0 \end{array}\right) \hspace{0.5cm}
\xi_{\sigma=-1/2}=\left(\begin{array}{c} 0 \\ 1 \end{array}\right).
\]



We assume that we have periodic boundary conditions which limit the allowed wave numbers to
\[
k_i=\frac{2\pi n_i}{L}\hspace{0.5cm} i=x,y,z \hspace{0.5cm} n_i=0,\pm 1,\pm 2, \dots
\]
We assume first that the electrons interact via a central, symmetric and translationally invariant
interaction  $V(r_{12})$ with
$r_{12}=|\mathbf{r}_1-\mathbf{r}_2|$.  The interaction is spin independent.

The total Hamiltonian consists then of kinetic and potential energy
\[
\hat{H} = \hat{T}+\hat{V}.
\]
The operator for the kinetic energy can be written as
\[
\hat{T}=\sum_{\mathbf{k}\sigma}\frac{\hbar^2k^2}{2m}a_{\mathbf{k}\sigma}^{\dagger}a_{\mathbf{k}\sigma}.
\]


The Hamiltonian operator is given by
\[
\hat{H}=\hat{H}_{el}+\hat{H}_{b}+\hat{H}_{el-b},
\]


When using periodic boundary conditions, the 
discrete-momentum single-particle basis functions 
\[
\phi_{\mathbf{k}}(\mathbf{r}) =
e^{i\mathbf{k}\cdot \mathbf{r}}/L^{d/2}
\]
are associated with 
the single-particle energy   
\begin{align}
  \varepsilon_{n_{x}, n_{y}} = \frac{\hbar^{2}}{2m} \left( \frac{2\pi }{L}\right)^{2}\left( n_{x}^{2} + n_{y}^{2}\right)
\end{align}
for two-dimensional sytems and 
\begin{align}
  \varepsilon_{n_{x}, n_{y}, n_{z}} = \frac{\hbar^{2}}{2m}
  \left( \frac{2\pi }{L}\right)^{2}
  \left( n_{x}^{2} + n_{y}^{2} + n_{z}^{2}\right)
\end{align} 
for three-dimensional systems.


We choose  the single-particle basis such that both the occupied and 
unoccupied single-particle spaces have a closed-shell 
structure. This means that all single-particle states 
corresponding to energies below a chosen cutoff are
included in the basis. We study only the unpolarized spin
phase, in which all orbitals are occupied with one spin-up 
and one spin-down electron. 


The single-particle kinetic energy defined as
\[
\frac{\hbar^2}{2m}\left(k_{n_x}^2+k_{n_y}^2k_{n_z}^2\right),
\]
and 
\[
k_{n_i}=\frac{2\pi n_i}{L} \hspace{0.1cm} n_i = 0, \pm 1, \pm 2, \dots, 
\]
we can set up a similar table and obtain (assuming identical particles one and including spin up and spin down solutions)  for energies less than or equal to $n_{x}^{2}+n_{y}^{2}+n_{z}^{2}\le 3$


\begin{quote}
\begin{tabular}{ccccc}
\hline
\multicolumn{1}{c}{ $n_{x}^{2}+n_{y}^{2}+n_{z}^{2}$ } & \multicolumn{1}{c}{ $n_{x}$ } & \multicolumn{1}{c}{ $n_{y}$ } & \multicolumn{1}{c}{ $n_{z}$ } & \multicolumn{1}{c}{ $N_{\uparrow \downarrow }$ } \\
\hline
0                               & 0       & 0       & 0       & 2                          \\
\hline
1                               & -1      & 0       & 0       &                            \\
1                               & 1       & 0       & 0       &                            \\
1                               & 0       & -1      & 0       &                            \\
1                               & 0       & 1       & 0       &                            \\
1                               & 0       & 0       & -1      &                            \\
1                               & 0       & 0       & 1       & 14                         \\
\hline
2                               & -1      & -1      & 0       &                            \\
2                               & -1      & 1       & 0       &                            \\
2                               & 1       & -1      & 0       &                            \\
2                               & 1       & 1       & 0       &                            \\
2                               & -1      & 0       & -1      &                            \\
2                               & -1      & 0       & 1       &                            \\
2                               & 1       & 0       & -1      &                            \\
2                               & 1       & 0       & 1       &                            \\
2                               & 0       & -1      & -1      &                            \\
2                               & 0       & -1      & 1       &                            \\
2                               & 0       & 1       & -1      &                            \\
2                               & 0       & 1       & 1       & 38                         \\
\hline
3                               & -1      & -1      & -1      &                            \\
3                               & -1      & -1      & 1       &                            \\
3                               & -1      & 1       & -1      &                            \\
3                               & -1      & 1       & 1       &                            \\
3                               & 1       & -1      & -1      &                            \\
3                               & 1       & -1      & 1       &                            \\
3                               & 1       & 1       & -1      &                            \\
3                               & 1       & 1       & 1       & 54                         \\
\hline
\end{tabular}
\end{quote}


Continuing in this way we get for $n_{x}^{2}+n_{y}^{2}+n_{z}^{2}=4$ a
total of 22 additional states, resulting in $76$ as a new magic
number. For the lowest six energy values the degeneracy in energy
gives us $2$, $14$, $38$, $54$, $76$ and $114$ as magic numbers. These
numbers will then define our Fermi level when we compute the energy in
a Cartesian basis. When performing calculations based on many-body
perturbation theory, Coupled cluster theory or other many-body
methods, we need then to add states above the Fermi level in order to
sum over single-particle states which are not occupied.

If we wish to study infinite nuclear matter with both protons and
neutrons, the above magic numbers become $4, 28, 76, 108, 132,
228, \dots$.

Every number of particles for filled shells defines also the number of
particles to be used in a given calculation. Use the number of
particles to define the density of the system
\[
\rho = g \frac{k_F^3}{6\pi^2},
\]
where you need to define $k_F$ and the degeneracy $g$, which is two
for one type of spin-$1/2$ particles and four for symmetric nuclear
matter.

Use the density to find the length $L$ of the box used with periodic
boundary contributions, that is use the relation
\[
  V= L^3= \frac{A}{\rho}.
\]
You can use $L$ to define the spacing to set up the spacing between
varipus $k$-values, that is
\[
  \Delta k = \frac{2\pi}{L}.
\]
Here, $A$ can be the number of nucleons. If we deal with the electron
gas only, this needs to be replaced by the number of electrons $N$.



The total Hamiltonian consists then of kinetic and potential energy
\[
\hat{H} = \hat{T}+\hat{V}.
\]
The operator for the kinetic energy can be written as
\[
\hat{T}=\sum_{\mathbf{k}\sigma}\frac{\hbar^2k^2}{2m}a_{\mathbf{k}\sigma}^{\dagger}a_{\mathbf{k}\sigma}.
\]



As mentioned above, we will employ a plane wave basis
for our calculations of infinite matter properties. With a cartesian
basis it means that we can calculate directly the various matrix
elements, as discussed in the previous subsection. However, a
cartesian basis represents an approximation to the thermodynamical limit. In
order to compare the stability of our basis with results from the
thermodynamical limit, it is convenient to rewrite the nucleon-nucleon
interaction in terms of a partial wave expansion. This will allow us
to compute the Hartree-Fock energy of the ground state in the
thermodynamical limit (with the caveat that we need to limit the
number of partial waves). In order to find the expressions for the
Hartree-Fock energy in a partial wave basis, we will find it
convenient to rewrite our two-body force in terms of the relative and
center-of-mass motion momenta.

The direct matrix element, with single-particle three-dimensional
momenta $\mathbf{k}_i$, spin $\sigma_i$ and isospin $\tau_i$, is
defined as
\[
\langle \mathbf{k}_a\sigma_a\tau_a \mathbf{k}_b\sigma_b\tau_b \vert \hat{v}\vert \mathbf{k}_c\sigma_c\tau_c \mathbf{k}_d\sigma_d\tau_d \rangle, 
\]
or in a more compact form as
$\langle \mathbf{a}\mathbf{b}\vert \hat{v} \vert \mathbf{c}\mathbf{d} \rangle$
where the boldfaced letters $\mathbf{a}$ etc represent the relevant
quantum numbers, here momentum, spin and isospin. Introducing the
relative momentum
\[
\mathbf{k} = \frac{1}{2}\left(\mathbf{k}_a-\mathbf{k}_b\right), 
\]
and the center-of-mass momentum
\[
\mathbf{K} = \mathbf{k}_a+\mathbf{k}_b,
\]
we have 
\[
\langle \mathbf{k}_a\sigma_a\tau_a \mathbf{k}_b\sigma_b\tau_b \vert \hat{v}\vert \mathbf{k}_c\sigma_c\tau_c \mathbf{k}_d\sigma_d\tau_d \rangle=\langle \mathbf{k}\mathbf{K}\sigma_a\tau_a \sigma_b\tau_b \vert \hat{v}\vert \mathbf{k}'\mathbf{K}'\sigma_c\tau_c \sigma_d\tau_d \rangle.
\]
The nucleon-nucleon interaction conserves the total momentum and is
charge invariant, implying that the above uncoupled matrix element reads
\[
\langle \mathbf{k}\mathbf{K}\sigma_a\tau_a \sigma_b\tau_b \vert \hat{v}\vert \mathbf{k}'\mathbf{K}'\sigma_c\tau_c \sigma_d\tau_d \rangle=\delta_{T_z,T_z'}\delta(\mathbf{K}-\mathbf{K}')\langle \mathbf{k}T_zS_z=(\sigma_a+\sigma_b) \vert \hat{v}\vert \mathbf{k}'T_zS_z'=(\sigma_c+\sigma_d) \rangle,
\]
where we have defined the isospin projections $T_z=\tau_a+\tau_b$ and
$T_z'=\tau_c+\tau_d$.  Defining
$\hat{v}=\hat{v}(\mathbf{k},\mathbf{k}' )$, we can rewrite the
previous equation in a more compact form as
\[
\delta_{T_z,T_z'}\delta(\mathbf{K}-\mathbf{K}')\langle \mathbf{k}T_zS_z=(\sigma_a+\sigma_b) \vert \hat{v}\vert \mathbf{k}'T_zS_z'=(\sigma_c+\sigma_d) \rangle=\delta_{T_z,T_z'}\delta(\mathbf{K}-\mathbf{K}')\langle T_zS_z\vert\hat{v}(\mathbf{k},\mathbf{k}' ) \vert T_zS_z' \rangle.
\]
These matrix elements can in turn be rewritten in terms of the total
two-body quantum numbers for the spin $S$ of two spin-1/2 fermions as
\[
\langle \mathbf{k}T_zS_z \vert \hat{v}(\mathbf{k},\mathbf{k}' )\vert \mathbf{k}'T_zS_z' \rangle=\sum_{SS'}\langle \frac{1}{2}\sigma_a\frac{1}{2}\sigma_b\vert SS_z\rangle \langle \frac{1}{2}\sigma_c\frac{1}{2}\sigma_d\vert S'S_z'\rangle \langle \mathbf{k}T_zSS_z\vert \hat{v}(\mathbf{k},\mathbf{k}' )\vert \mathbf{k}T_zS'S_z' \rangle
\]
The coefficients $\langle \frac{1}{2}\sigma_a\frac{1}{2}\sigma_b\vert
SS_z\rangle$ are so-called Clebsch-Gordan recoupling coefficients.  We
will assume that our interactions break charge and isospin
symmetry. We will refer to $T_z=0$ as the $pn$ (proton-neutron)
channel, $T_z=-1$ as the $pp$ (proton-proton) channel and $T_z=1$ as
the $nn$ (neutron-neutron) channel.

The nucleon-nucleon force is often derived and analyzed theoretically
in terms of a partial wave expansion. A state with linear momentum
$\mathbf{k}$ can be written as
\[
\vert \mathbf{k} \rangle = \sum_{l=0}^{\infty}\sum_{l_l=-l}^{L}\imath^lY_{l}^{m_l}(\hat{k}\vert klm_l\rangle.
\]

In terms of the relative and center-of-mass momenta $\mathbf{k}$ and
$\mathbf{K}$, the potential in momentum space is related to the nonlocal operator
$V(\mathbf{r},\mathbf{r}')$ by
\begin{equation}
      \langle \mathbf{k'K'}\vert \hat{v} \vert \mathbf{k'K} \rangle=
       \int d\mathbf{r}d \mathbf{r'}
        e^{-\imath \mathbf{k'r'}}V(\mathbf{r'},\mathbf{r}) e^{\imath \mathbf{kr}}
       \delta(\mathbf{K},\mathbf{K'}).
\end{equation}
We will assume that the interaction is spherically symmetric and use
the partial wave expansion of the plane waves in
terms of spherical harmonics.
This means that we can separate the radial part of the wave function from its
angular dependence. The wave function of the relative motion is described
in terms of plane waves as
\begin{equation}
       e^{\imath \mathbf{kr}}  =
       \langle\mathbf{r}\vert \mathbf{k}\rangle =  4\pi \sum_{lm} \imath ^{l}
        j_{l} (kr) Y_{lm}^{*}(\mathbf{\hat{k}}) Y_{lm}(\mathbf{\hat{r}}),
\end{equation}
where $j_l$ is a spherical Bessel function and $Y_{lm}$ the
spherical harmonic.
This partial wave basis is useful for defining the operator for
the nucleon-nucleon interaction, which
is symmetric with respect to rotations, parity and
isospin transformations. These symmetries imply that the interaction is
diagonal with respect to the quantum numbers of total angular
momentum $J$, spin $S$ and isospin $T$. Using the above plane wave expansion,
and coupling to final $J$, $S$ and $T$ we get
\begin{equation}
      \langle \mathbf{k'}\vert V \vert \mathbf{k}\rangle
       = (4\pi)^2 \sum_{JM}\sum_{lm}\sum_{l'm'}
      \imath ^{l+l'} Y_{lm}^{*}(\mathbf{\hat{k}}) Y_{l'm'}(\mathbf{\hat{k}'})
      {\cal C}_{m'M_SM}^{l'SJ}{\cal C}_{mM_SM}^{lSJ}
      \langle k'l'STJM \vert V \vert klSTJM \rangle,
\label{eq:vpartial}
\end{equation}
where we have defined
\begin{equation}
    \langle k'l'STJM\vert V \vert klSTJM\rangle =
    \int   j_{l'}(k'r')\langle l'STJM\vert V(r',r)\vert lSTJM \rangle j_l(kr) {r'}^2 dr' r^2 dr.
\end{equation}
We have omitted the momentum of the center-of-mass motion $\mathbf{K}$ and the 
corresponding orbital momentum $L$, since the interaction is diagonal
in these variables. The potentials we will employ in this work, like
those of the Bonn group, are all non-local potentials defined in 
momentum space, and we will therefore not need the last equation.




\section{Hartree-Fock theory}

Hartree-Fock (HF) theory is an algorithm for finding an approximative expression for the ground state of a given Hamiltonian. The basic ingredients are
Define a single-particle basis $\{\psi_{\alpha}\}$ so that
\[ 
\hat{h}^{\mathrm{HF}}\psi_{\alpha} = \varepsilon_{\alpha}\psi_{\alpha}
\]
with the Hartree-Fock Hamiltonian defined as
\[
\hat{h}^{\mathrm{HF}}=\hat{t}+\hat{u}_{\mathrm{ext}}+\hat{u}^{\mathrm{HF}}
\]

The term  $\hat{u}^{\mathrm{HF}}$ is a single-particle potential to be determined by the HF algorithm.

The HF algorithm means to choose $\hat{u}^{\mathrm{HF}}$ in order to have 
\[ \langle \hat{H} \rangle = E^{\mathrm{HF}}= \langle \Phi_0 | \hat{H}|\Phi_0 \rangle
\]
that is to find a local minimum with a Slater determinant $\Phi_0$ being the ansatz for the ground state. 
The variational principle ensures that $E^{\mathrm{HF}} \ge E_0$, with $E_0$ the exact ground state energy.

We will show that the Hartree-Fock Hamiltonian $\hat{h}^{\mathrm{HF}}$ equals our definition of the operator $\hat{f}$ discussed in connection with the new definition of the normal-ordered Hamiltonian (see later lectures), that is we have, for a specific matrix element
\[
\langle p |\hat{h}^{\mathrm{HF}}| q \rangle =\langle p |\hat{f}| q \rangle=\langle p|\hat{t}+\hat{u}_{\mathrm{ext}}|q \rangle +\sum_{i\le F} \langle pi | \hat{V} | qi\rangle_{AS},
\]
meaning that
\[
\langle p|\hat{u}^{\mathrm{HF}}|q\rangle = \sum_{i\le F} \langle pi | \hat{V} | qi\rangle_{AS}.
\]
The so-called Hartree-Fock potential $\hat{u}^{\mathrm{HF}}$ brings an
explicit medium dependence due to the summation over all
single-particle states below the Fermi level $F$. It brings also in an
explicit dependence on the two-body interaction (in nuclear physics we
can also have complicated three- or higher-body forces). The two-body
interaction, with its contribution from the other bystanding fermions,
creates an effective mean field in which a given fermion moves, in
addition to the external potential $\hat{u}_{\mathrm{ext}}$ which
confines the motion of the fermion. For systems like nuclei, there is
no external confining potential. Nuclei are examples of self-bound
systems, where the binding arises due to the intrinsic nature of the
strong force. For nuclear systems thus, there would be no external
one-body potential in the Hartree-Fock Hamiltonian.


Another possibility is to expand the single-particle functions in a known basis  and vary the coefficients, 
that is, the new single-particle wave function is written as a linear expansion
in terms of a fixed chosen orthogonal basis (for example the well-known harmonic oscillator functions or the hydrogen-like functions etc).
We define our new Hartree-Fock single-particle basis by performing a unitary transformation 
on our previous basis (labelled with greek indices) as
\begin{equation}
\psi_p^{HF}  = \sum_{\lambda} C_{p\lambda}\phi_{\lambda}. \label{eq:newbasis}
\end{equation}
In this case we vary the coefficients $C_{p\lambda}$. If the basis has infinitely many solutions, we need
to truncate the above sum.  We assume that the basis $\phi_{\lambda}$ is orthogonal. A unitary transformation keeps the orthogonality, as discussed in exercise 1 below.  




It is normal to choose a single-particle basis defined as the eigenfunctions
of parts of the full Hamiltonian. The typical situation consists of the solutions of the one-body part of the Hamiltonian, that is we have
\[
\hat{h}_0\phi_{\lambda}=\epsilon_{\lambda}\phi_{\lambda}.
\]
The single-particle wave functions $\phi_{\lambda}({\bf r})$, defined by the quantum numbers $\lambda$ and ${\bf r}$
are defined as the overlap 
\[
   \phi_{\lambda}({\bf r})  = \langle {\bf r} | \lambda \rangle .
\]




In our discussions hereafter we will use our definitions of single-particle states above and below the Fermi ($F$) level given by the labels
$ijkl\dots \le F$ for so-called single-hole states and $abcd\dots > F$ for so-called particle states.
For general single-particle states we employ the labels $pqrs\dots$. 





\[
  E[\Phi] 
  = \sum_{\mu=1}^A \langle \mu | h | \mu \rangle +
  \frac{1}{2}\sum_{{\mu}=1}^A\sum_{{\nu}=1}^A \langle \mu\nu|\hat{v}|\mu\nu\rangle_{AS},
\]
we found the expression for the energy functional in terms of the basis function $\phi_{\lambda}({\bf r})$. We then  varied the above energy functional with respect to the basis functions $|\mu \rangle$. 
Now we are interested in defining a new basis defined in terms of
a chosen basis as defined in Eq.~(ref{eq:newbasis}). We can then rewrite the energy functional as
\begin{equation}
  E[\Phi^{HF}] 
  = \sum_{i=1}^A \langle i | h | i \rangle +
  \frac{1}{2}\sum_{ij=1}^A\langle ij|\hat{v}|ij\rangle_{AS}, \label{FunctionalEPhi2}
\end{equation}
where $\Phi^{HF}$ is the new Slater determinant defined by the new basis of Eq.~(ref{eq:newbasis}). 





Using Eq.~(\ref{eq:newbasis}) we can rewrite Eq.~(\ref{FunctionalEPhi2}) as 
\begin{equation}
  E[\Psi] 
  = \sum_{i=1}^A \sum_{\alpha\beta} C^*_{i\alpha}C_{i\beta}\langle \alpha | h | \beta \rangle +
  \frac{1}{2}\sum_{ij=1}^A\sum_{{\alpha\beta\gamma\delta}} C^*_{i\alpha}C^*_{j\beta}C_{i\gamma}C_{j\delta}\langle \alpha\beta|\hat{v}|\gamma\delta\rangle_{AS}. \label{FunctionalEPhi3}
\end{equation}


We wish now to minimize the above functional. We introduce again a set of Lagrange multipliers, noting that
since $\langle i | j \rangle = \delta_{i,j}$ and $\langle \alpha | \beta \rangle = \delta_{\alpha,\beta}$, 
the coefficients $C_{i\gamma}$ obey the relation
\[
 \langle i | j \rangle=\delta_{i,j}=\sum_{\alpha\beta} C^*_{i\alpha}C_{i\beta}\langle \alpha | \beta \rangle=
\sum_{\alpha} C^*_{i\alpha}C_{i\alpha},
\]
which allows us to define a functional to be minimized that reads
\begin{equation}
  F[\Phi^{HF}]=E[\Phi^{HF}] - \sum_{i=1}^A\epsilon_i\sum_{\alpha} C^*_{i\alpha}C_{i\alpha}.
\end{equation}







Minimizing with respect to $C^*_{i\alpha}$, remembering that the
equations for $C^*_{i\alpha}$ and $C_{i\alpha}$ can be written as two
independent equations, we obtain
\[
\frac{d}{dC^*_{i\alpha}}\left[  E[\Phi^{HF}] - \sum_{j}\epsilon_j\sum_{\alpha} C^*_{j\alpha}C_{j\alpha}\right]=0,
\]
which yields for every single-particle state $i$ and index $\alpha$
(recalling that the coefficients $C_{i\alpha}$ are matrix elements of
a unitary (or orthogonal for a real symmetric matrix) matrix) the
following Hartree-Fock equations
\[
\sum_{\beta} C_{i\beta}\langle \alpha | h | \beta \rangle+
\sum_{j=1}^A\sum_{\beta\gamma\delta} C^*_{j\beta}C_{j\delta}C_{i\gamma}\langle \alpha\beta|\hat{v}|\gamma\delta\rangle_{AS}=\epsilon_i^{HF}C_{i\alpha}.
\]


We can rewrite this equation as (changing dummy variables)
\[
\sum_{\beta} \left\{\langle \alpha | h | \beta \rangle+
\sum_{j}^A\sum_{\gamma\delta} C^*_{j\gamma}C_{j\delta}\langle \alpha\gamma|\hat{v}|\beta\delta\rangle_{AS}\right\}C_{i\beta}=\epsilon_i^{HF}C_{i\alpha}.
\]
Note that the sums over greek indices run over the number of basis set
functions (in principle an infinite number).





Defining 
\[
h_{\alpha\beta}^{HF}=\langle \alpha | h | \beta \rangle+
\sum_{j=1}^A\sum_{\gamma\delta} C^*_{j\gamma}C_{j\delta}\langle \alpha\gamma|\hat{v}|\beta\delta\rangle_{AS},
\]
we can rewrite the new equations as 
\begin{equation}
\sum_{\gamma}h_{\alpha\beta}^{HF}C_{i\beta}=\epsilon_i^{HF}C_{i\alpha}. \label{eq:newhf}
\end{equation}
The latter is nothing but a standard eigenvalue problem. Compared with
Eq.~(ref{eq:hartreefockcoordinatespace}), we see that we do not need
to compute any integrals in an iterative procedure for solving the
equations.  It suffices to tabulate the matrix elements
$\langle \alpha | h | \beta \rangle$ and
$\langle \alpha\gamma|\hat{v}|\beta\delta\rangle_{AS}$ once and for
all. Successive iterations require thus only a look-up in tables over
one-body and two-body matrix elements. These details will be discussed
below when we solve the Hartree-Fock equations numerical.


Our Hartree-Fock matrix  is thus
\[
\hat{h}_{\alpha\beta}^{HF}=\langle \alpha | \hat{h}_0 | \beta \rangle+
\sum_{j=1}^A\sum_{\gamma\delta} C^*_{j\gamma}C_{j\delta}\langle \alpha\gamma|\hat{v}|\beta\delta\rangle_{AS}.
\]
The Hartree-Fock equations are solved in an iterative waym starting with a guess for the coefficients $C_{j\gamma}=\delta_{j,\gamma}$ and solving the equations by diagonalization till the new single-particle energies
$\epsilon_i^{\mathrm{HF}}$ do not change anymore by a prefixed quantity. 




Normally we assume that the single-particle basis $|\beta\rangle$ forms an eigenbasis for the operator
$\hat{h}_0$, meaning that the Hartree-Fock matrix becomes  
\[
\hat{h}_{\alpha\beta}^{HF}=\epsilon_{\alpha}\delta_{\alpha,\beta}+
\sum_{j=1}^A\sum_{\gamma\delta} C^*_{j\gamma}C_{j\delta}\langle \alpha\gamma|\hat{v}|\beta\delta\rangle_{AS}.
\]
The Hartree-Fock eigenvalue problem
\[
\sum_{\beta}\hat{h}_{\alpha\beta}^{HF}C_{i\beta}=\epsilon_i^{\mathrm{HF}}C_{i\alpha},
\]
can be written out in a more compact form as
\[
\hat{h}^{HF}\hat{C}=\epsilon^{\mathrm{HF}}\hat{C}. 
\]




The Hartree-Fock equations are, in their simplest form, solved in an iterative way, starting with a guess for the
coefficients $C_{i\alpha}$. We label the coefficients as $C_{i\alpha}^{(n)}$, where the subscript $n$ stands for iteration $n$.
To set up the algorithm we can proceed as follows:

We start with a guess $C_{i\alpha}^{(0)}=\delta_{i,\alpha}$. Alternatively, we could have used random starting values as long as the vectors are normalized. Another possibility is to give states below the Fermi level a larger weight.
The Hartree-Fock matrix simplifies then to (assuming that the coefficients $C_{i\alpha} $  are real)
\[
\hat{h}_{\alpha\beta}^{HF}=\epsilon_{\alpha}\delta_{\alpha,\beta}+
\sum_{j = 1}^A\sum_{\gamma\delta} C_{j\gamma}^{(0)}C_{j\delta}^{(0)}\langle \alpha\gamma|\hat{v}|\beta\delta\rangle_{AS}.
\]




Solving the Hartree-Fock eigenvalue problem yields then new eigenvectors $C_{i\alpha}^{(1)}$ and eigenvalues
$\epsilon_i^{HF(1)}$. 
With the new eigenvalues we can set up a new Hartree-Fock potential 
\[
\sum_{j = 1}^A\sum_{\gamma\delta} C_{j\gamma}^{(1)}C_{j\delta}^{(1)}\langle \alpha\gamma|\hat{v}|\beta\delta\rangle_{AS}.
\]
The diagonalization with the new Hartree-Fock potential yields new eigenvectors and eigenvalues.
This process is continued till for example
\[
\frac{\sum_{p} |\epsilon_i^{(n)}-\epsilon_i^{(n-1)}|}{m} \le \lambda,  
\]
where $\lambda$ is a user prefixed quantity ($\lambda \sim 10^{-8}$ or smaller) and $p$ runs over all calculated single-particle
energies and $m$ is the number of single-particle states.


We can rewrite the ground state energy by adding and subtracting $\hat{u}^{HF}(x_i)$ 
\[
  E_0^{HF} =\langle \Phi_0 | \hat{H} | \Phi_0\rangle = 
\sum_{i\le F}^A \langle i | \hat{h}_0 +\hat{u}^{HF}| j\rangle+ \frac{1}{2}\sum_{i\le F}^A\sum_{j \le F}^A\left[\langle ij |\hat{v}|ij \rangle-\langle ij|\hat{v}|ji\rangle\right]-\sum_{i\le F}^A \langle i |\hat{u}^{HF}| i\rangle,
\]
which results in
\[
  E_0^{HF}
  = \sum_{i\le F}^A \varepsilon_i^{HF} + \frac{1}{2}\sum_{i\le F}^A\sum_{j \le F}^A\left[\langle ij |\hat{v}|ij \rangle-\langle ij|\hat{v}|ji\rangle\right]-\sum_{i\le F}^A \langle i |\hat{u}^{HF}| i\rangle.
\]
Our single-particle states $ijk\dots$ are now single-particle states obtained from the solution of the Hartree-Fock equations.



Using our definition of the Hartree-Fock single-particle energies we obtain then the following expression for the total ground-state energy
\[
  E_0^{HF}
  = \sum_{i\le F}^A \varepsilon_i - \frac{1}{2}\sum_{i\le F}^A\sum_{j \le F}^A\left[\langle ij |\hat{v}|ij \rangle-\langle ij|\hat{v}|ji\rangle\right].
\]


\subsection{Introducing our first ansatz for the ground state}

\subsection{Slater determinants as basis states}

The simplest possible choice for many-body wavefunctions are \textbf{product} wavefunctions.
That is
\[ 
\Psi(x_1, x_2, x_3, \ldots, x_A) \approx \phi_1(x_1) \phi_2(x_2) \phi_3(x_3) \ldots
\]
because we are really only good  at thinking about one particle at a time. Such 
product wavefunctions, without correlations, are easy to 
work with; for example, if the single-particle states $\phi_i(x)$ are orthonormal, then 
the product wavefunctions are easy to orthonormalize.   

Similarly, computing matrix elements of operators are relatively easy, because the 
integrals factorize.


The price we pay is the lack of correlations, which we must build up by using many, many product 
wavefunctions.


Because we have fermions, we are required to have antisymmetric wavefunctions, that is
\[
\Psi(x_1, x_2, x_3, \ldots, x_A) = - \Psi(x_2, x_1, x_3, \ldots, x_A)
\]
etc. This is accomplished formally by using the determinantal formalism
\[
\Psi(x_1, x_2, \ldots, x_A) 
= \frac{1}{\sqrt{A!}} 
\det \left | 
\begin{array}{cccc}
\phi_1(x_1) & \phi_1(x_2) & \ldots & \phi_1(x_A) \\
\phi_2(x_1) & \phi_2(x_2) & \ldots & \phi_2(x_A) \\
 \vdots & & &  \\
\phi_A(x_1) & \phi_A(x_2) & \ldots & \phi_A(x_A) 
\end{array}
\right |
\]
Product wavefunction + antisymmetry (Pauli principle) = Slater determinant. 


Properties of the determinant (interchange of any two rows or 
any two columns yields a change in sign; thus no two rows and no 
two columns can be the same) lead to the following consequence of the Pauli principle:

\begin{itemize}
\item No two particles can be at the same place (two columns the same); and

\item No two particles can be in the same state (two rows the same).
\end{itemize}

\noindent
As a practical matter, however, Slater determinants beyond $N=4$ quickly become 
unwieldy. Thus we turn to the \textbf{occupation representation} or \textbf{second quantization} to simplify calculations. 

The occupation representation, using fermion \textbf{creation} and \textbf{annihilation} 
operators, is compact and efficient. It is also abstract and, at first encounter, not easy to 
internalize. It is inspired by other operator formalism, such as the ladder operators for 
the harmonic oscillator or for angular momentum, but unlike those cases, the operators \textbf{do not have coordinate space representations}.

Instead, one can think of fermion creation/annihilation operators as a game of symbols that 
compactly reproduces what one would do, albeit clumsily, with full coordinate-space Slater 
determinants. 



We start with a set of orthonormal single-particle states $\{ \phi_i(x) \}$. 
(Note: this requirement, and others, can be relaxed, but leads to a 
more involved formalism.) \textbf{Any} orthonormal set will do. 

To each single-particle state $\phi_i(x)$ we associate a creation operator 
$\hat{a}^\dagger_i$ and an annihilation operator $\hat{a}_i$. 

When acting on the vacuum state $| 0 \rangle$, the creation operator $\hat{a}^\dagger_i$ causes 
a particle to occupy the single-particle state $\phi_i(x)$:
\[
\phi_i(x) \rightarrow \hat{a}^\dagger_i |0 \rangle
\]



But with multiple creation operators we can occupy multiple states:
\[
\phi_i(x) \phi_j(x^\prime) \phi_k(x^{\prime \prime}) 
\rightarrow \hat{a}^\dagger_i \hat{a}^\dagger_j \hat{a}^\dagger_k |0 \rangle.
\]

Now we impose antisymmetry, by having the fermion operators satisfy  \textbf{anticommutation relations}:
\[
\hat{a}^\dagger_i \hat{a}^\dagger_j + \hat{a}^\dagger_j \hat{a}^\dagger_i
= [ \hat{a}^\dagger_i ,\hat{a}^\dagger_j ]_+ 
= \{ \hat{a}^\dagger_i ,\hat{a}^\dagger_j \} = 0
\]
so that 
\[
\hat{a}^\dagger_i \hat{a}^\dagger_j = - \hat{a}^\dagger_j \hat{a}^\dagger_i
\]




Because of this property, automatically $\hat{a}^\dagger_i \hat{a}^\dagger_i = 0$, 
enforcing the Pauli exclusion principle.  Thus when writing a Slater determinant 
using creation operators, 
\[
\hat{a}^\dagger_i \hat{a}^\dagger_j \hat{a}^\dagger_k \ldots |0 \rangle
\]
each index $i,j,k, \ldots$ must be unique.





\subsection{The Breuckner $G$-matrix}

The Brueckner $G$-matrix has historically been an important ingredient
in many-body calculations of nuclear systems. In this section, we will
briefly survey the philosophy behind the $G$-matrix.

Historically, the $G$-matrix was developed in microscopic nuclear
matter calculations using realistic nucleon-nucleon (NN) interactions.
It is an ingenuous as well as an interesting method to overcome the
difficulties caused by the strong, short-range repulsive core contained
in all modern models for the NN interaction. The $G$-matrix method was
originally developed by Brueckner, and further
developed by Goldstone and Bethe, Brandow and Petschek. 
In the literature it is generally referred to as the
Brueckner theory or the Brueckner-Bethe-Goldstone theory.

Suppose we want to calculate the nuclear matter ground-state
energy $E_0$ using the non-relativistic Schr\"{o}dinger equation
\begin{equation}
      H\Psi_0(A)=E_0(A)\Psi_0(A),
\end{equation}
with $H=T+V$ where $A$ denotes the number of particles, $T$
is the kinetic energy and $V$ is
the nucleon-nucleon
(NN)  potential. Models for the NN interaction are discussed in the chapter on nuclear forces.
The corresponding unperturbed
problem is
\begin{equation}
      H_0\psi_0(A)=W_0(A)\psi_0(A).
\end{equation}
Here $H_0$ is just kinetic energy $T$ and $\psi_0$ is a Slater
determinant representing the Fermi sea, where all orbits through the
Fermi momentum $k_F$ are filled. We write
\begin{equation}
      E_0=W_0+\Delta E_0,
\end{equation}
where $\Delta E_0$ is the ground-state energy shift or correlation energy as it was defined in many-body perturbation theory.
If we know how to calculate $\Delta E_0$, then we know $E_0$, since
$W_0$ is easily obtained. In the limit $A\rightarrow \infty$,
the quantities $E_0$ and $\Delta E_0$ themselves are not well
defined, but the ratios $E_0/A$ and $\Delta E_0/A$ are. The
nuclear-matter binding energy per nucleon is commonly denoted
by $BE/A$, which is just $-E_0/A$. In passing, we note that
the empirical value for symmetric nuclear matter (proton number
$Z$=neutron number $N$) is $\approx 16$ MeV.
There exists a formal theory for the calculation of $\Delta E_0$.
According to the well-known Goldstone linked-diagram theory, the energy shift $\Delta E_0$ is given exactly by the
diagrammatic expansion shown in Fig.~\ref{fig:goldstone}. This theory,
is a linked-cluster perturbation expansion for the ground state
energy of a many-body system, and applies equally well to both
nuclear matter and closed-shell nuclei such as the doubly magic
nucleus $^{40}$Ca. 
We will not discuss the Goldstone expansion, but rather discuss
briefly how it is used in calculations.


Using the standard diagram rules (see the discussion on
coupled-cluster theory and many-body perturbation theory), the various
diagrams contained in the above figure can be readily calculated (in
an uncoupled scheme)
\begin{equation}
   (i)=\frac{(-)^{n_h+n_l}}{2^{n_{ep}}}\sum_{ij\leq k_F}
       \langle ij\vert\hat{v}\vert ij\rangle_{AS},
\end{equation}
with $n_h=n_l=2$ and $n_{ep}=1$. As discussed in connection with the
diagram rules in the many-body perturbation theory chapter, $n_h$
denotes the number of hole lines, $n_l$ the number of closed fermion
loops and $n_{ep}$ is the number of so-called equivalent pairs.  The
factor $1/2^{n_{ep}}$ is needed since we want to count a pair of
particles only once. We will carry this factor $1/2$ with us in the
equations below.  The subscript $AS$ denotes the antisymmetrized and
normalized matrix element
\begin{equation}
     \langle ij\vert\hat{v}\vert ij\rangle_{AS}=\langle ij \vert\hat{v}\vert ij\rangle-
     \langle ji \vert\hat{v}\vert ij\rangle.
\end{equation}
Similarly, diagrams (ii) and (iii) read
\begin{equation}
   (ii)=\frac{(-)^{2+2}}{2^2}\sum_{ij\leq k_F}\sum_{ab>k_F}
   \frac{\langle ij\vert\hat{v}\vert ab\rangle_{AS}
   \langle ab\vert\hat{v}\vert ij\rangle_{AS}}
   {\varepsilon_i+\varepsilon_j-\varepsilon_a-\varepsilon_b},
\end{equation}
and
\begin{equation}
   (iii)=\frac{(-)^{2+2}}{2^3}\sum_{k_i,k_j\leq k_F}\sum_{abcdk_F}
   \frac{\langle ij\vert\hat{v}\vert ab\rangle_{AS}
   \langle ab\vert\hat{v}\vert cd\rangle_{AS}
   \langle cd\vert\hat{v}\vert ij\rangle_{AS}}
   {(\varepsilon_i+\varepsilon_j-\varepsilon_a-\varepsilon_b)
   (\varepsilon_i+\varepsilon_j-\varepsilon_c-\varepsilon_d)}.
\end{equation}
In the above, $\varepsilon$ denotes the sp energies defined by
$H_0$.
The steps leading to the above expressions for the various
diagrams are rather straightforward. Though, if we wish to compute the
matrix elements for the interaction $v$, a serious problem
arises. Typically, the matrix elements will contain a term
(see the next section for the formal details) $V(|{\mathbf r}|)$, which
represents the interaction potential $V$ between two nucleons, where
${\mathbf r}$ is the internucleon distance.
All modern models
for $V$ have a strong short-range repulsive core. Hence,
matrix elements involving $V(|{\mathbf r}|)$, will result in large
(or infinitely large for a potential with a hard core)
and repulsive contributions to the ground-state energy. Thus, the
diagrammatic expansion for the ground-state energy in terms of the
potential $V(|{\mathbf r}|)$ becomes meaningless.

One possible solution to  this problem is provided by the well-known
Brueckner theory or the Brueckner $G$-matrix, or just the
$G$-matrix. In fact, the $G$-matrix is an almost indispensable
tool in almost every microscopic nuclear structure
calculation. Its main idea may be paraphrased as follows.
Suppose we want to calculate the function $f(x)=x/(1+x)$. If
$x$ is small, we may expand the function $f(x)$ as a power series
$x+x^2+x^3+\dots$ and it may be adequate to just calculate the first
few terms. In other words, $f(x)$ may be calculated using a low-order
perturbation method. But if $x$ is large
(or infinitely large), the above
power series is obviously meaningless.
However, the exact function
$x/(1+x)$ is still well defined in the limit
of $x$ becoming very large.

These arguments suggest that one should sum up the diagrams
(i), (ii), (iii) in fig.~\ref{fig:goldstone} and the similar ones
to all orders, instead of computing them one by one. Denoting this
all-order sum as $1/2\tilde{G}_{ijij}$, where we have
introduced the shorthand notation
$\tilde{G}_{ijij}=\langle k_ik_j\vert \tilde{G}\vert k_ik_j\rangle_{AS}$
(and similarly for $\tilde{v}$),
we have that
\begin{align}
      \frac{1}{2}\tilde{G}_{ijij}=&\frac{1}{2}\hat{v}_{ijij}
      +\sum_{ab>k_F}\frac{1}{2}\hat{v}_{ijab}\frac{1}{\varepsilon_i+\varepsilon_j-\varepsilon_a-\varepsilon_b}
      \nonumber \\
      & \times\left[\frac{1}{2}\hat{v}_{abij}+\sum_{cd>k_F}
      \frac{1}{2}\hat{v}_{abcd}\frac{1}
      {\varepsilon_i+\varepsilon_j-\varepsilon_c-\varepsilon_d}
      \frac{1}{2}V_{cdij}+\dots  \right].
\end{align}
The factor $1/2$ is the same as that discussed above, namely we want 
to count a pair of particles only once.
The quantity inside the brackets is just
$1/2\tilde{G}_{mnij}$ and the above equation can be
rewritten as an integral equation
\begin{equation}
      \tilde{G}_{ijij}=\tilde{V}_{ijij}
      +\sum_{ab>F}\frac{1}{2}\hat{v}_{ijab}\frac{1}{\varepsilon_i+\varepsilon_j-\varepsilon_a-\varepsilon_b}
      \tilde{G}_{abij}.
\end{equation}
Note that $\tilde{G}$ is the antisymmetrized $G$-matrix since
the potential $\tilde{v}$ is also antisymmetrized. This means that
$\tilde{G}$ obeys
\begin{equation}
  \tilde{G}_{ijij}=-\tilde{G}_{jiij}=-\tilde{G}_{ijji}.
\end{equation}
The $\tilde{G}$-matrix  is defined as
\begin{equation}
    \tilde{G}_{ijij}=G_{ijij}-G_{jiij},
\end{equation}
and the equation for $G$ is
\begin{equation}
      G_{ijij}=V_{ijij}
      +\sum_{ab>k_F}V_{ijab}\frac{1}
      {\varepsilon_i+\varepsilon_j-\varepsilon_a-\varepsilon_b}
      G_{abij},
      \label{eq:ggeneral}
\end{equation}
which is the familiar $G$-matrix equation. The above
matrix is specifically designed to treat a class of diagrams
contained in $\Delta E_0$, of which typical contributions
were shown in fig.~\ref{fig:goldstone}. In fact the sum of the diagrams
in fig.~\ref{fig:goldstone} is equal to $1/2(G_{ijij}-G_{jiij})$.

Let us now define a more general $G$-matrix as
\begin{equation}
      G_{ijij}=V_{ijij}
      +\sum_{mn>0}V_{ijmn}\frac{Q(mn)}
      {\omega -\varepsilon_m-\varepsilon_n}
      G_{mnij},
      \label{eq:gwithq}
\end{equation}
which is an extension of Eq. (\ref{eq:ggeneral}). Note that 
Eq. (\ref{eq:ggeneral}) has
$\varepsilon_i+\varepsilon_j$ in the energy denominator, whereas
in the latter equation we have a general energy variable $\omega$
in the denominator. Furthermore, in Eq. (\ref{eq:ggeneral})
we have a restricted
sum over $mn$, while in Eq. (\ref{eq:gwithq})
we sum over all $ab$ and we have
introduced a weighting factor $Q(ab)$. In Eq. (\ref{eq:gwithq}) $Q(ab)$
corresponds to the choice
\begin{equation}
   Q(a , b ) =
    \left\{\begin{array}{cc}1,&min(a ,b ) > k_F\\
    0,&\mathrm{else}.\end{array}\right. ,
\end{equation}
where $Q(ab)$ is usually referred to as the $G$-matrix Pauli
exclusion operator. The role of $Q$ is to enforce a selection
of the intermediate states allowed in the $G$-matrix equation. The above
$Q$ requires that the intermediate particles $a$ and $b$
must be both above the Fermi surface defined by $F$. We may enforce
a different requirement by using a summation over intermediate states
different from that in Eq. (\ref{eq:gwithq}).
An example is the Pauli operator
for the model-space Brueckner-Hartree-Fock method discussed below.


Before ending this section, let us rewrite the $G$-matrix equation
in a more compact form.
The sp energies $\varepsilon$ and wave functions are defined
by the unperturbed hamiltonian $H_0$ as
\begin{equation}
   H_0\vert \psi_a\psi_b=(\varepsilon_a+\varepsilon_b)
   \vert \psi_a\psi_b.
\end{equation}
The $G$-matrix equation can then be rewritten in the following
compact form
\begin{equation}
   G(\omega )=V+V\frac{\hat{Q}}{\omega -H_0}G(\omega ),
\end{equation}
with
$\hat{Q}=\sum_{ab}\vert \psi_a\psi_b\langle\langle \psi_a\psi_b\vert$.
In terms of diagrams, $G$ corresponds to an all-order sum of the
"ladder-type" interactions between two particles with the
intermediate states restricted by $Q$.

The $G$-matrix equation has a very simple form. But its
calculation is rather complicated, particularly for finite
nuclear systems such as the nucleus $^{18}$O. There are a
number of complexities. To mention a few, the Pauli operator
$Q$ may not commute with the unperturbed hamiltonian
$H_0$ and we have to make the replacement
\[
\frac{Q}{\omega -H_0}\rightarrow Q\frac{1}{\omega -QH_0Q}Q.
\]
The determination of the starting energy $\omega$ is also another
problem. 


In a medium such as nuclear 
matter we must account
for the fact that certain states are not available as intermediate
states in the calculation of the $G$-matrix.
Following the discussion above
this is achieved by introducing the medium
dependent Pauli operator $Q$. Further, the
energy $\omega$ of the incoming particles, given by a pure kinetic
term in a scattering problem between two unbound particles (for example two colliding protons), must be modified so as to allow
for medium corrections.
How to evaluate the Pauli operator for
nuclear matter is, however, not straightforward.
Before discussing how to evaluate the Pauli operator for nuclear matter,
we note that the $G$-matrix
is conventionally given in terms of partial waves and
the coordinates of the relative and center-of-mass motion.
If we assume that the $G$-matrix is diagonal in $\alpha$ ($\alpha$ is a shorthand
notation for $J$, $S$, $L$ and $T$), we  write the equation for the $G$-matrix as a 
coupled-channels equation in the relative and center-of-mass system
\begin{equation}
   G_{ll'}^{\alpha}(kk'K\omega )=V_{ll'}^{\alpha}(kk')
   +\sum_{l''}\int \frac{d^3 q}{(2\pi )^3}V_{ll''}^{\alpha}(kq)
   \frac{Q(q,K)}{\omega -H_0}
   G_{l''l'}^{\alpha}(qk'K\omega).
   \label{eq:gnonrel}
\end{equation}
This equation is similar in structure to the scattering
equations discussed in connection with nuclear forces (see the chapter on models for nuclear forces), except that we now have
introduced the Pauli operator $Q$ and a medium dependent two-particle
energy $\omega$. The notations in this equation follow those of the chapter on nuclear forces
where we discuss the solution of the scattering
matrix $T$.
The numerical details on how to solve the above $G$-matrix
equation through matrix inversion techniques are discussed below
Note however that the $G$-matrix may not be diagonal in $\alpha$.
This is due to the fact that the
Pauli operator $Q$ is not diagonal
in the above representation in the relative and center-of-mass
system. The Pauli operator depends on the
angle between the relative momentum and the center of mass momentum.
This angle dependence causes $Q$ to couple states with different
relative angular
momentua ${\cal J}$, rendering  a partial wave decomposition of the $G$-matrix equation 
rather difficult.
The angle dependence of the Pauli operator
can be eliminated by introducing the angle-average
Pauli operator, where one replaces the exact Pauli operator $Q$
by its average $\bar{Q}$ over all angles for fixed relative and center-of-mass
momenta.
The choice of Pauli operator is decisive to the determination of the
sp
spectrum. Basically, to first order in the reaction matrix $G$,
there are three commonly used sp spectra, all
defined by the solution of the following equations
\begin{equation}
   \varepsilon_{m} = \varepsilon (k_{m})= t_{m} + u_{m}=\frac{k_{m}^2}{2M_N}+u_{m},
   \label{eq:spnrel}
\end{equation}
and
\begin{align}
   u_{m} =& {\displaystyle \sum_{h \leq k_F}}\left\langle m h \right| G(\omega = \varepsilon_{m} + \varepsilon_h )
   \left| m h \right\rangle_{AS}  \hspace{3mm}k_m \leq k_M,  \\ \\
   u_m=&0, k_m > k_M.
   \label{eq:selfcon}
\end{align}
For notational economy, we set $|{\bf k}_m|=k_m$.
Here we employ antisymmetrized matrix elements (AS), and $k_M$ is a cutoff
on the momentum. Further, $t_m$ is the sp kinetic
energy and similarly $u_m$
is the
sp potential.
The choice of cutoff $k_M$ is actually what determines the three
commonly used sp spectra.
In the conventional BHF approach one employs $k_M = k_F$,
which leads
to a Pauli operator $Q_{\mathrm{BHF}}$ (in the laboratory system) given by
\begin{equation}
   Q_{\mathrm{BHF}}(k_m , k_n ) =
    \left\{\begin{array}{cc}1,&min(k_m ,k_n ) > k_F\\
    0,&\mathrm{else}.\end{array}\right.
    \label{eq:bhf},
\end{equation}
or, since we will define an
angle-average Pauli operator in the relative and center-of-mass
system, we have
\begin{equation}
     \bar{Q}_{\mathrm{BHF}}(k,K)=\left\{\begin{array}{cc}
         0,&k\leq \sqrt{k_{F}^{2}-K^2/4}\\
         1,&k\geq k_F + K/2\\
	\frac{K^2/4+k^2 -k_{F}^2}{kK}&\mathrm{else},\end{array}\right.
    \label{eq:qbhf}
\end{equation}
with $k_F$ the momentum at the Fermi surface.

The BHF choice sets $u_k = 0$ for $k > k_F$, which leads
to an unphysical, large gap at the Fermi surface, typically
of the order of $50-60$ MeV. 
To overcome the gap
problem, Mahaux and collaborators 
introduced a continuous sp spectrum
for all values of $k$. The divergencies
which then may occur in Eq. (\ref{eq:gnonrel}) are taken care of by
introducing
a principal value integration in Eq. (\ref{eq:gnonrel}),
to retain only the
real part contribution to the $G$-matrix.


To define the energy denominators we will also make use of the
angle-average approximation.
The angle dependence is handled by the
so-called effective mass approximation. The single-particle energies
in nuclear matter are assumed to have the simple quadratic form
\begin{equation}
   \begin{array}{ccc}
   \varepsilon (k_m)=&
   {\displaystyle\frac{\hbar^{2}k_m^2}
   {2M_{N}^{*}}}+\Delta ,&\hspace{3mm}k_m\leq k_F\\
   &&\\
   =&{\displaystyle\frac{\hbar^{2}
   k_m^2}{2M_{N}}},&\hspace{3mm}k_m> k_F ,\\
   \end{array}
   \label{eq:spen}
\end{equation}
where $M_{N}^{*}$ is the effective mass of the nucleon and $M_{N}$ is the
bare nucleon mass. For particle states above the Fermi sea we choose
a pure kinetic energy term, whereas for hole states,
the terms $M_{N}^{*}$ and $\Delta$, the latter being 
an effective single-particle
potential related to the $G$-matrix, are obtained through the
self-consistent Brueckner-Hartree-Fock procedure.
The sp potential is obtained through the same angle-average approximation
\begin{align}
  \label{eq:Uav}
   U(k_m) & =\sum_{l\alpha} (2T+1)(2J+1)
   \left \{ \frac{8}{\pi}\int_{0}^{(k_F-k_m)/2}
   k^2dk G_{ll}^{\alpha}(k,\bar{K}_1) \right.  \\
   &    \left.
    + \frac{1}{\pi k_m}\int_{(k_F-k_m)/2}^{(k_F+k_m)/2}
   kdk (k_F ^2-(k_m-2k)^2)
   G_{ll}^{\alpha}(k,\bar{K}_2)  \right \}  \nonumber,
\end{align}
where we have defined
\begin{equation}
    \bar{K}_1^2=4(k_m^2+k^2),
\end{equation}
and
\begin{equation}
    \bar{K}_2^2=4(k_m^2+k^2)-(2k+k_m-k_F)(2k+k_1+k_F).
\end{equation}
This
self-consistency scheme consists in choosing adequate initial values of the
effective mass and $\Delta$. The obtained $G$-matrix is in turn used to
obtain new values for $M_{N}^{*}$ and $\Delta$. This procedure
continues until these parameters vary little.





\section{Full Configuration Interaction Theory}

We have defined the ansatz for the ground state as 
\[
|\Phi_0\rangle = \left(\prod_{i\le F}\hat{a}_{i}^{\dagger}\right)|0\rangle,
\]
where the index $i$ defines different single-particle states up to the Fermi level. We have assumed that we have $N$ fermions. 
A given one-particle-one-hole ($1p1h$) state can be written as
\[
|\Phi_i^a\rangle = \hat{a}_{a}^{\dagger}\hat{a}_i|\Phi_0\rangle,
\]
while a $2p2h$ state can be written as
\[
|\Phi_{ij}^{ab}\rangle = \hat{a}_{a}^{\dagger}\hat{a}_{b}^{\dagger}\hat{a}_j\hat{a}_i|\Phi_0\rangle,
\]
and a general $ApAh$ state as 
\[
|\Phi_{ijk\dots}^{abc\dots}\rangle = \hat{a}_{a}^{\dagger}\hat{a}_{b}^{\dagger}\hat{a}_{c}^{\dagger}\dots\hat{a}_k\hat{a}_j\hat{a}_i|\Phi_0\rangle.
\]

We use letters $ijkl\dots$ for states below the Fermi level and $abcd\dots$ for states above the Fermi level. A general single-particle state is given by letters $pqrs\dots$.

We can then expand our exact state function for the ground state 
as
\[
|\Psi_0\rangle=C_0|\Phi_0\rangle+\sum_{ai}C_i^a|\Phi_i^a\rangle+\sum_{abij}C_{ij}^{ab}|\Phi_{ij}^{ab}\rangle+\dots
=(C_0+\hat{C})|\Phi_0\rangle,
\]
where we have introduced the so-called correlation operator 
\[
\hat{C}=\sum_{ai}C_i^a\hat{a}_{a}^{\dagger}\hat{a}_i  +\sum_{abij}C_{ij}^{ab}\hat{a}_{a}^{\dagger}\hat{a}_{b}^{\dagger}\hat{a}_j\hat{a}_i+\dots
\]
Since the normalization of $\Psi_0$ is at our disposal and since $C_0$ is by hypothesis non-zero, we may arbitrarily set $C_0=1$ with 
corresponding proportional changes in all other coefficients. Using this so-called intermediate normalization we have
\[
\langle \Psi_0 | \Phi_0 \rangle = \langle \Phi_0 | \Phi_0 \rangle = 1, 
\]
resulting in 
\[
|\Psi_0\rangle=(1+\hat{C})|\Phi_0\rangle.
\]


We rewrite 
\[
|\Psi_0\rangle=C_0|\Phi_0\rangle+\sum_{ai}C_i^a|\Phi_i^a\rangle+\sum_{abij}C_{ij}^{ab}|\Phi_{ij}^{ab}\rangle+\dots,
\]
in a more compact form as 
\[
|\Psi_0\rangle=\sum_{PH}C_H^P\Phi_H^P=\left(\sum_{PH}C_H^P\hat{A}_H^P\right)|\Phi_0\rangle,
\]
where $H$ stands for $0,1,\dots,n$ hole states and $P$ for $0,1,\dots,n$ particle states. 
Our requirement of unit normalization gives
\[
\langle \Psi_0 | \Psi_0 \rangle = \sum_{PH}|C_H^P|^2= 1,
\]
and the energy can be written as 
\[
E= \langle \Psi_0 | \hat{H} |\Psi_0 \rangle= \sum_{PP'HH'}C_H^{*P}\langle \Phi_H^P | \hat{H} |\Phi_{H'}^{P'} \rangle C_{H'}^{P'}.
\]


Normally 
\[
E= \langle \Psi_0 | \hat{H} |\Psi_0 \rangle= \sum_{PP'HH'}C_H^{*P}\langle \Phi_H^P | \hat{H} |\Phi_{H'}^{P'} \rangle C_{H'}^{P'},
\]
is solved by diagonalization setting up the Hamiltonian matrix defined by the basis of all possible Slater determinants. A diagonalization
is equivalent to finding the variational minimum   of 
\[
 \langle \Psi_0 | \hat{H} |\Psi_0 \rangle-\lambda \langle \Psi_0 |\Psi_0 \rangle,
\]
where $\lambda$ is a variational multiplier to be identified with the energy of the system.

The minimization process results in 
\[
\delta\left[ \langle \Psi_0 | \hat{H} |\Psi_0 \rangle-\lambda \langle \Psi_0 |\Psi_0 \rangle\right]=
\]
\[
\sum_{P'H'}\left\{\delta[C_H^{*P}]\langle \Phi_H^P | \hat{H} |\Phi_{H'}^{P'} \rangle C_{H'}^{P'}+
C_H^{*P}\langle \Phi_H^P | \hat{H} |\Phi_{H'}^{P'} \rangle \delta[C_{H'}^{P'}]-
\lambda( \delta[C_H^{*P}]C_{H'}^{P'}+C_H^{*P}\delta[C_{H'}^{P'}]\right\} = 0.
\]
Since the coefficients $\delta[C_H^{*P}]$ and $\delta[C_{H'}^{P'}]$ are complex conjugates it is necessary and sufficient to require the quantities that multiply with $\delta[C_H^{*P}]$ to vanish.  

This leads to 
\[
\sum_{P'H'}\langle \Phi_H^P | \hat{H} |\Phi_{H'}^{P'} \rangle C_{H'}^{P'}-\lambda C_H^{P}=0,
\]
for all sets of $P$ and $H$.

If we then multiply by the corresponding $C_H^{*P}$ and sum over $PH$ we obtain
\[ 
\sum_{PP'HH'}C_H^{*P}\langle \Phi_H^P | \hat{H} |\Phi_{H'}^{P'} \rangle C_{H'}^{P'}-\lambda\sum_{PH}|C_H^P|^2=0,
\]
leading to the identification $\lambda = E$. This means that we have for all $PH$ sets
\begin{equation}
\sum_{P'H'}\langle \Phi_H^P | \hat{H} -E|\Phi_{H'}^{P'} \rangle = 0. \label{eq:fullci}
\end{equation}



An alternative way to derive the last equation is to start from 
\[
(\hat{H} -E)|\Psi_0\rangle = (\hat{H} -E)\sum_{P'H'}C_{H'}^{P'}|\Phi_{H'}^{P'} \rangle=0, 
\]
and if this equation is successively projected against all $\Phi_H^P$ in the expansion of $\Psi$, we end up with Eq.~(\ref{eq:fullci}).

One solves this equation normally by diagonalization. If we are able to solve this equation exactly (that is
numerically exactly) in a large Hilbert space (it will be truncated in terms of the number of single-particle states included in the definition
of Slater determinants), it can then serve as a benchmark for other many-body methods which approximate the correlation operator
$\hat{C}$.  


\subsection{Example of a Hamiltonian matrix}

Suppose, as an example, that we have six fermions below the Fermi level.
This means that we can make at most $6p-6h$ excitations. If we have an infinity of single particle states above the Fermi level, we will obviously have an infinity of say $2p-2h$ excitations. Each such way to configure the particles is called a \textbf{configuration}. We will always have to truncate in the basis of single-particle states.
This gives us a finite number of possible Slater determinants. Our Hamiltonian matrix would then look like (where each block can have a large dimensionalities):


\begin{quote}
\begin{tabular}{cccccccc}
\hline
\multicolumn{1}{c}{  } & \multicolumn{1}{c}{ $0p-0h$ } & \multicolumn{1}{c}{ $1p-1h$ } & \multicolumn{1}{c}{ $2p-2h$ } & \multicolumn{1}{c}{ $3p-3h$ } & \multicolumn{1}{c}{ $4p-4h$ } & \multicolumn{1}{c}{ $5p-5h$ } & \multicolumn{1}{c}{ $6p-6h$ } \\
\hline
$0p-0h$ & x       & x       & x       & 0       & 0       & 0       & 0       \\
$1p-1h$ & x       & x       & x       & x       & 0       & 0       & 0       \\
$2p-2h$ & x       & x       & x       & x       & x       & 0       & 0       \\
$3p-3h$ & 0       & x       & x       & x       & x       & x       & 0       \\
$4p-4h$ & 0       & 0       & x       & x       & x       & x       & x       \\
$5p-5h$ & 0       & 0       & 0       & x       & x       & x       & x       \\
$6p-6h$ & 0       & 0       & 0       & 0       & x       & x       & x       \\
\hline
\end{tabular}
\end{quote}

\noindent
with a two-body force. Why are there non-zero blocks of elements? 
If we use a Hartree-Fock basis, this corresponds to a particular unitary transformation where matrix elements of the type $\langle 0p-0h \vert \hat{H} \vert 1p-1h\rangle =\langle \Phi_0 | \hat{H}|\Phi_{i}^{a}\rangle=0$ and our Hamiltonian matrix becomes 


\begin{quote}
\begin{tabular}{cccccccc}
\hline
\multicolumn{1}{c}{  } & \multicolumn{1}{c}{ $0p-0h$ } & \multicolumn{1}{c}{ $1p-1h$ } & \multicolumn{1}{c}{ $2p-2h$ } & \multicolumn{1}{c}{ $3p-3h$ } & \multicolumn{1}{c}{ $4p-4h$ } & \multicolumn{1}{c}{ $5p-5h$ } & \multicolumn{1}{c}{ $6p-6h$ } \\
\hline
$0p-0h$ & $\tilde{x}$ & 0           & $\tilde{x}$ & 0           & 0           & 0           & 0           \\
$1p-1h$ & 0           & $\tilde{x}$ & $\tilde{x}$ & $\tilde{x}$ & 0           & 0           & 0           \\
$2p-2h$ & $\tilde{x}$ & $\tilde{x}$ & $\tilde{x}$ & $\tilde{x}$ & $\tilde{x}$ & 0           & 0           \\
$3p-3h$ & 0           & $\tilde{x}$ & $\tilde{x}$ & $\tilde{x}$ & $\tilde{x}$ & $\tilde{x}$ & 0           \\
$4p-4h$ & 0           & 0           & $\tilde{x}$ & $\tilde{x}$ & $\tilde{x}$ & $\tilde{x}$ & $\tilde{x}$ \\
$5p-5h$ & 0           & 0           & 0           & $\tilde{x}$ & $\tilde{x}$ & $\tilde{x}$ & $\tilde{x}$ \\
$6p-6h$ & 0           & 0           & 0           & 0           & $\tilde{x}$ & $\tilde{x}$ & $\tilde{x}$ \\
\hline
\end{tabular}
\end{quote}

\noindent
If we do not make any truncations in the possible sets of Slater determinants (many-body states) we can make by distributing $A$ nucleons among $n$ single-particle states, we call such a calculation for 
\begin{itemize}
\item Full configuration interaction theory
\end{itemize}

\noindent
If we make truncations, we have different possibilities

\begin{itemize}
\item The standard nuclear shell-model. Here we define an effective Hilbert space with respect to a given core. The calculations are normally then performed for all many-body states that can be constructed from the effective Hilbert spaces. This approach requires a properly defined effective Hamiltonian

\item We can truncate in the number of excitations. For example, we can limit the possible Slater determinants to only $1p-1h$ and $2p-2h$ excitations. This is called a configuration interaction calculation at the level of singles and doubles excitations, or just CISD. 

\item We can limit the number of excitations in terms of the excitation energies. If we do not define a core, this defines normally what is called the no-core shell-model approach. 
\end{itemize}

\noindent
What happens if we have a three-body interaction and a Hartree-Fock basis? 

Full configuration interaction theory calculations provide in principle, if we can diagonalize numerically, all states of interest. The dimensionality of the problem explodes however quickly.

The total number of Slater determinants which can be built with say $N$ neutrons distributed among $n$ single particle states is
\[
\left (\begin{array}{c} n \\ N\end{array} \right) =\frac{n!}{(n-N)!N!}. 
\]

For a model space which comprises the first for major shells only $0s$, $0p$, $1s0d$ and $1p0f$ we have $40$ single particle states for neutrons and protons.  For the eight neutrons of oxygen-16 we would then have
\[
\left (\begin{array}{c} 40 \\ 8\end{array} \right) =\frac{40!}{(32)!8!}\sim 10^{9}, 
\]
and multiplying this with the number of proton Slater determinants we end up with approximately witha dimensionality $d$ of $d\sim 10^{18}$.


This number can be reduced if we look at specific symmetries only. However, the dimensionality explodes quickly!

\begin{itemize}
\item For Hamiltonian matrices of dimensionalities  which are smaller than $d\sim 10^5$, we would use so-called direct methods for diagonalizing the Hamiltonian matrix

\item For larger dimensionalities iterative eigenvalue solvers like Lanczos' method are used. The most efficient codes at present can handle matrices of $d\sim 10^{10}$. 
\end{itemize}

\noindent
\subsection{A non-practical way of solving the eigenvalue problem}

For reasons to come (links with Coupled-Cluster theory and Many-Body perturbation theory), 
we will rewrite Eq.~(\ref{eq:fullci}) as a set of coupled non-linear equations in terms of the unknown coefficients $C_H^P$. 
To obtain the eigenstates and eigenvalues in terms of non-linear equations is not a very practical approach. However, it serves the scope of linking FCI theory with approximative solutions to the many-body problem.

To see this, we look at the contributions arising from 
\[
\langle \Phi_H^P | = \langle \Phi_0|
\]
in  Eq.~(\ref{eq:fullci}), that is we multiply with $\langle \Phi_0 |$
from the left in 
\[
(\hat{H} -E)\sum_{P'H'}C_{H'}^{P'}|\Phi_{H'}^{P'} \rangle=0. 
\]
If we assume that we have a two-body operator at most, Slater's rule gives then an equation for the 
correlation energy in terms of $C_i^a$ and $C_{ij}^{ab}$ only.  We get then
\[
\langle \Phi_0 | \hat{H} -E| \Phi_0\rangle + \sum_{ai}\langle \Phi_0 | \hat{H} -E|\Phi_{i}^{a} \rangle C_{i}^{a}+
\sum_{abij}\langle \Phi_0 | \hat{H} -E|\Phi_{ij}^{ab} \rangle C_{ij}^{ab}=0,
\]
or 
\[
E-E_0 =\Delta E=\sum_{ai}\langle \Phi_0 | \hat{H}|\Phi_{i}^{a} \rangle C_{i}^{a}+
\sum_{abij}\langle \Phi_0 | \hat{H}|\Phi_{ij}^{ab} \rangle C_{ij}^{ab},
\]
where the energy $E_0$ is the reference energy and $\Delta E$ defines the so-called correlation energy.
The single-particle basis functions  could be the results of a Hartree-Fock calculation or just the eigenstates of the non-interacting part of the Hamiltonian. 

In our notes on Hartree-Fock calculations, 
we have already computed the matrix $\langle \Phi_0 | \hat{H}|\Phi_{i}^{a}\rangle $ and $\langle \Phi_0 | \hat{H}|\Phi_{ij}^{ab}\rangle$.  If we are using a Hartree-Fock basis, then the matrix elements
$\langle \Phi_0 | \hat{H}|\Phi_{i}^{a}\rangle=0$ and we are left with a \emph{correlation energy} given by
\[
E-E_0 =\Delta E^{HF}=\sum_{abij}\langle \Phi_0 | \hat{H}|\Phi_{ij}^{ab} \rangle C_{ij}^{ab}. 
\]


Inserting the various matrix elements we can rewrite the previous equation as
\[
\Delta E=\sum_{ai}\langle i| \hat{f}|a \rangle C_{i}^{a}+
\sum_{abij}\langle ij | \hat{v}| ab \rangle C_{ij}^{ab}.
\]
This equation determines the correlation energy but not the coefficients $C$. 
We need more equations. Our next step is to set up
\[
\langle \Phi_i^a | \hat{H} -E| \Phi_0\rangle + \sum_{bj}\langle \Phi_i^a | \hat{H} -E|\Phi_{j}^{b} \rangle C_{j}^{b}+
\sum_{bcjk}\langle \Phi_i^a | \hat{H} -E|\Phi_{jk}^{bc} \rangle C_{jk}^{bc}+
\sum_{bcdjkl}\langle \Phi_i^a | \hat{H} -E|\Phi_{jkl}^{bcd} \rangle C_{jkl}^{bcd}=0,
\]
as this equation will allow us to find an expression for the coefficents $C_i^a$ since we can rewrite this equation as 
\[
\langle i | \hat{f}| a\rangle +\langle \Phi_i^a | \hat{H}|\Phi_{i}^{a} \rangle C_{i}^{a}+ \sum_{bj\ne ai}\langle \Phi_i^a | \hat{H}|\Phi_{j}^{b} \rangle C_{j}^{b}+
\sum_{bcjk}\langle \Phi_i^a | \hat{H}|\Phi_{jk}^{bc} \rangle C_{jk}^{bc}+
\sum_{bcdjkl}\langle \Phi_i^a | \hat{H}|\Phi_{jkl}^{bcd} \rangle C_{jkl}^{bcd}=EC_i^a.
\]

We see that on the right-hand side we have the energy $E$. This leads to a non-linear equation in the unknown coefficients. 
These equations are normally solved iteratively ( that is we can start with a guess for the coefficients $C_i^a$). A common choice is to use perturbation theory for the first guess, setting thereby
\[
 C_{i}^{a}=\frac{\langle i | \hat{f}| a\rangle}{\epsilon_i-\epsilon_a}.
\]

The observant reader will however see that we need an equation for $C_{jk}^{bc}$ and $C_{jkl}^{bcd}$ as well.
To find equations for these coefficients we need then to continue our multiplications from the left with the various
$\Phi_{H}^P$ terms. 


For $C_{jk}^{bc}$ we need then
\[
\langle \Phi_{ij}^{ab} | \hat{H} -E| \Phi_0\rangle + \sum_{kc}\langle \Phi_{ij}^{ab} | \hat{H} -E|\Phi_{k}^{c} \rangle C_{k}^{c}+
\]
\[
\sum_{cdkl}\langle \Phi_{ij}^{ab} | \hat{H} -E|\Phi_{kl}^{cd} \rangle C_{kl}^{cd}+\sum_{cdeklm}\langle \Phi_{ij}^{ab} | \hat{H} -E|\Phi_{klm}^{cde} \rangle C_{klm}^{cde}+\sum_{cdefklmn}\langle \Phi_{ij}^{ab} | \hat{H} -E|\Phi_{klmn}^{cdef} \rangle C_{klmn}^{cdef}=0,
\]
and we can isolate the coefficients $C_{kl}^{cd}$ in a similar way as we did for the coefficients $C_{i}^{a}$. 
A standard choice for the first iteration is to set 
\[
C_{ij}^{ab} =\frac{\langle ij \vert \hat{v} \vert ab \rangle}{\epsilon_i+\epsilon_j-\epsilon_a-\epsilon_b}.
\]
At the end we can rewrite our solution of the Schroedinger equation in terms of $n$ coupled equations for the coefficients $C_H^P$.
This is a very cumbersome way of solving the equation. However, by using this iterative scheme we can illustrate how we can compute the
various terms in the wave operator or correlation operator $\hat{C}$. We will later identify the calculation of the various terms $C_H^P$
as parts of different many-body approximations to full CI. In particular, we can  relate this non-linear scheme with Coupled Cluster theory and
many-body perturbation theory.


\subsection{Summarizing FCI and bringing in approximative methods}


If we can diagonalize large matrices, FCI is the method of choice since:
\begin{itemize}
\item It gives all eigenvalues, ground state and excited states

\item The eigenvectors are obtained directly from the coefficients $C_H^P$ which result from the diagonalization

\item We can compute easily expectation values of other operators, as well as transition probabilities

\item Correlations are easy to understand in terms of contributions to a given operator beyond the Hartree-Fock contribution. This is the standard approach in  many-body theory. 
\end{itemize}

\noindent
The correlation energy is defined as, with a two-body Hamiltonian,  
\[
\Delta E=\sum_{ai}\langle i| \hat{f}|a \rangle C_{i}^{a}+
\sum_{abij}\langle ij | \hat{v}| ab \rangle C_{ij}^{ab}.
\]

The coefficients $C$ result from the solution of the eigenvalue problem. 
The energy of say the ground state is then
\[
E=E_{ref}+\Delta E,
\]
where the so-called reference energy is the energy we obtain from a Hartree-Fock calculation, that is
\[
E_{ref}=\langle \Phi_0 \vert \hat{H} \vert \Phi_0 \rangle.
\]

However, as we have seen, even for a small case like the four first major shells and a nucleus like oxygen-16, the dimensionality becomes quickly intractable. If we wish to include single-particle states that reflect weakly bound systems, we need a much larger single-particle basis. We need thus approximative methods that sum specific correlations to infinite order. 

Popular methods are
\begin{itemize}
\item Many-body perturbation theory (in essence a Taylor expansion)

\item Coupled cluster theory (coupled non-linear equations)

\item Green's function approaches (matrix inversion)

\item Similarity group transformation methods (coupled ordinary differential equations
\end{itemize}

\noindent
All these methods start normally with a Hartree-Fock basis as the calculational basis. 


\subsection{Building a many-body basis}

Here we will discuss how we can set up a single-particle basis which we can use in the various parts of our projects, from the simple pairing model to infinite nuclear matter. We will use here the simple pairing model to illustrate in particular how to set up a single-particle basis. We will also use this do discuss standard FCI approaches like:
\begin{enumerate}
 \item Standard shell-model basis in one or two major shells

 \item Full CI in a given basis and no truncations

 \item CISD and CISDT approximations

 \item No-core shell model and truncation in excitation energy
\end{enumerate}

\noindent
An important step in an FCI code  is to construct the many-body basis.  

While the formalism is independent of the choice of basis, the \textbf{effectiveness} of a calculation 
will certainly be basis dependent. 

Furthermore there are common conventions useful to know.

First, the single-particle basis has angular momentum as a good quantum number.  You can 
imagine the single-particle wavefunctions being generated by a one-body Hamiltonian, 
for example a harmonic oscillator.  Modifications include harmonic oscillator plus 
spin-orbit splitting, or self-consistent mean-field potentials, or the Woods-Saxon potential which mocks 
up the self-consistent mean-field. 
For nuclei, the harmonic oscillator, modified by spin-orbit splitting, provides a useful language 
for describing single-particle states.


Each single-particle state is labeled by the following quantum numbers: 

\begin{itemize}
\item Orbital angular momentum $l$

\item Intrinsic spin $s$ = 1/2 for protons and neutrons

\item Angular momentum $j = l \pm 1/2$

\item $z$-component $j_z$ (or $m$)

\item Some labeling of the radial wavefunction, typically $n$ the number of nodes in  the radial wavefunction, but in the case of harmonic oscillator one can also use the principal quantum number $N$, where the harmonic oscillator energy is $(N+3/2)\hbar \omega$.  For our nuclear matter projects, you will need to change the quantum numbers to those relevant for calculations
\end{itemize}

\noindent
in three-dimensional cartesian basis, see the relevante \href{{https://github.com/NuclearTalent/Course2ManyBodyMethods/blob/master/doc/pub/cc/pdf/Lectures1-2_TALENT_NuclearMatter_GH.pdf}}{lectures}.


In this format one labels states by $n(l)_j$, with $(l)$ replaced by a letter:
$s$ for $l=0$, $p$ for $l=1$, $d$ for $l=2$, $f$ for $l=3$, and thenceforth alphabetical.


 In practice the single-particle space has to be severely truncated.  This truncation is 
typically based upon the single-particle energies, which is the effective energy 
from a mean-field potential. 

Sometimes we freeze the core and only consider a valence space. For example, one 
may assume a frozen ${}^{4}\mbox{He}$ core, with two protons and two neutrons in the $0s_{1/2}$ 
shell, and then only allow active particles in the $0p_{1/2}$ and $0p_{3/2}$ orbits. 


Another example is a frozen ${}^{16}\mbox{O}$ core, with eight protons and eight neutrons filling the 
$0s_{1/2}$,  $0p_{1/2}$ and $0p_{3/2}$ orbits, with valence particles in the 
$0d_{5/2}, 1s_{1/2}$ and $0d_{3/2}$ orbits.


Sometimes we refer to nuclei by the valence space where their last nucleons go.  
So, for example, we call ${}^{12}\mbox{C}$ a $p$-shell nucleus, while ${}^{26}\mbox{Al}$ is an 
$sd$-shell nucleus and ${}^{56}\mbox{Fe}$ is a $pf$-shell nucleus.





There are different kinds of truncations.

\begin{itemize}
\item For example, one can start with `filled' orbits (almost always the lowest), and then  allow one, two, three... particles excited out of those filled orbits. These are called  1p-1h, 2p-2h, 3p-3h excitations. 

\item Alternately, one can state a maximal orbit and allow all possible configurations with  particles occupying states up to that maximum. This is called \emph{full configuration}.

\item Finally, for particular use in nuclear physics, there is the \emph{energy} truncation, also  called the $N\hbar\Omega$ or $N_{max}$ truncation. 
\end{itemize}

\noindent
Here one works in a harmonic oscillator basis, with each major oscillator shell assigned  a principal quantum number $N=0,1,2,3,...$. 
The $N\hbar\Omega$ or $N_{max}$ truncation: Any configuration is given an noninteracting energy, which is the sum 
of the single-particle harmonic oscillator energies. (Thus this ignores 
spin-orbit splitting.)

Excited state are labeled relative to the lowest configuration by the 
number of harmonic oscillator quanta.

This truncation is useful because if one includes \emph{all} configuration up to 
some $N_{max}$, and has a translationally invariant interaction, then the intrinsic 
motion and the center-of-mass motion factor. In other words, we can know exactly 
the center-of-mass wavefunction. 

In almost all cases, the many-body Hamiltonian is rotationally invariant. This means 
it commutes with the operators $\hat{J}^2, \hat{J}_z$ and so eigenstates will have 
good $J,M$. Furthermore, the eigenenergies do not depend upon the orientation $M$. 


Therefore we can choose to construct a many-body basis which has fixed $M$; this is 
called an $M$-scheme basis. 


Alternately, one can construct a many-body basis which has fixed $J$, or a $J$-scheme 
basis. 

The Hamiltonian matrix will have smaller dimensions (a factor of 10 or more) in the $J$-scheme than in the $M$-scheme. 
On the other hand, as we'll show in the next slide, the $M$-scheme is very easy to 
construct with Slater determinants, while the $J$-scheme basis states, and thus the 
matrix elements, are more complicated, almost always being linear combinations of 
$M$-scheme states. $J$-scheme bases are important and useful, but we'll focus on the 
simpler $M$-scheme.

The quantum number $m$ is additive (because the underlying group is Abelian): 
if a Slater determinant $\hat{a}_i^\dagger \hat{a}^\dagger_j \hat{a}^\dagger_k \ldots | 0 \rangle$ 
is built from single-particle states all with good $m$, then the total 
\[
M = m_i + m_j + m_k + \ldots
\]
This is \emph{not} true of $J$, because the angular momentum group SU(2) is not Abelian.

The upshot is that 
\begin{itemize}
\item It is easy to construct a Slater determinant with good total $M$;

\item It is trivial to calculate $M$ for each Slater determinant;

\item So it is easy to construct an $M$-scheme basis with fixed total $M$.
\end{itemize}

\noindent
Note that the individual $M$-scheme basis states will \emph{not}, in general, 
have good total $J$. 
Because the Hamiltonian is rotationally invariant, however, the eigenstates will 
have good $J$. (The situation is muddied when one has states of different $J$ that are 
nonetheless degenerate.) 




Example: two $j=1/2$ orbits


\begin{quote}
\begin{tabular}{ccccc}
\hline
\multicolumn{1}{c}{ Index } & \multicolumn{1}{c}{ $n$ } & \multicolumn{1}{c}{ $l$ } & \multicolumn{1}{c}{ $j$ } & \multicolumn{1}{c}{ $m_j$ } \\
\hline
1     & 0   & 0   & 1/2 & -1/2  \\
2     & 0   & 0   & 1/2 & 1/2   \\
3     & 1   & 0   & 1/2 & -1/2  \\
4     & 1   & 0   & 1/2 & 1/2   \\
\hline
\end{tabular}
\end{quote}

\noindent
Note that the order is arbitrary.
There are $\left ( \begin{array}{c} 4 \\ 2 \end{array} \right) = 6$ two-particle states, 
which we list with the total $M$:


\begin{quote}
\begin{tabular}{cc}
\hline
\multicolumn{1}{c}{ Occupied } & \multicolumn{1}{c}{ $M$ } \\
\hline
1,2      & 0   \\
1,3      & -1  \\
1,4      & 0   \\
2,3      & 0   \\
2,4      & 1   \\
3,4      & 0   \\
\hline
\end{tabular}
\end{quote}

\noindent
and 1 each with $M = \pm 1$.




As another example, consider using only single particle states from the $0d_{5/2}$ space. 
They have the following quantum numbers


\begin{quote}
\begin{tabular}{ccccc}
\hline
\multicolumn{1}{c}{ Index } & \multicolumn{1}{c}{ $n$ } & \multicolumn{1}{c}{ $l$ } & \multicolumn{1}{c}{ $j$ } & \multicolumn{1}{c}{ $m_j$ } \\
\hline
1     & 0   & 2   & 5/2 & -5/2  \\
2     & 0   & 2   & 5/2 & -3/2  \\
3     & 0   & 2   & 5/2 & -1/2  \\
4     & 0   & 2   & 5/2 & 1/2   \\
5     & 0   & 2   & 5/2 & 3/2   \\
6     & 0   & 2   & 5/2 & 5/2   \\
\hline
\end{tabular}
\end{quote}

\noindent
There are $\left ( \begin{array}{c} 6 \\ 2 \end{array} \right) = 15$ two-particle states, 
which we list with the total $M$:


\begin{quote}
\begin{tabular}{cccccc}
\hline
\multicolumn{1}{c}{ Occupied } & \multicolumn{1}{c}{ $M$ } & \multicolumn{1}{c}{ Occupied } & \multicolumn{1}{c}{ $M$ } & \multicolumn{1}{c}{ Occupied } & \multicolumn{1}{c}{ $M$ } \\
\hline
1,2      & -4  & 2,3      & -2  & 3,5      & 1   \\
1,3      & -3  & 2,4      & -1  & 3,6      & 2   \\
1,4      & -2  & 2,5      & 0   & 4,5      & 2   \\
1,5      & -1  & 2,6      & 1   & 4,6      & 3   \\
1,6      & 0   & 3,4      & 0   & 5,6      & 4   \\
\hline
\end{tabular}
\end{quote}


\section{Many-body perturbation theory}

\subsection{Many-body perturbation theory}

We assume here that we are only interested in the ground state of the system and 
expand the exact wave function in term of a series of Slater determinants
\[
\vert \Psi_0\rangle = \vert \Phi_0\rangle + \sum_{m=1}^{\infty}C_m\vert \Phi_m\rangle,
\]
where we have assumed that the true ground state is dominated by the 
solution of the unperturbed problem, that is
\[
\hat{H}_0\vert \Phi_0\rangle= W_0\vert \Phi_0\rangle.
\]
The state $\vert \Psi_0\rangle$ is not normalized, rather we have used an intermediate 
normalization $\langle \Phi_0 \vert \Psi_0\rangle=1$ since we have $\langle \Phi_0\vert \Phi_0\rangle=1$. 



The Schroedinger equation is
\[
\hat{H}\vert \Psi_0\rangle = E\vert \Psi_0\rangle,
\]
and multiplying the latter from the left with $\langle \Phi_0\vert $ gives
\[
\langle \Phi_0\vert \hat{H}\vert \Psi_0\rangle = E\langle \Phi_0\vert \Psi_0\rangle=E,
\]
and subtracting from this equation
\[
\langle \Psi_0\vert \hat{H}_0\vert \Phi_0\rangle= W_0\langle \Psi_0\vert \Phi_0\rangle=W_0,
\]
and using the fact that the both operators $\hat{H}$ and $\hat{H}_0$ are hermitian 
results in
\[
\Delta E=E-W_0=\langle \Phi_0\vert \hat{H}_I\vert \Psi_0\rangle,
\]
which is an exact result. We call this quantity the correlation energy.



This equation forms the starting point for all perturbative derivations. However,
as it stands it represents nothing but a mere formal rewriting of Schroedinger's equation and is not of much practical use. The exact wave function $\vert \Psi_0\rangle$ is unknown. In order to obtain a perturbative expansion, we need to expand the exact wave function in terms of the interaction $\hat{H}_I$. 

Here we have assumed that our model space defined by the operator $\hat{P}$ is one-dimensional, meaning that
\[
\hat{P}= \vert \Phi_0\rangle \langle \Phi_0\vert ,
\]
and
\[
\hat{Q}=\sum_{m=1}^{\infty}\vert \Phi_m\rangle \langle \Phi_m\vert .
\]


We can thus rewrite the exact wave function as
\[
\vert \Psi_0\rangle= (\hat{P}+\hat{Q})\vert \Psi_0\rangle=\vert \Phi_0\rangle+\hat{Q}\vert \Psi_0\rangle.
\]
Going back to the Schr\"odinger equation, we can rewrite it as, adding and a subtracting a term $\omega \vert \Psi_0\rangle$ as
\[
\left(\omega-\hat{H}_0\right)\vert \Psi_0\rangle=\left(\omega-E+\hat{H}_I\right)\vert \Psi_0\rangle,
\]
where $\omega$ is an energy variable to be specified later. 


We assume also that the resolvent of $\left(\omega-\hat{H}_0\right)$ exits, that is
it has an inverse which defined the unperturbed Green's function as
\[
\left(\omega-\hat{H}_0\right)^{-1}=\frac{1}{\left(\omega-\hat{H}_0\right)}.
\]

We can rewrite Schroedinger's equation as
\[
\vert \Psi_0\rangle=\frac{1}{\omega-\hat{H}_0}\left(\omega-E+\hat{H}_I\right)\vert \Psi_0\rangle,
\]
and multiplying from the left with $\hat{Q}$ results in
\[
\hat{Q}\vert \Psi_0\rangle=\frac{\hat{Q}}{\omega-\hat{H}_0}\left(\omega-E+\hat{H}_I\right)\vert \Psi_0\rangle,
\]
which is possible since we have defined the operator $\hat{Q}$ in terms of the eigenfunctions of $\hat{H}$.




These operators commute meaning that
\[
\hat{Q}\frac{1}{\left(\omega-\hat{H}_0\right)}\hat{Q}=\hat{Q}\frac{1}{\left(\omega-\hat{H}_0\right)}=\frac{\hat{Q}}{\left(\omega-\hat{H}_0\right)}.
\]
With these definitions we can in turn define the wave function as 
\[
\vert \Psi_0\rangle=\vert \Phi_0\rangle+\frac{\hat{Q}}{\omega-\hat{H}_0}\left(\omega-E+\hat{H}_I\right)\vert \Psi_0\rangle.
\]
This equation is again nothing but a formal rewrite of Schr\"odinger's equation
and does not represent a practical calculational scheme.  
It is a non-linear equation in two unknown quantities, the energy $E$ and the exact
wave function $\vert \Psi_0\rangle$. We can however start with a guess for $\vert \Psi_0\rangle$ on the right hand side of the last equation.



 The most common choice is to start with the function which is expected to exhibit the largest overlap with the wave function we are searching after, namely $\vert \Phi_0\rangle$. This can again be inserted in the solution for $\vert \Psi_0\rangle$ in an iterative fashion and if we continue along these lines we end up with
\[
\vert \Psi_0\rangle=\sum_{i=0}^{\infty}\left\{\frac{\hat{Q}}{\omega-\hat{H}_0}\left(\omega-E+\hat{H}_I\right)\right\}^i\vert \Phi_0\rangle, 
\]
for the wave function and
\[
\Delta E=\sum_{i=0}^{\infty}\langle \Phi_0\vert \hat{H}_I\left\{\frac{\hat{Q}}{\omega-\hat{H}_0}\left(\omega-E+\hat{H}_I\right)\right\}^i\vert \Phi_0\rangle, 
\]
which is now  a perturbative expansion of the exact energy in terms of the interaction
$\hat{H}_I$ and the unperturbed wave function $\vert \Psi_0\rangle$.



In our equations for $\vert \Psi_0\rangle$ and $\Delta E$ in terms of the unperturbed
solutions $\vert \Phi_i\rangle$  we have still an undetermined parameter $\omega$
and a dependecy on the exact energy $E$. Not much has been gained thus from a practical computational point of view. 

In Brilluoin-Wigner perturbation theory it is customary to set $\omega=E$. This results in the following perturbative expansion for the energy $\Delta E$
\[
\Delta E=\sum_{i=0}^{\infty}\langle \Phi_0\vert \hat{H}_I\left\{\frac{\hat{Q}}{\omega-\hat{H}_0}\left(\omega-E+\hat{H}_I\right)\right\}^i\vert \Phi_0\rangle=
\]
\[
\langle \Phi_0\vert \left(\hat{H}_I+\hat{H}_I\frac{\hat{Q}}{E-\hat{H}_0}\hat{H}_I+
\hat{H}_I\frac{\hat{Q}}{E-\hat{H}_0}\hat{H}_I\frac{\hat{Q}}{E-\hat{H}_0}\hat{H}_I+\dots\right)\vert \Phi_0\rangle. 
\]

\[
\Delta E=\sum_{i=0}^{\infty}\langle \Phi_0\vert \hat{H}_I\left\{\frac{\hat{Q}}{\omega-\hat{H}_0}\left(\omega-E+\hat{H}_I\right)\right\}^i\vert \Phi_0\rangle=\]
\[
\langle \Phi_0\vert \left(\hat{H}_I+\hat{H}_I\frac{\hat{Q}}{E-\hat{H}_0}\hat{H}_I+
\hat{H}_I\frac{\hat{Q}}{E-\hat{H}_0}\hat{H}_I\frac{\hat{Q}}{E-\hat{H}_0}\hat{H}_I+\dots\right)\vert \Phi_0\rangle. 
\]
This expression depends however on the exact energy $E$ and is again not very convenient from a practical point of view. It can obviously be solved iteratively, by starting with a guess for  $E$ and then solve till some kind of self-consistency criterion has been reached. 

Actually, the above expression is nothing but a rewrite again of the full Schr\"odinger equation. 

Defining $e=E-\hat{H}_0$ and recalling that $\hat{H}_0$ commutes with 
$\hat{Q}$ by construction and that $\hat{Q}$ is an idempotent operator
$\hat{Q}^2=\hat{Q}$. 
Using this equation in the above expansion for $\Delta E$ we can write the denominator 
\[
\hat{Q}\frac{1}{\hat{e}-\hat{Q}\hat{H}_I\hat{Q}}=
\]
\[
\hat{Q}\left[\frac{1}{\hat{e}}+\frac{1}{\hat{e}}\hat{Q}\hat{H}_I\hat{Q}
\frac{1}{\hat{e}}+\frac{1}{\hat{e}}\hat{Q}\hat{H}_I\hat{Q}
\frac{1}{\hat{e}}\hat{Q}\hat{H}_I\hat{Q}\frac{1}{\hat{e}}+\dots\right]\hat{Q}.
\]

Inserted in the expression for $\Delta E$ leads to 
\[
\Delta E=
\langle \Phi_0\vert \hat{H}_I+\hat{H}_I\hat{Q}\frac{1}{E-\hat{H}_0-\hat{Q}\hat{H}_I\hat{Q}}\hat{Q}\hat{H}_I\vert \Phi_0\rangle. 
\]
In RS perturbation theory we set $\omega = W_0$ and obtain the following expression for the energy difference
\[
\Delta E=\sum_{i=0}^{\infty}\langle \Phi_0\vert \hat{H}_I\left\{\frac{\hat{Q}}{W_0-\hat{H}_0}\left(\hat{H}_I-\Delta E\right)\right\}^i\vert \Phi_0\rangle=
\]
\[
\langle \Phi_0\vert \left(\hat{H}_I+\hat{H}_I\frac{\hat{Q}}{W_0-\hat{H}_0}(\hat{H}_I-\Delta E)+
\hat{H}_I\frac{\hat{Q}}{W_0-\hat{H}_0}(\hat{H}_I-\Delta E)\frac{\hat{Q}}{W_0-\hat{H}_0}(\hat{H}_I-\Delta E)+\dots\right)\vert \Phi_0\rangle.
\]



Recalling that $\hat{Q}$ commutes with $\hat{H_0}$ and since $\Delta E$ is a constant we obtain that
\[
\hat{Q}\Delta E\vert \Phi_0\rangle = \hat{Q}\Delta E\vert \hat{Q}\Phi_0\rangle = 0.
\]
Inserting this results in the expression for the energy results in
\[
\Delta E=\langle \Phi_0\vert \left(\hat{H}_I+\hat{H}_I\frac{\hat{Q}}{W_0-\hat{H}_0}\hat{H}_I+
\hat{H}_I\frac{\hat{Q}}{W_0-\hat{H}_0}(\hat{H}_I-\Delta E)\frac{\hat{Q}}{W_0-\hat{H}_0}\hat{H}_I+\dots\right)\vert \Phi_0\rangle.
\]



We can now this expression in terms of a perturbative expression in terms
of $\hat{H}_I$ where we iterate the last expression in terms of $\Delta E$
\[
\Delta E=\sum_{i=1}^{\infty}\Delta E^{(i)}.
\]
We get the following expression for $\Delta E^{(i)}$
\[
\Delta E^{(1)}=\langle \Phi_0\vert \hat{H}_I\vert \Phi_0\rangle,
\] 
which is just the contribution to first order in perturbation theory,
\[
\Delta E^{(2)}=\langle\Phi_0\vert \hat{H}_I\frac{\hat{Q}}{W_0-\hat{H}_0}\hat{H}_I\vert \Phi_0\rangle, 
\]
which is the contribution to second order.



\[
\Delta E^{(3)}=\langle \Phi_0\vert \hat{H}_I\frac{\hat{Q}}{W_0-\hat{H}_0}\hat{H}_I\frac{\hat{Q}}{W_0-\hat{H}_0}\hat{H}_I\Phi_0\rangle-
\langle\Phi_0\vert \hat{H}_I\frac{\hat{Q}}{W_0-\hat{H}_0}\langle \Phi_0\vert \hat{H}_I\vert \Phi_0\rangle\frac{\hat{Q}}{W_0-\hat{H}_0}\hat{H}_I\vert \Phi_0\rangle,
\]
being the third-order contribution. 


\subsection{Interpreting the correlation energy and the wave operator}

In the shell-model lectures we showed that we could rewrite the exact state function for say the ground state, as a linear expansion in terms of all possible Slater determinants. That is, we 
define the ansatz for the ground state as 
\[
|\Phi_0\rangle = \left(\prod_{i\le F}\hat{a}_{i}^{\dagger}\right)|0\rangle,
\]
where the index $i$ defines different single-particle states up to the Fermi level. We have assumed that we have $N$ fermions. 
A given one-particle-one-hole ($1p1h$) state can be written as
\[
|\Phi_i^a\rangle = \hat{a}_{a}^{\dagger}\hat{a}_i|\Phi_0\rangle,
\]
while a $2p2h$ state can be written as
\[
|\Phi_{ij}^{ab}\rangle = \hat{a}_{a}^{\dagger}\hat{a}_{b}^{\dagger}\hat{a}_j\hat{a}_i|\Phi_0\rangle,
\]
and a general $ApAh$ state as 
\[
|\Phi_{ijk\dots}^{abc\dots}\rangle = \hat{a}_{a}^{\dagger}\hat{a}_{b}^{\dagger}\hat{a}_{c}^{\dagger}\dots\hat{a}_k\hat{a}_j\hat{a}_i|\Phi_0\rangle.
\]

We use letters $ijkl\dots$ for states below the Fermi level and $abcd\dots$ for states above the Fermi level. A general single-particle state is given by letters $pqrs\dots$.

We can then expand our exact state function for the ground state 
as
\[
|\Psi_0\rangle=C_0|\Phi_0\rangle+\sum_{ai}C_i^a|\Phi_i^a\rangle+\sum_{abij}C_{ij}^{ab}|\Phi_{ij}^{ab}\rangle+\dots
=(C_0+\hat{C})|\Phi_0\rangle,
\]
where we have introduced the so-called correlation operator 
\[
\hat{C}=\sum_{ai}C_i^a\hat{a}_{a}^{\dagger}\hat{a}_i  +\sum_{abij}C_{ij}^{ab}\hat{a}_{a}^{\dagger}\hat{a}_{b}^{\dagger}\hat{a}_j\hat{a}_i+\dots
\]
Since the normalization of $\Psi_0$ is at our disposal and since $C_0$ is by hypothesis non-zero, we may arbitrarily set $C_0=1$ with 
corresponding proportional changes in all other coefficients. Using this so-called intermediate normalization we have
\[
\langle \Psi_0 | \Phi_0 \rangle = \langle \Phi_0 | \Phi_0 \rangle = 1, 
\]
resulting in 
\[
|\Psi_0\rangle=(1+\hat{C})|\Phi_0\rangle.
\]

In a shell-model calculation, the unknown coefficients in $\hat{C}$ are the 
eigenvectors which result from the diagonalization of the Hamiltonian matrix.

How can we use perturbation theory to determine the same coefficients? Let us study the contributions to second order in the interaction, namely
\[
\Delta E^{(2)}=\langle\Phi_0\vert \hat{H}_I\frac{\hat{Q}}{W_0-\hat{H}_0}\hat{H}_I\vert \Phi_0\rangle.
\]

The intermediate states given by $\hat{Q}$ can at most be of a $2p-2h$ nature if we have a two-body Hamiltonian. This means that second order in the perturbation theory can have $1p-1h$ and $2p-2h$ at most as intermediate states. When we diagonalize, these contributions are included to infinite order. This means that higher-orders in perturbation theory bring in more complicated correlations. 

If we limit the attention to a Hartree-Fock basis, then we have that
$\langle\Phi_0\vert \hat{H}_I \vert 2p-2h\rangle$ is the only contribution and the contribution to the energy reduces to
\[
\Delta E^{(2)}=\frac{1}{4}\sum_{abij}\langle ij\vert \hat{v}\vert ab\rangle \frac{\langle ab\vert \hat{v}\vert ij\rangle}{\epsilon_i+\epsilon_j-\epsilon_a-\epsilon_b}.
\]

If we compare this to the correlation energy obtained from full configuration interaction theory with a Hartree-Fock basis, we found that
\[
E-E_0 =\Delta E=
\sum_{abij}\langle ij | \hat{v}| ab \rangle C_{ij}^{ab},
\]
where the energy $E_0$ is the reference energy and $\Delta E$ defines the so-called correlation energy.

We see that if we set
\[
C_{ij}^{ab} =\frac{1}{4}\frac{\langle ab \vert \hat{v} \vert ij \rangle}{\epsilon_i+\epsilon_j-\epsilon_a-\epsilon_b},
\]
we have a perfect agreement between FCI and MBPT. However, FCI includes such $2p-2h$ correlations to infinite order. In order to make a meaningful comparison we would at least need to sum such correlations to infinite order in perturbation theory. 

Summing up, we can see that
\begin{itemize}
\item MBPT introduces order-by-order specific correlations and we make comparisons with exact calculations like FCI

\item At every order, we can calculate all contributions since they are well-known and either tabulated or calculated on the fly.

\item MBPT is a non-variational theory and there is no guarantee that higher orders will improve the convergence. 

\item However, since FCI calculations are limited by the size of the Hamiltonian matrices to diagonalize (today's most efficient codes can attach dimensionalities of ten billion basis states, MBPT can function as an approximative method which gives a straightforward (but tedious) calculation recipe. 

\item MBPT has been widely used to compute effective interactions for the nuclear shell-model.

\item But there are better methods which sum to infinite order important correlations. Coupled cluster theory is one of these methods. 
\end{itemize}

\section{Coupled cluster theory}
\section{Introduction}
Coester and Kummel first developed the ideas that led to coupled-cluster
theory in the late 1950s. The basic idea is that the correlated wave function
of a many-body system $\mid\Psi\rangle$
can be formulated as an exponential of correlation
operators $T$ acting on a reference state $\mid\Phi\rangle$
\[
\mid\Psi\rangle = \exp\left(-\hat{T}\right)\mid\Phi\rangle\ .
\]
We will discuss how to define the operators later in this work. This simple
ansatz carries enormous power. It leads to a non-perturbative many-body
theory that includes summation of ladder diagrams , ring
diagrams, and an infinite-order
generalization of many-body perturbation theory..

Developments and applications
of coupled-cluster theory took different routes in chemistry
and nuclear physics. In quantum chemistry,
coupled-cluster developments
and applications have proven to be extremely useful, see for example the review by \href{{http://journals.aps.org/rmp/abstract/10.1103/RevModPhys.79.291}}{Barrett and Musial} as well as the recent 
textbook by \href{{http://www.cambridge.org/fr/academic/subjects/chemistry/physical-chemistry/many-body-methods-chemistry-and-physics-mbpt-and-coupled-cluster-theory?format=HB}}{Shavitt and Barrett}.  Many previous applications to nuclear physics struggled with the repulsive character of the nuclear forces and limited basis sets used in the computations. Most of these problems have been overcome during the last decade and coupled-cluster
theory is one of the computational methods of preference for doing nuclear physics, with applications ranging from light nuclei to medium-heavy nuclei,
see for example the recent review by \href{{http://iopscience.iop.org/0034-4885/77/9/096302}}{Hagen, Papenbrock, Hjorth-Jensen and Dean}. 


\subsection{A non-practical way of solving the eigenvalue problem}

Before we proceed with the derivation of the Coupled cluster equations, let us repeat some of the arguments we presented during our FCI lectures. 
In our FCI discussions, we rewrote the solution of the Schroedinger equation as a set of coupled equationsin the unknown coefficients $C$. Let us repeat some of these arguments.
To obtain the eigenstates and eigenvalues in terms of non-linear equations is not a very practical approach. However, it serves the scope of linking FCI theory with approximative solutions to the many-body problem
like Coupled cluster (CC) theory 

If we assume that we have a two-body operator at most, the Slater-Condon rule 
gives then an equation for the 
correlation energy in terms of $C_i^a$ and $C_{ij}^{ab}$ only.  We get then
\[
\langle \Phi_0 | \hat{H} -E| \Phi_0\rangle + \sum_{ai}\langle \Phi_0 | \hat{H} -E|\Phi_{i}^{a} \rangle C_{i}^{a}+
\sum_{abij}\langle \Phi_0 | \hat{H} -E|\Phi_{ij}^{ab} \rangle C_{ij}^{ab}=0,
\]
or 
\[
E-E_0 =\Delta E=\sum_{ai}\langle \Phi_0 | \hat{H}|\Phi_{i}^{a} \rangle C_{i}^{a}+
\sum_{abij}\langle \Phi_0 | \hat{H}|\Phi_{ij}^{ab} \rangle C_{ij}^{ab},
\]
where the energy $E_0$ is the reference energy and $\Delta E$ defines the so-called correlation energy.
The single-particle basis functions  could be the results of a Hartree-Fock calculation or just the eigenstates of the non-interacting part of the Hamiltonian. 

In our notes on Hartree-Fock calculations, 
we have already computed the matrix $\langle \Phi_0 | \hat{H}|\Phi_{i}^{a}\rangle $ and $\langle \Phi_0 | \hat{H}|\Phi_{ij}^{ab}\rangle$.  If we are using a Hartree-Fock basis, then the matrix elements
$\langle \Phi_0 | \hat{H}|\Phi_{i}^{a}\rangle=0$ and we are left with a \emph{correlation energy} given by
\[
E-E_0 =\Delta E^{HF}=\sum_{abij}\langle \Phi_0 | \hat{H}|\Phi_{ij}^{ab} \rangle C_{ij}^{ab}. 
\]


Inserting the various matrix elements we can rewrite the previous equation as
\[
\Delta E=\sum_{ai}\langle i| \hat{f}|a \rangle C_{i}^{a}+
\sum_{abij}\langle ij | \hat{v}| ab \rangle C_{ij}^{ab}.
\]
This equation determines the correlation energy but not the coefficients $C$. 
We need more equations. Our next step is to set up
\[
\langle \Phi_i^a | \hat{H} -E| \Phi_0\rangle + \sum_{bj}\langle \Phi_i^a | \hat{H} -E|\Phi_{j}^{b} \rangle C_{j}^{b}+
\sum_{bcjk}\langle \Phi_i^a | \hat{H} -E|\Phi_{jk}^{bc} \rangle C_{jk}^{bc}+
\sum_{bcdjkl}\langle \Phi_i^a | \hat{H} -E|\Phi_{jkl}^{bcd} \rangle C_{jkl}^{bcd}=0,
\]
as this equation will allow us to find an expression for the coefficents $C_i^a$ since we can rewrite this equation as 
\[
\langle i | \hat{f}| a\rangle +\langle \Phi_i^a | \hat{H}|\Phi_{i}^{a} \rangle C_{i}^{a}+ \sum_{bj\ne ai}\langle \Phi_i^a | \hat{H}|\Phi_{j}^{b} \rangle C_{j}^{b}+
\sum_{bcjk}\langle \Phi_i^a | \hat{H}|\Phi_{jk}^{bc} \rangle C_{jk}^{bc}+
\sum_{bcdjkl}\langle \Phi_i^a | \hat{H}|\Phi_{jkl}^{bcd} \rangle C_{jkl}^{bcd}=EC_i^a.
\]

We see that on the right-hand side we have the energy $E$. This leads to a non-linear equation in the unknown coefficients. 
These equations are normally solved iteratively ( that is we can start with a guess for the coefficients $C_i^a$). A common choice is to use perturbation theory for the first guess, setting thereby
\[
 C_{i}^{a}=\frac{\langle i | \hat{f}| a\rangle}{\epsilon_i-\epsilon_a}.
\]

The observant reader will however see that we need an equation for $C_{jk}^{bc}$ and $C_{jkl}^{bcd}$ as well.
To find equations for these coefficients we need then to continue our multiplications from the left with the various
$\Phi_{H}^P$ terms. 


For $C_{jk}^{bc}$ we need then
\[
\langle \Phi_{ij}^{ab} | \hat{H} -E| \Phi_0\rangle + \sum_{kc}\langle \Phi_{ij}^{ab} | \hat{H} -E|\Phi_{k}^{c} \rangle C_{k}^{c}+
\]
\[
\sum_{cdkl}\langle \Phi_{ij}^{ab} | \hat{H} -E|\Phi_{kl}^{cd} \rangle C_{kl}^{cd}+\sum_{cdeklm}\langle \Phi_{ij}^{ab} | \hat{H} -E|\Phi_{klm}^{cde} \rangle C_{klm}^{cde}+\sum_{cdefklmn}\langle \Phi_{ij}^{ab} | \hat{H} -E|\Phi_{klmn}^{cdef} \rangle C_{klmn}^{cdef}=0,
\]
and we can isolate the coefficients $C_{kl}^{cd}$ in a similar way as we did for the coefficients $C_{i}^{a}$. 
A standard choice for the first iteration is to set 
\[
C_{ij}^{ab} =\frac{\langle ij \vert \hat{v} \vert ab \rangle}{\epsilon_i+\epsilon_j-\epsilon_a-\epsilon_b}.
\]
At the end we can rewrite our solution of the Schroedinger equation in terms of $n$ coupled equations for the coefficients $C_H^P$.
This is a very cumbersome way of solving the equation. However, by using this iterative scheme we can illustrate how we can compute the
various terms in the wave operator or correlation operator $\hat{C}$. We will later identify the calculation of the various terms $C_H^P$
as parts of different many-body approximations to full CI. In particular, we can  relate this non-linear scheme with Coupled Cluster theory and
many-body perturbation theory.


\subsection{Summarizing FCI and bringing in approximative methods}


If we can diagonalize large matrices, FCI is the method of choice since:
\begin{itemize}
\item It gives all eigenvalues, ground state and excited states

\item The eigenvectors are obtained directly from the coefficients $C_H^P$ which result from the diagonalization

\item We can compute easily expectation values of other operators, as well as transition probabilities

\item Correlations are easy to understand in terms of contributions to a given operator beyond the Hartree-Fock contribution. This is the standard approach in  many-body theory. 
\end{itemize}

\noindent
The correlation energy is defined as, with a two-body Hamiltonian,  
\[
\Delta E=\sum_{ai}\langle i| \hat{f}|a \rangle C_{i}^{a}+
\sum_{abij}\langle ij | \hat{v}| ab \rangle C_{ij}^{ab}.
\]

The coefficients $C$ result from the solution of the eigenvalue problem. 
The energy of say the ground state is then
\[
E=E_{ref}+\Delta E,
\]
where the so-called reference energy is the energy we obtain from a Hartree-Fock calculation, that is
\[
E_{ref}=\langle \Phi_0 \vert \hat{H} \vert \Phi_0 \rangle.
\]

However, as we have seen, even for a small case like the four first major shells and a nucleus like oxygen-16, the dimensionality becomes quickly intractable. If we wish to include single-particle states that reflect weakly bound systems, we need a much larger single-particle basis. We need thus approximative methods that sum specific correlations to infinite order. 

Popular methods are
\begin{itemize}
\item \href{{http://www.sciencedirect.com/science/journal/03701573/261/3-4}}{Many-body perturbation theory (in essence a Taylor expansion)}

\item \href{{http://iopscience.iop.org/0034-4885/77/9/096302}}{Coupled cluster theory (coupled non-linear equations)}

\item \href{{http://www.worldscientific.com/worldscibooks/10.1142/6821}}{Green's function approaches (matrix inversion)}

\item \href{{http://journals.aps.org/prc/abstract/10.1103/PhysRevC.85.061304}}{Similarity group transformation methods (coupled ordinary differential equations)}
\end{itemize}

\noindent
All these methods start normally with a Hartree-Fock basis as the calculational basis. 


\subsection{A quick tour of Coupled Cluster theory}

The ansatz for the wavefunction (ground state) is given by
\begin{equation*}
   \vert \Psi\rangle = \vert \Psi_{CC}\rangle = e^{\hat{T}} \vert \Phi_0\rangle =  
  \left( \sum_{n=1}^{A} \frac{1}{n!} \hat{T}^n \right) \vert \Phi_0\rangle,
\end{equation*}
where $A$ represents the maximum number of particle-hole excitations and $\hat{T}$ is the cluster operator defined as
\begin{align*}
            \hat{T} &= \hat{T}_1 + \hat{T}_2 + \ldots + \hat{T}_A \\
            \hat{T}_n &= \left(\frac{1}{n!}\right)^2 
                \sum_{\substack{
                        i_1,i_2,\ldots i_n \\
                        a_1,a_2,\ldots a_n}}
                t_{i_1i_2\ldots i_n}^{a_1a_2\ldots a_n} a_{a_1}^\dagger a_{a_2}^\dagger \ldots a_{a_n}^\dagger a_{i_n} \ldots a_{i_2} a_{i_1}.
        \end{align*}
    The energy is given by
    \begin{equation*}
        E_{\mathrm{CC}} = \langle\Phi_0\vert  \overline{H}\vert \Phi_0\rangle,
    \end{equation*}
    where $\overline{H}$ is a similarity transformed Hamiltonian
    \begin{align*}
        \overline{H}&= e^{-\hat{T}} \hat{H}_N e^{\hat{T}} \\
        \hat{H}_N &= \hat{H} - \langle\Phi_0\vert \hat{H} \vert \Phi_0\rangle.
    \end{align*}

    The coupled cluster energy is a function of the unknown cluster amplitudes $t_{i_1i_2\ldots i_n}^{a_1a_2\ldots a_n}$,
given by the solutions to the amplitude equations
    \begin{equation*}
        0 = \langle\Phi_{i_1 \ldots i_n}^{a_1 \ldots a_n}\vert \overline{H}\vert \Phi_0\rangle.
    \end{equation*}
The similarity transformed   Hamiltonian  $\overline{H}$ is expanded using the Baker-Campbell-Hausdorff expression,
    \begin{align*}
        \overline{H}&= \hat{H}_N + \left[ \hat{H}_N, \hat{T} \right] + 
            \frac{1}{2} \left[\left[ \hat{H}_N, \hat{T} \right], \hat{T}\right] + \ldots \\
            & \quad \frac{1}{n!} \left[ \ldots \left[ \hat{H}_N, \hat{T} \right], \ldots \hat{T} \right] +\dots
    \end{align*}
and simplified using the connected cluster theorem
    \begin{equation*}
        \overline{H}= \hat{H}_N + \left( \hat{H}_N \hat{T}\right)_c + \frac{1}{2} \left( \hat{H}_N \hat{T}^2\right)_c
            + \dots + \frac{1}{n!} \left( \hat{H}_N \hat{T}^n\right)_c +\dots
    \end{equation*}

A much used approximation is to  truncate the cluster operator $\hat{T}$ at the $n=2$ level. This defines the so-called singes and doubles approximation to the Coupled Cluster wavefunction, normally shortened to CCSD..

The coupled cluster wavefunction is now given by
\begin{equation*}
            \vert \Psi_{CC}\rangle = e^{\hat{T}_1 + \hat{T}_2} \vert \Phi_0\rangle
\end{equation*}
where 
        \begin{align*}
            \hat{T}_1 &= 
            \sum_{ia}
                t_{i}^{a} a_{a}^\dagger a_i \\
            \hat{T}_2 &= \frac{1}{4} 
            \sum_{ijab}
                t_{ij}^{ab} a_{a}^\dagger a_{b}^\dagger a_{j} a_{i}.
        \end{align*}

The amplutudes $t$ play a role similar to the coefficients $C$ in the shell-model calculations. They are obtained by solving a set of non-linear equations
similar to those discussed above in connection withe FCI discussion.

If we truncate our equations at the CCSD level, it corresponds to performing a transformation of the Hamiltonian matrix of the following type for a six particle problem (with a two-body Hamiltonian):


\begin{quote}
\begin{tabular}{cccccccc}
\hline
\multicolumn{1}{c}{  } & \multicolumn{1}{c}{ $0p-0h$ } & \multicolumn{1}{c}{ $1p-1h$ } & \multicolumn{1}{c}{ $2p-2h$ } & \multicolumn{1}{c}{ $3p-3h$ } & \multicolumn{1}{c}{ $4p-4h$ } & \multicolumn{1}{c}{ $5p-5h$ } & \multicolumn{1}{c}{ $6p-6h$ } \\
\hline
$0p-0h$ & $\tilde{x}$ & $\tilde{x}$ & $\tilde{x}$ & 0           & 0           & 0           & 0           \\
$1p-1h$ & 0           & $\tilde{x}$ & $\tilde{x}$ & $\tilde{x}$ & 0           & 0           & 0           \\
$2p-2h$ & 0           & $\tilde{x}$ & $\tilde{x}$ & $\tilde{x}$ & $\tilde{x}$ & 0           & 0           \\
$3p-3h$ & 0           & $\tilde{x}$ & $\tilde{x}$ & $\tilde{x}$ & $\tilde{x}$ & $\tilde{x}$ & 0           \\
$4p-4h$ & 0           & 0           & $\tilde{x}$ & $\tilde{x}$ & $\tilde{x}$ & $\tilde{x}$ & $\tilde{x}$ \\
$5p-5h$ & 0           & 0           & 0           & $\tilde{x}$ & $\tilde{x}$ & $\tilde{x}$ & $\tilde{x}$ \\
$6p-6h$ & 0           & 0           & 0           & 0           & $\tilde{x}$ & $\tilde{x}$ & $\tilde{x}$ \\
\hline
\end{tabular}
\end{quote}

\noindent


In our FCI discussion the correlation energy is defined as, with a two-body Hamiltonian,  
\[
\Delta E=\sum_{ai}\langle i| \hat{f}|a \rangle C_{i}^{a}+
\sum_{abij}\langle ij | \hat{v}| ab \rangle C_{ij}^{ab}.
\]

In Coupled cluster theory it becomes (irrespective of level of truncation of $T$)
\[
\Delta E=\sum_{ai}\langle i| \hat{f}|a \rangle t_{i}^{a}+
\sum_{abij}\langle ij | \hat{v}| ab \rangle t_{ij}^{ab}.
\]

Coupled cluster theory has several interesting computational features and is the method of choice in quantum chemistry. The method was originally proposed by Coester and Kummel, two nuclear physicists (way back in the fifties). It came back in full strength in nuclear physics during the last decade. 

There are several interesting features:
\begin{itemize}
\item With a truncation like CCSD or CCSDT, we can include to infinite order correlations like $2p-2h$.

\item We can include a large basis of single-particle states, not possible in standard FCI calculations
\end{itemize}

\noindent
However, Coupled Cluster theory is
\begin{itemize}
\item non-variational

\item if we want to find properties of excited states, additional calculations via for example equation of motion methods are needed

\item if correlations are strong, a single-reference ansatz may not be the best starting point

\item we cannot quantify properly the error we make when truncations are made in the cluster operator
\end{itemize}

\noindent
\subsection{The CCD approximation}

We will now approximate the cluster operator $\hat{T}$ to include only $2p-2h$ correlations. This leads to the so-called CCD approximation, that is
\[
\hat{T}\approx \hat{T}_2=\frac{1}{4}\sum_{abij}t_{ij}^{ab}a^{\dagger}_aa^{\dagger}_ba_ja_i,
\]
meaning that we have
\[
\vert \Psi_0 \rangle \approx \vert \Psi_{CCD} \rangle = \exp{\left(\hat{T}_2\right)}\vert \Phi_0\rangle.
\]

Inserting these equations in the expression for the computation of the energy we have,
with a Hamiltonian defined with respect to a general vacuum (see the exercises in the second quantization part)
\[
\hat{H}=\hat{H}_N+E_{\mathrm{ref}},
\]
with 
\[
\hat{H}_N=\sum_{pq}\langle p \vert \hat{f} \vert q \rangle  a^{\dagger}_pa_q + \frac{1}{4}\sum_{pqrs}\langle pq \vert \hat{v} \vert rs \rangle a^{\dagger}_pa^{\dagger}_qa_sa_r,
\]
we obtain that the energy can be written as 
\[
\langle \Phi_0 \vert \exp{-\left(\hat{T}_2\right)}\hat{H}_N\exp{\left(\hat{T}_2\right)}\vert \Phi_0\rangle =
\langle \Phi_0 \vert \hat{H}_N(1+\hat{T}_2)\vert \Phi_0\rangle = E_{CCD}.
\]
This quantity becomes 
\[
E_{CCD}=E_{\mathrm{ref}}+\frac{1}{4}\sum_{abij}\langle ij \vert \hat{v} \vert ab \rangle t_{ij}^{ab},
\]
where the latter is the correlation energy from this level of approximation of CC theory. 
Similarly, the expression for the amplitudes reads
\[
\langle \Phi_{ij}^{ab} \vert \exp{-\left(\hat{T}_2\right)}\hat{H}_N\exp{\left(\hat{T}_2\right)}\vert \Phi_0\rangle = 0.
\]
These equations can be reduced to (after several applications of Wick's theorem) to, for all $i > j$ and all $a  > b$,
\begin{align}
0 = \langle ab \vert \hat{v} \vert ij \rangle + \left(\epsilon_a+\epsilon_b-\epsilon_i-\epsilon_j\right)t_{ij}^{ab} & \nonumber \\ 
+\frac{1}{2}\sum_{cd} \langle ab \vert \hat{v} \vert cd \rangle t_{ij}^{cd}+\frac{1}{2}\sum_{kl} \langle kl \vert \hat{v} \vert ij \rangle t_{kl}^{ab}+\hat{P}(ij\vert ab)\sum_{kc} \langle kb \vert \hat{v} \vert cj \rangle t_{ik}^{ac} & \nonumber \\
+\frac{1}{4}\sum_{klcd} \langle kl \vert \hat{v} \vert cd \rangle t_{ij}^{cd}t_{kl}^{ab}+\hat{P}(ij)\sum_{klcd} \langle kl \vert \hat{v} \vert cd \rangle t_{ik}^{ac}t_{jl}^{bd}& \nonumber \\
-\frac{1}{2}\hat{P}(ij)\sum_{klcd} \langle kl \vert \hat{v} \vert cd \rangle t_{ik}^{dc}t_{lj}^{ab}-\frac{1}{2}\hat{P}(ab)\sum_{klcd} \langle kl \vert \hat{v} \vert cd \rangle t_{lk}^{ac}t_{ij}^{db},&
\label{eq:ccd}
\end{align}
where we have defined 
\[
\hat{P}\left(ab\right)= 1-\hat{P}_{ab},
\]
where $\hat{P}_{ab}$ interchanges two particles occupying the quantum numbers $a$ and $b$. 
The operator $\hat{P}(ij\vert ab)$  is defined as
\[
\hat{P}(ij\vert ab) = (1-\hat{P}_{ij})(1-\hat{P}_{ab}).
\]
Recall also that the unknown amplitudes $t_{ij}^{ab}$
represent anti-symmetrized matrix elements, meaning that they obey the same symmetry relations as the two-body interaction, that is
\[
t_{ij}^{ab}=-t_{ji}^{ab}=-t_{ij}^{ba}=t_{ji}^{ba}.
\]
The two-body matrix elements are also anti-symmetrized, meaning that
\[
\langle ab \vert \hat{v} \vert ij \rangle = -\langle ab \vert \hat{v} \vert ji \rangle= -\langle ba \vert \hat{v} \vert ij \rangle=\langle ba \vert \hat{v} \vert ji \rangle.
\]
The non-linear equations for the unknown amplitudes  $t_{ij}^{ab}$ are solved iteratively. We discuss the implementation of these equations below.

\paragraph{Approximations to the full CCD equations.}
It is useful to make approximations to the equations for the amplitudes. The standard method for solving these equations is to set up an iterative scheme where method's like Newton's method or similar root searching methods are used to find the amplitudes. 
Itreative solvers need a guess for the amplitudes. A good starting point is to use the correlated wave operator from perturbation theory to
first order in the interaction.
This means that we define the zeroth approximation to the amplitudes as 
\[
t^{(0)}=\frac{\langle ab \vert \hat{v} \vert ij \rangle}{\left(\epsilon_i+\epsilon_j-\epsilon_a-\epsilon_b\right)},
\]
leading to our first approximation for the correlation energy at the CCD level to be equal to second-order perturbation theory without $1p-1h$ excitations, namely
\[
\Delta E_{\mathrm{CCD}}^{(0)}=\frac{1}{4}\sum_{abij} \frac{\langle ij \vert \hat{v} \vert ab \rangle \langle ab \vert \hat{v} \vert ij \rangle}{\left(\epsilon_i+\epsilon_j-\epsilon_a-\epsilon_b\right)}.
\]

With this starting point, we are now ready to solve Eq. (\ref{eq:ccd}) iteratively. Before we attack the full equations, it is however instructive to study a truncated version of the equations. We will first study the following approximation where we take away all terms except the linear terms that involve the single-particle energies and the the two-particle intermediate excitations, that is
\begin{equation}
0 = \langle ab \vert \hat{v} \vert ij \rangle + \left(\epsilon_a+\epsilon_b-\epsilon_i-\epsilon_j\right)t_{ij}^{ab}+\frac{1}{2}\sum_{cd} \langle ab \vert \hat{v} \vert cd \rangle t_{ij}^{cd}.
\label{eq:ccd1}
\end{equation}

Setting the single-particle energies for the hole states equal to an energy variable $\omega = \epsilon_i+\epsilon_j$, Eq. (\ref{eq:ccd1}) reduces to the
well-known equations for the so-called $G$-matrix, widely used in \href{{http://www.sciencedirect.com/science/journal/03701573/261/3-4}}{infinite matter and finite nuclei studies}. The equation can then be reordered and solved by matrix inversion.  To see this let us define the following quantity
\[
\tau_{ij}^{ab}= \left(\omega-\epsilon_a-\epsilon_b\right)t_{ij}^{ab},
\]
and inserting 
\[
1=\frac{\left(\omega-\epsilon_c-\epsilon_d\right)}{\left(\omega-\epsilon_c-\epsilon_d\right)},
\]
in the intermediate sums over $cd$ in Eq. (\ref{eq:ccd1}), we can rewrite the latter equation as
\[
\tau_{ij}^{ab}(\omega)= \langle ab \vert \hat{v} \vert ij \rangle + \frac{1}{2}\sum_{cd} \langle ab \vert \hat{v} \vert cd \rangle \frac{1}{\omega-\epsilon_c-\epsilon_d}\tau_{ij}^{cd}(\omega),
\]
where we have indicated an explicit energy dependence. This equation, transforming a two-particle configuration into a single index, can be transformed into a matrix inversion problem.  Solving the equations for a fixed energy $\omega$ allows us to compare directly with results from Green's function theory when only two-particle intermediate states are included. 

To solve Eq. (\ref{eq:ccd1}), we would thus start with a guess for the unknown amplitudes, typically using the wave operator defined by first order in perturbation theory, leading to a zeroth approximation to the energy given by second-order perturbation theory for the correlation energy.
A simple approach to the solution of  Eq. (\ref{eq:ccd1}), is to thus to
\begin{enumerate}
\item Start with a guess for the amplitudes and compute the zeroth approximation to the correlation energy

\item Use the ansatz for the amplitudes to solve Eq. (\ref{eq:ccd1}) via for example your root-finding method of choice (Newton's method or modifications thereof can be used) and continue these iterations till the correlation energy does not change more than a prefixed quantity $\lambda$; $\Delta E_{\mathrm{CCD}}^{(i)}-\Delta E_{\mathrm{CCD}}^{(i-1)} \le \lambda$.

\item It is common during the iterations to scale the amplitudes with a parameter $\alpha$, with $\alpha \in (0,1]$ as  $t^{(i)}=\alpha t^{(i)}+(1-\alpha)t^{(i-1)}$.
\end{enumerate}

\noindent
The next approximation is to include the two-hole term in Eq. (\ref{eq:ccd}), a term which allow us to make a link with Green's function theory with two-particle and two-hole correlations. This means that we solve
\begin{equation}
0 = \langle ab \vert \hat{v} \vert ij \rangle + \left(\epsilon_a+\epsilon_b-\epsilon_i-\epsilon_j\right)t_{ij}^{ab}+\frac{1}{2}\sum_{cd} \langle ab \vert \hat{v} \vert cd \rangle t_{ij}^{cd}+\frac{1}{2}\sum_{kl} \langle kl \vert \hat{v} \vert ij \rangle t_{kl}^{ab}.
\label{eq:ccd2}
\end{equation}
This equation is solved the same way as we would do for Eq. (\ref{eq:ccd1}). The final step is then to include all terms in Eq. (\ref{eq:ccd}). 


\subsection{Formal derivation of the CCSD equations}




\section{How to build a numerical quantum mechanical project}


\section{Summary}
 





